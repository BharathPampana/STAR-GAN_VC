{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainedModel.ipynb","provenance":[],"mount_file_id":"1ee22MSkiYJxgG0oWDDI6rrs2sucEDW5l","authorship_tag":"ABX9TyOAT1HpAhAj3j2xFmkrvZ9V"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bl82fFhSfM-C"},"source":["import os\n","os.chdir('/content/drive/My Drive/GAN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QF5Vu474f2uD","executionInfo":{"status":"ok","timestamp":1604046367885,"user_tz":-330,"elapsed":2166,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"cad3d873-63e4-4cbf-e7f3-777eff6fcb36","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RYywUbvNf_j8","executionInfo":{"status":"ok","timestamp":1604046373483,"user_tz":-330,"elapsed":3565,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"63f56880-d141-4f0c-e4c4-0ded404d6553","colab":{"base_uri":"https://localhost:8080/"}},"source":["pip install librosa"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.17.0)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n","Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (50.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0hdcKzk6g4HX","executionInfo":{"status":"ok","timestamp":1604046379532,"user_tz":-330,"elapsed":4495,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"517a88ad-18d9-4b78-dbf4-2b62c78ceb3f","colab":{"base_uri":"https://localhost:8080/"}},"source":["pip install pyworld"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyworld in /usr/local/lib/python3.6/dist-packages (0.2.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyworld) (1.18.5)\n","Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from pyworld) (0.29.21)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aOfZ6NyVg7Wb","executionInfo":{"status":"ok","timestamp":1603947121608,"user_tz":-330,"elapsed":2926811,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"b57c3e56-b1db-404f-ff08-f343df497ea5","colab":{"base_uri":"https://localhost:8080/"}},"source":["import librosa\n","import numpy as np\n","import os\n","import pyworld\n","import pyworld as pw\n","import glob\n","from utility import *\n","import argparse\n","\n","FEATURE_DIM = 36\n","SAMPLE_RATE = 16000\n","FRAMES = 512\n","FFTSIZE = 1024\n","SPEAKERS_NUM = 4  # in our experiment, we use four speakers\n","\n","EPSILON = 1e-10\n","MODEL_NAME = 'starganvc_model'\n","\n","\n","def load_wavs(dataset: str, sr):\n","    '''\n","    data dict contains all audios file path\n","    resdict contains all wav files   \n","    '''\n","    data = {}\n","    with os.scandir(dataset) as it:\n","        for entry in it:\n","            if entry.is_dir():\n","                data[entry.name] = []\n","                # print(entry.name, entry.path)\n","                with os.scandir(entry.path) as it_f:\n","                    for onefile in it_f:\n","                        if onefile.is_file():\n","                            # print(onefile.path)\n","                            data[entry.name].append(onefile.path)\n","    print(f'loaded keys: {data.keys()}')\n","    # data like {TM1:[xx,xx,xxx,xxx]}\n","    resdict = {}\n","\n","    cnt = 0\n","    for key, value in data.items():\n","        resdict[key] = {}\n","\n","        for one_file in value:\n","\n","            filename = os.path.normpath(one_file).split(os.sep)[-1].split('.')[0]  # like 100061\n","            newkey = f'{filename}'\n","            wav, _ = librosa.load(one_file, sr=sr, mono=True, dtype=np.float64)\n","\n","            resdict[key][newkey] = wav\n","            # resdict[key].append(temp_dict) #like TM1:{100062:[xxxxx], .... }\n","            print('.', end='')\n","            cnt += 1\n","\n","    print(f'\\nTotal {cnt} aduio files!')\n","    return resdict\n","\n","\n","def wav_to_mcep_file(dataset: str, sr=16000, ispad: bool = False, processed_filepath: str = './data/processed'):\n","    '''convert wavs to mcep feature using image repr'''\n","    # if no processed_filepath, create it ,or delete all npz files\n","    if not os.path.exists(processed_filepath):\n","        os.makedirs(processed_filepath)\n","    else:\n","        filelist = glob.glob(os.path.join(processed_filepath, \"*.npy\"))\n","        for f in filelist:\n","            os.remove(f)\n","\n","    allwavs_cnt = len(glob.glob(f'{dataset}/*/*.wav'))\n","    # allwavs_cnt = allwavs_cnt//4*3 * 12+200 #about this number not precise\n","    print(f'Total {allwavs_cnt} audio files!')\n","\n","    d = load_wavs(dataset, sr)\n","    cnt = 1  #\n","\n","    for one_speaker in d.keys():\n","        for audio_name, audio_wav in d[one_speaker].items():\n","            # cal source audio feature\n","            audio_mcep_dict = cal_mcep(\n","                audio_wav, fs=sr, ispad=ispad, frame_period=0.005, dim=FEATURE_DIM)\n","            newname = f'{one_speaker}-{audio_name}'\n","\n","            # save the dict as npz\n","            file_path_z = f'{processed_filepath}/{newname}'\n","            print(f'save file: {file_path_z}')\n","            np.savez(file_path_z, audio_mcep_dict)\n","\n","            # save every  36*FRAMES blocks\n","            print(f'audio mcep shape {audio_mcep_dict[\"coded_sp\"].shape}')\n","\n","            # TODO step may be FRAMES//2\n","            for start_idx in range(0, audio_mcep_dict[\"coded_sp\"].shape[1] - FRAMES + 1, FRAMES):\n","                one_audio_seg = audio_mcep_dict[\"coded_sp\"][:,\n","                                                            start_idx:start_idx + FRAMES]\n","\n","                if one_audio_seg.shape[1] == FRAMES:\n","\n","                    temp_name = f'{newname}_{start_idx}'\n","                    filePath = f'{processed_filepath}/{temp_name}'\n","\n","                    print(f'[{cnt}:{allwavs_cnt}]svaing file: {filePath}.npy')\n","                    np.save(filePath, one_audio_seg)\n","            cnt += 1\n","\n","\n","def cal_mcep(wav_ori, fs=SAMPLE_RATE, ispad=False, frame_period=0.005, dim=FEATURE_DIM, fft_size=FFTSIZE):\n","    '''cal mcep given wav singnal\n","        the frame_period used only for pad_wav_to_get_fixed_frames\n","    '''\n","    if ispad:\n","        wav, pad_length = pad_wav_to_get_fixed_frames(\n","            wav_ori, frames=FRAMES, frame_period=frame_period, sr=fs)\n","    else:\n","        wav = wav_ori\n","    # Harvest F0 extraction algorithm.\n","    f0, timeaxis = pyworld.harvest(wav, fs)\n","\n","    # CheapTrick harmonic spectral envelope estimation algorithm.\n","    sp = pyworld.cheaptrick(wav, f0, timeaxis, fs, fft_size=fft_size)\n","\n","    # D4C aperiodicity estimation algorithm.\n","    ap = pyworld.d4c(wav, f0, timeaxis, fs, fft_size=fft_size)\n","    # feature reduction nxdim\n","    coded_sp = pyworld.code_spectral_envelope(sp, fs, dim)\n","    # log\n","    coded_sp = coded_sp.T  # dim x n\n","\n","    res = {\n","        'f0': f0,  # n\n","        'ap': ap,  # n*fftsize//2+1\n","        'sp': sp,  # n*fftsize//2+1\n","        'coded_sp': coded_sp,  # dim * n\n","    }\n","    return res\n","\n","\n","def pad_wav_to_get_fixed_frames(x: np.ndarray, frames: int = 128, frame_period: float = 0.005, sr: int = 16000):\n","    # one frame's points\n","    frame_length = frame_period * sr\n","    # frames points\n","    frames_points = frames * frame_length\n","\n","    wav_len = len(x)\n","\n","    # pad amount\n","    pieces = wav_len // frames_points\n","\n","    need_pad = 0\n","    if wav_len % frames_points != 0:\n","        # can't devide need pad\n","        need_pad = int((pieces + 1) * frames_points - wav_len)\n","\n","    afterpad_len = wav_len + need_pad\n","    # print(f'need pad: {need_pad}, after pad: {afterpad_len}')\n","    # padding process\n","    tempx = x.tolist()\n","\n","    if need_pad <= len(x):\n","        tempx.extend(x[:need_pad])\n","    else:\n","        temp1, temp2 = need_pad // len(x), need_pad / len(x)\n","        tempx = tempx * (temp1 + 1)\n","        samll_pad_len = int(np.ceil((temp2 - temp1) * len(x)))\n","        tempx.extend(x[:samll_pad_len])\n","\n","        diff = 0\n","        if afterpad_len != len(tempx):\n","            diff = afterpad_len - len(tempx)\n","        if diff > 0:\n","            tempx.extend(tempx[:diff])\n","        elif diff < 0:\n","            tempx = tempx[:diff]\n","\n","    # print(f'padding length: {len(x)}-->length: {len(tempx)}')\n","    # remove last point for calculate convience:the frame length are 128*(some integer).\n","    tempx = tempx[:-1]\n","\n","    return np.asarray(tempx, dtype=np.float), need_pad\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description='Convert the wav waveform to mel-cepstral coefficients(MCCs)\\\n","    and calculate the speech statistical characteristics')\n","\n","    input_dir = './data/fourspeakers'\n","    output_dir = './data/processed'\n","    ispad = True\n","    parser.add_argument('-f')\n","    parser.add_argument('--input_dir', type=str,\n","                        help='the direcotry contains data need to be processed', default=input_dir)\n","    parser.add_argument('--output_dir', type=str,\n","                        help='the directory stores the processed data', default=output_dir)\n","    parser.add_argument(\n","        '--ispad', type=bool, help='whether to pad the wavs  to get fixed length MCEP', default=ispad)\n","\n","    argv = parser.parse_args()\n","    input_dir = argv.input_dir\n","    output_dir = argv.output_dir\n","    ispad = argv.ispad\n","\n","    wav_to_mcep_file(input_dir, SAMPLE_RATE, ispad=ispad,\n","                     processed_filepath=output_dir)\n","\n","    # input_dir is train dataset. we need to calculate and save the speech\\\n","    # statistical characteristics for each speaker.\n","    generator = GenerateStatics(output_dir)\n","    generator.generate_stats()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total 648 audio files!\n","loaded keys: dict_keys(['TM2', 'TM1', 'SF2', 'SF1'])\n","........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n","Total 648 aduio files!\n","save file: ./data/processed/TM2-100004\n","audio mcep shape (36, 512)\n","[1:648]svaing file: ./data/processed/TM2-100004_0.npy\n","save file: ./data/processed/TM2-100028\n","audio mcep shape (36, 512)\n","[2:648]svaing file: ./data/processed/TM2-100028_0.npy\n","save file: ./data/processed/TM2-100084\n","audio mcep shape (36, 512)\n","[3:648]svaing file: ./data/processed/TM2-100084_0.npy\n","save file: ./data/processed/TM2-100131\n","audio mcep shape (36, 1024)\n","[4:648]svaing file: ./data/processed/TM2-100131_0.npy\n","[4:648]svaing file: ./data/processed/TM2-100131_512.npy\n","save file: ./data/processed/TM2-100121\n","audio mcep shape (36, 1024)\n","[5:648]svaing file: ./data/processed/TM2-100121_0.npy\n","[5:648]svaing file: ./data/processed/TM2-100121_512.npy\n","save file: ./data/processed/TM2-100070\n","audio mcep shape (36, 1024)\n","[6:648]svaing file: ./data/processed/TM2-100070_0.npy\n","[6:648]svaing file: ./data/processed/TM2-100070_512.npy\n","save file: ./data/processed/TM2-100007\n","audio mcep shape (36, 512)\n","[7:648]svaing file: ./data/processed/TM2-100007_0.npy\n","save file: ./data/processed/TM2-100022\n","audio mcep shape (36, 1536)\n","[8:648]svaing file: ./data/processed/TM2-100022_0.npy\n","[8:648]svaing file: ./data/processed/TM2-100022_512.npy\n","[8:648]svaing file: ./data/processed/TM2-100022_1024.npy\n","save file: ./data/processed/TM2-100057\n","audio mcep shape (36, 1024)\n","[9:648]svaing file: ./data/processed/TM2-100057_0.npy\n","[9:648]svaing file: ./data/processed/TM2-100057_512.npy\n","save file: ./data/processed/TM2-100042\n","audio mcep shape (36, 1024)\n","[10:648]svaing file: ./data/processed/TM2-100042_0.npy\n","[10:648]svaing file: ./data/processed/TM2-100042_512.npy\n","save file: ./data/processed/TM2-100114\n","audio mcep shape (36, 1536)\n","[11:648]svaing file: ./data/processed/TM2-100114_0.npy\n","[11:648]svaing file: ./data/processed/TM2-100114_512.npy\n","[11:648]svaing file: ./data/processed/TM2-100114_1024.npy\n","save file: ./data/processed/TM2-100110\n","audio mcep shape (36, 1024)\n","[12:648]svaing file: ./data/processed/TM2-100110_0.npy\n","[12:648]svaing file: ./data/processed/TM2-100110_512.npy\n","save file: ./data/processed/TM2-100115\n","audio mcep shape (36, 1024)\n","[13:648]svaing file: ./data/processed/TM2-100115_0.npy\n","[13:648]svaing file: ./data/processed/TM2-100115_512.npy\n","save file: ./data/processed/TM2-100032\n","audio mcep shape (36, 1024)\n","[14:648]svaing file: ./data/processed/TM2-100032_0.npy\n","[14:648]svaing file: ./data/processed/TM2-100032_512.npy\n","save file: ./data/processed/TM2-100160\n","audio mcep shape (36, 1536)\n","[15:648]svaing file: ./data/processed/TM2-100160_0.npy\n","[15:648]svaing file: ./data/processed/TM2-100160_512.npy\n","[15:648]svaing file: ./data/processed/TM2-100160_1024.npy\n","save file: ./data/processed/TM2-100127\n","audio mcep shape (36, 1024)\n","[16:648]svaing file: ./data/processed/TM2-100127_0.npy\n","[16:648]svaing file: ./data/processed/TM2-100127_512.npy\n","save file: ./data/processed/TM2-100112\n","audio mcep shape (36, 512)\n","[17:648]svaing file: ./data/processed/TM2-100112_0.npy\n","save file: ./data/processed/TM2-100051\n","audio mcep shape (36, 1024)\n","[18:648]svaing file: ./data/processed/TM2-100051_0.npy\n","[18:648]svaing file: ./data/processed/TM2-100051_512.npy\n","save file: ./data/processed/TM2-100155\n","audio mcep shape (36, 1024)\n","[19:648]svaing file: ./data/processed/TM2-100155_0.npy\n","[19:648]svaing file: ./data/processed/TM2-100155_512.npy\n","save file: ./data/processed/TM2-100027\n","audio mcep shape (36, 1024)\n","[20:648]svaing file: ./data/processed/TM2-100027_0.npy\n","[20:648]svaing file: ./data/processed/TM2-100027_512.npy\n","save file: ./data/processed/TM2-100031\n","audio mcep shape (36, 512)\n","[21:648]svaing file: ./data/processed/TM2-100031_0.npy\n","save file: ./data/processed/TM2-100096\n","audio mcep shape (36, 2048)\n","[22:648]svaing file: ./data/processed/TM2-100096_0.npy\n","[22:648]svaing file: ./data/processed/TM2-100096_512.npy\n","[22:648]svaing file: ./data/processed/TM2-100096_1024.npy\n","[22:648]svaing file: ./data/processed/TM2-100096_1536.npy\n","save file: ./data/processed/TM2-100098\n","audio mcep shape (36, 1536)\n","[23:648]svaing file: ./data/processed/TM2-100098_0.npy\n","[23:648]svaing file: ./data/processed/TM2-100098_512.npy\n","[23:648]svaing file: ./data/processed/TM2-100098_1024.npy\n","save file: ./data/processed/TM2-100067\n","audio mcep shape (36, 1024)\n","[24:648]svaing file: ./data/processed/TM2-100067_0.npy\n","[24:648]svaing file: ./data/processed/TM2-100067_512.npy\n","save file: ./data/processed/TM2-100056\n","audio mcep shape (36, 1024)\n","[25:648]svaing file: ./data/processed/TM2-100056_0.npy\n","[25:648]svaing file: ./data/processed/TM2-100056_512.npy\n","save file: ./data/processed/TM2-100053\n","audio mcep shape (36, 512)\n","[26:648]svaing file: ./data/processed/TM2-100053_0.npy\n","save file: ./data/processed/TM2-100017\n","audio mcep shape (36, 1024)\n","[27:648]svaing file: ./data/processed/TM2-100017_0.npy\n","[27:648]svaing file: ./data/processed/TM2-100017_512.npy\n","save file: ./data/processed/TM2-100116\n","audio mcep shape (36, 1024)\n","[28:648]svaing file: ./data/processed/TM2-100116_0.npy\n","[28:648]svaing file: ./data/processed/TM2-100116_512.npy\n","save file: ./data/processed/TM2-100132\n","audio mcep shape (36, 512)\n","[29:648]svaing file: ./data/processed/TM2-100132_0.npy\n","save file: ./data/processed/TM2-100024\n","audio mcep shape (36, 1024)\n","[30:648]svaing file: ./data/processed/TM2-100024_0.npy\n","[30:648]svaing file: ./data/processed/TM2-100024_512.npy\n","save file: ./data/processed/TM2-100033\n","audio mcep shape (36, 1024)\n","[31:648]svaing file: ./data/processed/TM2-100033_0.npy\n","[31:648]svaing file: ./data/processed/TM2-100033_512.npy\n","save file: ./data/processed/TM2-100122\n","audio mcep shape (36, 512)\n","[32:648]svaing file: ./data/processed/TM2-100122_0.npy\n","save file: ./data/processed/TM2-100111\n","audio mcep shape (36, 1024)\n","[33:648]svaing file: ./data/processed/TM2-100111_0.npy\n","[33:648]svaing file: ./data/processed/TM2-100111_512.npy\n","save file: ./data/processed/TM2-100159\n","audio mcep shape (36, 512)\n","[34:648]svaing file: ./data/processed/TM2-100159_0.npy\n","save file: ./data/processed/TM2-100118\n","audio mcep shape (36, 1024)\n","[35:648]svaing file: ./data/processed/TM2-100118_0.npy\n","[35:648]svaing file: ./data/processed/TM2-100118_512.npy\n","save file: ./data/processed/TM2-100069\n","audio mcep shape (36, 512)\n","[36:648]svaing file: ./data/processed/TM2-100069_0.npy\n","save file: ./data/processed/TM2-100003\n","audio mcep shape (36, 512)\n","[37:648]svaing file: ./data/processed/TM2-100003_0.npy\n","save file: ./data/processed/TM2-100158\n","audio mcep shape (36, 512)\n","[38:648]svaing file: ./data/processed/TM2-100158_0.npy\n","save file: ./data/processed/TM2-100046\n","audio mcep shape (36, 512)\n","[39:648]svaing file: ./data/processed/TM2-100046_0.npy\n","save file: ./data/processed/TM2-100120\n","audio mcep shape (36, 1024)\n","[40:648]svaing file: ./data/processed/TM2-100120_0.npy\n","[40:648]svaing file: ./data/processed/TM2-100120_512.npy\n","save file: ./data/processed/TM2-100055\n","audio mcep shape (36, 512)\n","[41:648]svaing file: ./data/processed/TM2-100055_0.npy\n","save file: ./data/processed/TM2-100038\n","audio mcep shape (36, 1024)\n","[42:648]svaing file: ./data/processed/TM2-100038_0.npy\n","[42:648]svaing file: ./data/processed/TM2-100038_512.npy\n","save file: ./data/processed/TM2-100043\n","audio mcep shape (36, 512)\n","[43:648]svaing file: ./data/processed/TM2-100043_0.npy\n","save file: ./data/processed/TM2-100133\n","audio mcep shape (36, 1536)\n","[44:648]svaing file: ./data/processed/TM2-100133_0.npy\n","[44:648]svaing file: ./data/processed/TM2-100133_512.npy\n","[44:648]svaing file: ./data/processed/TM2-100133_1024.npy\n","save file: ./data/processed/TM2-100130\n","audio mcep shape (36, 1024)\n","[45:648]svaing file: ./data/processed/TM2-100130_0.npy\n","[45:648]svaing file: ./data/processed/TM2-100130_512.npy\n","save file: ./data/processed/TM2-100054\n","audio mcep shape (36, 1024)\n","[46:648]svaing file: ./data/processed/TM2-100054_0.npy\n","[46:648]svaing file: ./data/processed/TM2-100054_512.npy\n","save file: ./data/processed/TM2-100156\n","audio mcep shape (36, 512)\n","[47:648]svaing file: ./data/processed/TM2-100156_0.npy\n","save file: ./data/processed/TM2-100068\n","audio mcep shape (36, 512)\n","[48:648]svaing file: ./data/processed/TM2-100068_0.npy\n","save file: ./data/processed/TM2-100044\n","audio mcep shape (36, 512)\n","[49:648]svaing file: ./data/processed/TM2-100044_0.npy\n","save file: ./data/processed/TM2-100152\n","audio mcep shape (36, 1024)\n","[50:648]svaing file: ./data/processed/TM2-100152_0.npy\n","[50:648]svaing file: ./data/processed/TM2-100152_512.npy\n","save file: ./data/processed/TM2-100040\n","audio mcep shape (36, 1024)\n","[51:648]svaing file: ./data/processed/TM2-100040_0.npy\n","[51:648]svaing file: ./data/processed/TM2-100040_512.npy\n","save file: ./data/processed/TM2-100100\n","audio mcep shape (36, 1024)\n","[52:648]svaing file: ./data/processed/TM2-100100_0.npy\n","[52:648]svaing file: ./data/processed/TM2-100100_512.npy\n","save file: ./data/processed/TM2-100126\n","audio mcep shape (36, 1024)\n","[53:648]svaing file: ./data/processed/TM2-100126_0.npy\n","[53:648]svaing file: ./data/processed/TM2-100126_512.npy\n","save file: ./data/processed/TM2-100080\n","audio mcep shape (36, 1024)\n","[54:648]svaing file: ./data/processed/TM2-100080_0.npy\n","[54:648]svaing file: ./data/processed/TM2-100080_512.npy\n","save file: ./data/processed/TM2-100045\n","audio mcep shape (36, 1024)\n","[55:648]svaing file: ./data/processed/TM2-100045_0.npy\n","[55:648]svaing file: ./data/processed/TM2-100045_512.npy\n","save file: ./data/processed/TM2-100025\n","audio mcep shape (36, 1536)\n","[56:648]svaing file: ./data/processed/TM2-100025_0.npy\n","[56:648]svaing file: ./data/processed/TM2-100025_512.npy\n","[56:648]svaing file: ./data/processed/TM2-100025_1024.npy\n","save file: ./data/processed/TM2-100013\n","audio mcep shape (36, 1024)\n","[57:648]svaing file: ./data/processed/TM2-100013_0.npy\n","[57:648]svaing file: ./data/processed/TM2-100013_512.npy\n","save file: ./data/processed/TM2-100162\n","audio mcep shape (36, 1024)\n","[58:648]svaing file: ./data/processed/TM2-100162_0.npy\n","[58:648]svaing file: ./data/processed/TM2-100162_512.npy\n","save file: ./data/processed/TM2-100006\n","audio mcep shape (36, 1024)\n","[59:648]svaing file: ./data/processed/TM2-100006_0.npy\n","[59:648]svaing file: ./data/processed/TM2-100006_512.npy\n","save file: ./data/processed/TM2-100041\n","audio mcep shape (36, 512)\n","[60:648]svaing file: ./data/processed/TM2-100041_0.npy\n","save file: ./data/processed/TM2-100148\n","audio mcep shape (36, 1024)\n","[61:648]svaing file: ./data/processed/TM2-100148_0.npy\n","[61:648]svaing file: ./data/processed/TM2-100148_512.npy\n","save file: ./data/processed/TM2-100001\n","audio mcep shape (36, 1024)\n","[62:648]svaing file: ./data/processed/TM2-100001_0.npy\n","[62:648]svaing file: ./data/processed/TM2-100001_512.npy\n","save file: ./data/processed/TM2-100147\n","audio mcep shape (36, 512)\n","[63:648]svaing file: ./data/processed/TM2-100147_0.npy\n","save file: ./data/processed/TM2-100109\n","audio mcep shape (36, 512)\n","[64:648]svaing file: ./data/processed/TM2-100109_0.npy\n","save file: ./data/processed/TM2-100030\n","audio mcep shape (36, 512)\n","[65:648]svaing file: ./data/processed/TM2-100030_0.npy\n","save file: ./data/processed/TM2-100062\n","audio mcep shape (36, 1024)\n","[66:648]svaing file: ./data/processed/TM2-100062_0.npy\n","[66:648]svaing file: ./data/processed/TM2-100062_512.npy\n","save file: ./data/processed/TM2-100081\n","audio mcep shape (36, 1536)\n","[67:648]svaing file: ./data/processed/TM2-100081_0.npy\n","[67:648]svaing file: ./data/processed/TM2-100081_512.npy\n","[67:648]svaing file: ./data/processed/TM2-100081_1024.npy\n","save file: ./data/processed/TM2-100037\n","audio mcep shape (36, 512)\n","[68:648]svaing file: ./data/processed/TM2-100037_0.npy\n","save file: ./data/processed/TM2-100021\n","audio mcep shape (36, 1536)\n","[69:648]svaing file: ./data/processed/TM2-100021_0.npy\n","[69:648]svaing file: ./data/processed/TM2-100021_512.npy\n","[69:648]svaing file: ./data/processed/TM2-100021_1024.npy\n","save file: ./data/processed/TM2-100135\n","audio mcep shape (36, 1024)\n","[70:648]svaing file: ./data/processed/TM2-100135_0.npy\n","[70:648]svaing file: ./data/processed/TM2-100135_512.npy\n","save file: ./data/processed/TM2-100106\n","audio mcep shape (36, 512)\n","[71:648]svaing file: ./data/processed/TM2-100106_0.npy\n","save file: ./data/processed/TM2-100105\n","audio mcep shape (36, 1024)\n","[72:648]svaing file: ./data/processed/TM2-100105_0.npy\n","[72:648]svaing file: ./data/processed/TM2-100105_512.npy\n","save file: ./data/processed/TM2-100059\n","audio mcep shape (36, 1024)\n","[73:648]svaing file: ./data/processed/TM2-100059_0.npy\n","[73:648]svaing file: ./data/processed/TM2-100059_512.npy\n","save file: ./data/processed/TM2-100092\n","audio mcep shape (36, 1024)\n","[74:648]svaing file: ./data/processed/TM2-100092_0.npy\n","[74:648]svaing file: ./data/processed/TM2-100092_512.npy\n","save file: ./data/processed/TM2-100010\n","audio mcep shape (36, 1024)\n","[75:648]svaing file: ./data/processed/TM2-100010_0.npy\n","[75:648]svaing file: ./data/processed/TM2-100010_512.npy\n","save file: ./data/processed/TM2-100078\n","audio mcep shape (36, 512)\n","[76:648]svaing file: ./data/processed/TM2-100078_0.npy\n","save file: ./data/processed/TM2-100087\n","audio mcep shape (36, 1024)\n","[77:648]svaing file: ./data/processed/TM2-100087_0.npy\n","[77:648]svaing file: ./data/processed/TM2-100087_512.npy\n","save file: ./data/processed/TM2-100011\n","audio mcep shape (36, 1024)\n","[78:648]svaing file: ./data/processed/TM2-100011_0.npy\n","[78:648]svaing file: ./data/processed/TM2-100011_512.npy\n","save file: ./data/processed/TM2-100064\n","audio mcep shape (36, 1024)\n","[79:648]svaing file: ./data/processed/TM2-100064_0.npy\n","[79:648]svaing file: ./data/processed/TM2-100064_512.npy\n","save file: ./data/processed/TM2-100138\n","audio mcep shape (36, 512)\n","[80:648]svaing file: ./data/processed/TM2-100138_0.npy\n","save file: ./data/processed/TM2-100052\n","audio mcep shape (36, 512)\n","[81:648]svaing file: ./data/processed/TM2-100052_0.npy\n","save file: ./data/processed/TM2-100029\n","audio mcep shape (36, 1024)\n","[82:648]svaing file: ./data/processed/TM2-100029_0.npy\n","[82:648]svaing file: ./data/processed/TM2-100029_512.npy\n","save file: ./data/processed/TM2-100036\n","audio mcep shape (36, 512)\n","[83:648]svaing file: ./data/processed/TM2-100036_0.npy\n","save file: ./data/processed/TM2-100107\n","audio mcep shape (36, 1024)\n","[84:648]svaing file: ./data/processed/TM2-100107_0.npy\n","[84:648]svaing file: ./data/processed/TM2-100107_512.npy\n","save file: ./data/processed/TM2-100012\n","audio mcep shape (36, 1024)\n","[85:648]svaing file: ./data/processed/TM2-100012_0.npy\n","[85:648]svaing file: ./data/processed/TM2-100012_512.npy\n","save file: ./data/processed/TM2-100023\n","audio mcep shape (36, 512)\n","[86:648]svaing file: ./data/processed/TM2-100023_0.npy\n","save file: ./data/processed/TM2-100113\n","audio mcep shape (36, 512)\n","[87:648]svaing file: ./data/processed/TM2-100113_0.npy\n","save file: ./data/processed/TM2-100050\n","audio mcep shape (36, 1024)\n","[88:648]svaing file: ./data/processed/TM2-100050_0.npy\n","[88:648]svaing file: ./data/processed/TM2-100050_512.npy\n","save file: ./data/processed/TM2-100085\n","audio mcep shape (36, 1024)\n","[89:648]svaing file: ./data/processed/TM2-100085_0.npy\n","[89:648]svaing file: ./data/processed/TM2-100085_512.npy\n","save file: ./data/processed/TM2-100061\n","audio mcep shape (36, 1024)\n","[90:648]svaing file: ./data/processed/TM2-100061_0.npy\n","[90:648]svaing file: ./data/processed/TM2-100061_512.npy\n","save file: ./data/processed/TM2-100002\n","audio mcep shape (36, 512)\n","[91:648]svaing file: ./data/processed/TM2-100002_0.npy\n","save file: ./data/processed/TM2-100140\n","audio mcep shape (36, 512)\n","[92:648]svaing file: ./data/processed/TM2-100140_0.npy\n","save file: ./data/processed/TM2-100154\n","audio mcep shape (36, 512)\n","[93:648]svaing file: ./data/processed/TM2-100154_0.npy\n","save file: ./data/processed/TM2-100101\n","audio mcep shape (36, 1024)\n","[94:648]svaing file: ./data/processed/TM2-100101_0.npy\n","[94:648]svaing file: ./data/processed/TM2-100101_512.npy\n","save file: ./data/processed/TM2-100145\n","audio mcep shape (36, 512)\n","[95:648]svaing file: ./data/processed/TM2-100145_0.npy\n","save file: ./data/processed/TM2-100077\n","audio mcep shape (36, 1024)\n","[96:648]svaing file: ./data/processed/TM2-100077_0.npy\n","[96:648]svaing file: ./data/processed/TM2-100077_512.npy\n","save file: ./data/processed/TM2-100119\n","audio mcep shape (36, 512)\n","[97:648]svaing file: ./data/processed/TM2-100119_0.npy\n","save file: ./data/processed/TM2-100151\n","audio mcep shape (36, 1024)\n","[98:648]svaing file: ./data/processed/TM2-100151_0.npy\n","[98:648]svaing file: ./data/processed/TM2-100151_512.npy\n","save file: ./data/processed/TM2-100008\n","audio mcep shape (36, 1024)\n","[99:648]svaing file: ./data/processed/TM2-100008_0.npy\n","[99:648]svaing file: ./data/processed/TM2-100008_512.npy\n","save file: ./data/processed/TM2-100034\n","audio mcep shape (36, 1024)\n","[100:648]svaing file: ./data/processed/TM2-100034_0.npy\n","[100:648]svaing file: ./data/processed/TM2-100034_512.npy\n","save file: ./data/processed/TM2-100014\n","audio mcep shape (36, 1024)\n","[101:648]svaing file: ./data/processed/TM2-100014_0.npy\n","[101:648]svaing file: ./data/processed/TM2-100014_512.npy\n","save file: ./data/processed/TM2-100128\n","audio mcep shape (36, 512)\n","[102:648]svaing file: ./data/processed/TM2-100128_0.npy\n","save file: ./data/processed/TM2-100103\n","audio mcep shape (36, 512)\n","[103:648]svaing file: ./data/processed/TM2-100103_0.npy\n","save file: ./data/processed/TM2-100090\n","audio mcep shape (36, 512)\n","[104:648]svaing file: ./data/processed/TM2-100090_0.npy\n","save file: ./data/processed/TM2-100019\n","audio mcep shape (36, 512)\n","[105:648]svaing file: ./data/processed/TM2-100019_0.npy\n","save file: ./data/processed/TM2-100009\n","audio mcep shape (36, 512)\n","[106:648]svaing file: ./data/processed/TM2-100009_0.npy\n","save file: ./data/processed/TM2-100083\n","audio mcep shape (36, 1024)\n","[107:648]svaing file: ./data/processed/TM2-100083_0.npy\n","[107:648]svaing file: ./data/processed/TM2-100083_512.npy\n","save file: ./data/processed/TM2-100104\n","audio mcep shape (36, 512)\n","[108:648]svaing file: ./data/processed/TM2-100104_0.npy\n","save file: ./data/processed/TM2-100157\n","audio mcep shape (36, 1024)\n","[109:648]svaing file: ./data/processed/TM2-100157_0.npy\n","[109:648]svaing file: ./data/processed/TM2-100157_512.npy\n","save file: ./data/processed/TM2-100082\n","audio mcep shape (36, 512)\n","[110:648]svaing file: ./data/processed/TM2-100082_0.npy\n","save file: ./data/processed/TM2-100099\n","audio mcep shape (36, 1024)\n","[111:648]svaing file: ./data/processed/TM2-100099_0.npy\n","[111:648]svaing file: ./data/processed/TM2-100099_512.npy\n","save file: ./data/processed/TM2-100150\n","audio mcep shape (36, 512)\n","[112:648]svaing file: ./data/processed/TM2-100150_0.npy\n","save file: ./data/processed/TM2-100123\n","audio mcep shape (36, 1024)\n","[113:648]svaing file: ./data/processed/TM2-100123_0.npy\n","[113:648]svaing file: ./data/processed/TM2-100123_512.npy\n","save file: ./data/processed/TM2-100094\n","audio mcep shape (36, 1024)\n","[114:648]svaing file: ./data/processed/TM2-100094_0.npy\n","[114:648]svaing file: ./data/processed/TM2-100094_512.npy\n","save file: ./data/processed/TM2-100039\n","audio mcep shape (36, 1024)\n","[115:648]svaing file: ./data/processed/TM2-100039_0.npy\n","[115:648]svaing file: ./data/processed/TM2-100039_512.npy\n","save file: ./data/processed/TM2-100026\n","audio mcep shape (36, 512)\n","[116:648]svaing file: ./data/processed/TM2-100026_0.npy\n","save file: ./data/processed/TM2-100058\n","audio mcep shape (36, 512)\n","[117:648]svaing file: ./data/processed/TM2-100058_0.npy\n","save file: ./data/processed/TM2-100095\n","audio mcep shape (36, 1024)\n","[118:648]svaing file: ./data/processed/TM2-100095_0.npy\n","[118:648]svaing file: ./data/processed/TM2-100095_512.npy\n","save file: ./data/processed/TM2-100063\n","audio mcep shape (36, 512)\n","[119:648]svaing file: ./data/processed/TM2-100063_0.npy\n","save file: ./data/processed/TM2-100149\n","audio mcep shape (36, 1536)\n","[120:648]svaing file: ./data/processed/TM2-100149_0.npy\n","[120:648]svaing file: ./data/processed/TM2-100149_512.npy\n","[120:648]svaing file: ./data/processed/TM2-100149_1024.npy\n","save file: ./data/processed/TM2-100065\n","audio mcep shape (36, 1024)\n","[121:648]svaing file: ./data/processed/TM2-100065_0.npy\n","[121:648]svaing file: ./data/processed/TM2-100065_512.npy\n","save file: ./data/processed/TM2-100143\n","audio mcep shape (36, 512)\n","[122:648]svaing file: ./data/processed/TM2-100143_0.npy\n","save file: ./data/processed/TM2-100073\n","audio mcep shape (36, 1024)\n","[123:648]svaing file: ./data/processed/TM2-100073_0.npy\n","[123:648]svaing file: ./data/processed/TM2-100073_512.npy\n","save file: ./data/processed/TM2-100093\n","audio mcep shape (36, 512)\n","[124:648]svaing file: ./data/processed/TM2-100093_0.npy\n","save file: ./data/processed/TM2-100139\n","audio mcep shape (36, 512)\n","[125:648]svaing file: ./data/processed/TM2-100139_0.npy\n","save file: ./data/processed/TM2-100015\n","audio mcep shape (36, 512)\n","[126:648]svaing file: ./data/processed/TM2-100015_0.npy\n","save file: ./data/processed/TM2-100018\n","audio mcep shape (36, 512)\n","[127:648]svaing file: ./data/processed/TM2-100018_0.npy\n","save file: ./data/processed/TM2-100005\n","audio mcep shape (36, 1024)\n","[128:648]svaing file: ./data/processed/TM2-100005_0.npy\n","[128:648]svaing file: ./data/processed/TM2-100005_512.npy\n","save file: ./data/processed/TM2-100089\n","audio mcep shape (36, 512)\n","[129:648]svaing file: ./data/processed/TM2-100089_0.npy\n","save file: ./data/processed/TM2-100060\n","audio mcep shape (36, 512)\n","[130:648]svaing file: ./data/processed/TM2-100060_0.npy\n","save file: ./data/processed/TM2-100108\n","audio mcep shape (36, 1024)\n","[131:648]svaing file: ./data/processed/TM2-100108_0.npy\n","[131:648]svaing file: ./data/processed/TM2-100108_512.npy\n","save file: ./data/processed/TM2-100144\n","audio mcep shape (36, 1024)\n","[132:648]svaing file: ./data/processed/TM2-100144_0.npy\n","[132:648]svaing file: ./data/processed/TM2-100144_512.npy\n","save file: ./data/processed/TM2-100076\n","audio mcep shape (36, 512)\n","[133:648]svaing file: ./data/processed/TM2-100076_0.npy\n","save file: ./data/processed/TM2-100079\n","audio mcep shape (36, 512)\n","[134:648]svaing file: ./data/processed/TM2-100079_0.npy\n","save file: ./data/processed/TM2-100134\n","audio mcep shape (36, 512)\n","[135:648]svaing file: ./data/processed/TM2-100134_0.npy\n","save file: ./data/processed/TM2-100071\n","audio mcep shape (36, 1024)\n","[136:648]svaing file: ./data/processed/TM2-100071_0.npy\n","[136:648]svaing file: ./data/processed/TM2-100071_512.npy\n","save file: ./data/processed/TM2-100142\n","audio mcep shape (36, 1024)\n","[137:648]svaing file: ./data/processed/TM2-100142_0.npy\n","[137:648]svaing file: ./data/processed/TM2-100142_512.npy\n","save file: ./data/processed/TM2-100074\n","audio mcep shape (36, 1024)\n","[138:648]svaing file: ./data/processed/TM2-100074_0.npy\n","[138:648]svaing file: ./data/processed/TM2-100074_512.npy\n","save file: ./data/processed/TM2-100020\n","audio mcep shape (36, 512)\n","[139:648]svaing file: ./data/processed/TM2-100020_0.npy\n","save file: ./data/processed/TM2-100129\n","audio mcep shape (36, 512)\n","[140:648]svaing file: ./data/processed/TM2-100129_0.npy\n","save file: ./data/processed/TM2-100066\n","audio mcep shape (36, 512)\n","[141:648]svaing file: ./data/processed/TM2-100066_0.npy\n","save file: ./data/processed/TM2-100075\n","audio mcep shape (36, 1024)\n","[142:648]svaing file: ./data/processed/TM2-100075_0.npy\n","[142:648]svaing file: ./data/processed/TM2-100075_512.npy\n","save file: ./data/processed/TM2-100161\n","audio mcep shape (36, 1024)\n","[143:648]svaing file: ./data/processed/TM2-100161_0.npy\n","[143:648]svaing file: ./data/processed/TM2-100161_512.npy\n","save file: ./data/processed/TM2-100097\n","audio mcep shape (36, 512)\n","[144:648]svaing file: ./data/processed/TM2-100097_0.npy\n","save file: ./data/processed/TM2-100016\n","audio mcep shape (36, 1024)\n","[145:648]svaing file: ./data/processed/TM2-100016_0.npy\n","[145:648]svaing file: ./data/processed/TM2-100016_512.npy\n","save file: ./data/processed/TM2-100146\n","audio mcep shape (36, 512)\n","[146:648]svaing file: ./data/processed/TM2-100146_0.npy\n","save file: ./data/processed/TM2-100049\n","audio mcep shape (36, 1024)\n","[147:648]svaing file: ./data/processed/TM2-100049_0.npy\n","[147:648]svaing file: ./data/processed/TM2-100049_512.npy\n","save file: ./data/processed/TM2-100117\n","audio mcep shape (36, 512)\n","[148:648]svaing file: ./data/processed/TM2-100117_0.npy\n","save file: ./data/processed/TM2-100047\n","audio mcep shape (36, 1024)\n","[149:648]svaing file: ./data/processed/TM2-100047_0.npy\n","[149:648]svaing file: ./data/processed/TM2-100047_512.npy\n","save file: ./data/processed/TM2-100072\n","audio mcep shape (36, 1024)\n","[150:648]svaing file: ./data/processed/TM2-100072_0.npy\n","[150:648]svaing file: ./data/processed/TM2-100072_512.npy\n","save file: ./data/processed/TM2-100136\n","audio mcep shape (36, 1024)\n","[151:648]svaing file: ./data/processed/TM2-100136_0.npy\n","[151:648]svaing file: ./data/processed/TM2-100136_512.npy\n","save file: ./data/processed/TM2-100086\n","audio mcep shape (36, 512)\n","[152:648]svaing file: ./data/processed/TM2-100086_0.npy\n","save file: ./data/processed/TM2-100102\n","audio mcep shape (36, 512)\n","[153:648]svaing file: ./data/processed/TM2-100102_0.npy\n","save file: ./data/processed/TM2-100141\n","audio mcep shape (36, 512)\n","[154:648]svaing file: ./data/processed/TM2-100141_0.npy\n","save file: ./data/processed/TM2-100153\n","audio mcep shape (36, 512)\n","[155:648]svaing file: ./data/processed/TM2-100153_0.npy\n","save file: ./data/processed/TM2-100048\n","audio mcep shape (36, 1024)\n","[156:648]svaing file: ./data/processed/TM2-100048_0.npy\n","[156:648]svaing file: ./data/processed/TM2-100048_512.npy\n","save file: ./data/processed/TM2-100125\n","audio mcep shape (36, 1536)\n","[157:648]svaing file: ./data/processed/TM2-100125_0.npy\n","[157:648]svaing file: ./data/processed/TM2-100125_512.npy\n","[157:648]svaing file: ./data/processed/TM2-100125_1024.npy\n","save file: ./data/processed/TM2-100091\n","audio mcep shape (36, 1024)\n","[158:648]svaing file: ./data/processed/TM2-100091_0.npy\n","[158:648]svaing file: ./data/processed/TM2-100091_512.npy\n","save file: ./data/processed/TM2-100137\n","audio mcep shape (36, 512)\n","[159:648]svaing file: ./data/processed/TM2-100137_0.npy\n","save file: ./data/processed/TM2-100088\n","audio mcep shape (36, 1536)\n","[160:648]svaing file: ./data/processed/TM2-100088_0.npy\n","[160:648]svaing file: ./data/processed/TM2-100088_512.npy\n","[160:648]svaing file: ./data/processed/TM2-100088_1024.npy\n","save file: ./data/processed/TM2-100124\n","audio mcep shape (36, 512)\n","[161:648]svaing file: ./data/processed/TM2-100124_0.npy\n","save file: ./data/processed/TM2-100035\n","audio mcep shape (36, 512)\n","[162:648]svaing file: ./data/processed/TM2-100035_0.npy\n","save file: ./data/processed/TM1-100056\n","audio mcep shape (36, 1024)\n","[163:648]svaing file: ./data/processed/TM1-100056_0.npy\n","[163:648]svaing file: ./data/processed/TM1-100056_512.npy\n","save file: ./data/processed/TM1-100100\n","audio mcep shape (36, 512)\n","[164:648]svaing file: ./data/processed/TM1-100100_0.npy\n","save file: ./data/processed/TM1-100016\n","audio mcep shape (36, 512)\n","[165:648]svaing file: ./data/processed/TM1-100016_0.npy\n","save file: ./data/processed/TM1-100161\n","audio mcep shape (36, 1024)\n","[166:648]svaing file: ./data/processed/TM1-100161_0.npy\n","[166:648]svaing file: ./data/processed/TM1-100161_512.npy\n","save file: ./data/processed/TM1-100128\n","audio mcep shape (36, 512)\n","[167:648]svaing file: ./data/processed/TM1-100128_0.npy\n","save file: ./data/processed/TM1-100095\n","audio mcep shape (36, 1024)\n","[168:648]svaing file: ./data/processed/TM1-100095_0.npy\n","[168:648]svaing file: ./data/processed/TM1-100095_512.npy\n","save file: ./data/processed/TM1-100077\n","audio mcep shape (36, 1536)\n","[169:648]svaing file: ./data/processed/TM1-100077_0.npy\n","[169:648]svaing file: ./data/processed/TM1-100077_512.npy\n","[169:648]svaing file: ./data/processed/TM1-100077_1024.npy\n","save file: ./data/processed/TM1-100130\n","audio mcep shape (36, 1024)\n","[170:648]svaing file: ./data/processed/TM1-100130_0.npy\n","[170:648]svaing file: ./data/processed/TM1-100130_512.npy\n","save file: ./data/processed/TM1-100111\n","audio mcep shape (36, 1536)\n","[171:648]svaing file: ./data/processed/TM1-100111_0.npy\n","[171:648]svaing file: ./data/processed/TM1-100111_512.npy\n","[171:648]svaing file: ./data/processed/TM1-100111_1024.npy\n","save file: ./data/processed/TM1-100042\n","audio mcep shape (36, 1024)\n","[172:648]svaing file: ./data/processed/TM1-100042_0.npy\n","[172:648]svaing file: ./data/processed/TM1-100042_512.npy\n","save file: ./data/processed/TM1-100160\n","audio mcep shape (36, 1536)\n","[173:648]svaing file: ./data/processed/TM1-100160_0.npy\n","[173:648]svaing file: ./data/processed/TM1-100160_512.npy\n","[173:648]svaing file: ./data/processed/TM1-100160_1024.npy\n","save file: ./data/processed/TM1-100149\n","audio mcep shape (36, 1536)\n","[174:648]svaing file: ./data/processed/TM1-100149_0.npy\n","[174:648]svaing file: ./data/processed/TM1-100149_512.npy\n","[174:648]svaing file: ./data/processed/TM1-100149_1024.npy\n","save file: ./data/processed/TM1-100028\n","audio mcep shape (36, 512)\n","[175:648]svaing file: ./data/processed/TM1-100028_0.npy\n","save file: ./data/processed/TM1-100138\n","audio mcep shape (36, 512)\n","[176:648]svaing file: ./data/processed/TM1-100138_0.npy\n","save file: ./data/processed/TM1-100032\n","audio mcep shape (36, 1024)\n","[177:648]svaing file: ./data/processed/TM1-100032_0.npy\n","[177:648]svaing file: ./data/processed/TM1-100032_512.npy\n","save file: ./data/processed/TM1-100080\n","audio mcep shape (36, 1024)\n","[178:648]svaing file: ./data/processed/TM1-100080_0.npy\n","[178:648]svaing file: ./data/processed/TM1-100080_512.npy\n","save file: ./data/processed/TM1-100008\n","audio mcep shape (36, 1536)\n","[179:648]svaing file: ./data/processed/TM1-100008_0.npy\n","[179:648]svaing file: ./data/processed/TM1-100008_512.npy\n","[179:648]svaing file: ./data/processed/TM1-100008_1024.npy\n","save file: ./data/processed/TM1-100018\n","audio mcep shape (36, 512)\n","[180:648]svaing file: ./data/processed/TM1-100018_0.npy\n","save file: ./data/processed/TM1-100026\n","audio mcep shape (36, 512)\n","[181:648]svaing file: ./data/processed/TM1-100026_0.npy\n","save file: ./data/processed/TM1-100076\n","audio mcep shape (36, 512)\n","[182:648]svaing file: ./data/processed/TM1-100076_0.npy\n","save file: ./data/processed/TM1-100096\n","audio mcep shape (36, 2048)\n","[183:648]svaing file: ./data/processed/TM1-100096_0.npy\n","[183:648]svaing file: ./data/processed/TM1-100096_512.npy\n","[183:648]svaing file: ./data/processed/TM1-100096_1024.npy\n","[183:648]svaing file: ./data/processed/TM1-100096_1536.npy\n","save file: ./data/processed/TM1-100115\n","audio mcep shape (36, 1024)\n","[184:648]svaing file: ./data/processed/TM1-100115_0.npy\n","[184:648]svaing file: ./data/processed/TM1-100115_512.npy\n","save file: ./data/processed/TM1-100068\n","audio mcep shape (36, 512)\n","[185:648]svaing file: ./data/processed/TM1-100068_0.npy\n","save file: ./data/processed/TM1-100127\n","audio mcep shape (36, 1024)\n","[186:648]svaing file: ./data/processed/TM1-100127_0.npy\n","[186:648]svaing file: ./data/processed/TM1-100127_512.npy\n","save file: ./data/processed/TM1-100098\n","audio mcep shape (36, 1536)\n","[187:648]svaing file: ./data/processed/TM1-100098_0.npy\n","[187:648]svaing file: ./data/processed/TM1-100098_512.npy\n","[187:648]svaing file: ./data/processed/TM1-100098_1024.npy\n","save file: ./data/processed/TM1-100046\n","audio mcep shape (36, 512)\n","[188:648]svaing file: ./data/processed/TM1-100046_0.npy\n","save file: ./data/processed/TM1-100084\n","audio mcep shape (36, 512)\n","[189:648]svaing file: ./data/processed/TM1-100084_0.npy\n","save file: ./data/processed/TM1-100119\n","audio mcep shape (36, 512)\n","[190:648]svaing file: ./data/processed/TM1-100119_0.npy\n","save file: ./data/processed/TM1-100052\n","audio mcep shape (36, 512)\n","[191:648]svaing file: ./data/processed/TM1-100052_0.npy\n","save file: ./data/processed/TM1-100057\n","audio mcep shape (36, 1536)\n","[192:648]svaing file: ./data/processed/TM1-100057_0.npy\n","[192:648]svaing file: ./data/processed/TM1-100057_512.npy\n","[192:648]svaing file: ./data/processed/TM1-100057_1024.npy\n","save file: ./data/processed/TM1-100103\n","audio mcep shape (36, 1024)\n","[193:648]svaing file: ./data/processed/TM1-100103_0.npy\n","[193:648]svaing file: ./data/processed/TM1-100103_512.npy\n","save file: ./data/processed/TM1-100006\n","audio mcep shape (36, 1024)\n","[194:648]svaing file: ./data/processed/TM1-100006_0.npy\n","[194:648]svaing file: ./data/processed/TM1-100006_512.npy\n","save file: ./data/processed/TM1-100134\n","audio mcep shape (36, 512)\n","[195:648]svaing file: ./data/processed/TM1-100134_0.npy\n","save file: ./data/processed/TM1-100129\n","audio mcep shape (36, 512)\n","[196:648]svaing file: ./data/processed/TM1-100129_0.npy\n","save file: ./data/processed/TM1-100069\n","audio mcep shape (36, 512)\n","[197:648]svaing file: ./data/processed/TM1-100069_0.npy\n","save file: ./data/processed/TM1-100131\n","audio mcep shape (36, 1024)\n","[198:648]svaing file: ./data/processed/TM1-100131_0.npy\n","[198:648]svaing file: ./data/processed/TM1-100131_512.npy\n","save file: ./data/processed/TM1-100073\n","audio mcep shape (36, 1024)\n","[199:648]svaing file: ./data/processed/TM1-100073_0.npy\n","[199:648]svaing file: ./data/processed/TM1-100073_512.npy\n","save file: ./data/processed/TM1-100142\n","audio mcep shape (36, 1024)\n","[200:648]svaing file: ./data/processed/TM1-100142_0.npy\n","[200:648]svaing file: ./data/processed/TM1-100142_512.npy\n","save file: ./data/processed/TM1-100079\n","audio mcep shape (36, 512)\n","[201:648]svaing file: ./data/processed/TM1-100079_0.npy\n","save file: ./data/processed/TM1-100112\n","audio mcep shape (36, 512)\n","[202:648]svaing file: ./data/processed/TM1-100112_0.npy\n","save file: ./data/processed/TM1-100132\n","audio mcep shape (36, 512)\n","[203:648]svaing file: ./data/processed/TM1-100132_0.npy\n","save file: ./data/processed/TM1-100001\n","audio mcep shape (36, 1024)\n","[204:648]svaing file: ./data/processed/TM1-100001_0.npy\n","[204:648]svaing file: ./data/processed/TM1-100001_512.npy\n","save file: ./data/processed/TM1-100066\n","audio mcep shape (36, 512)\n","[205:648]svaing file: ./data/processed/TM1-100066_0.npy\n","save file: ./data/processed/TM1-100109\n","audio mcep shape (36, 1024)\n","[206:648]svaing file: ./data/processed/TM1-100109_0.npy\n","[206:648]svaing file: ./data/processed/TM1-100109_512.npy\n","save file: ./data/processed/TM1-100090\n","audio mcep shape (36, 1024)\n","[207:648]svaing file: ./data/processed/TM1-100090_0.npy\n","[207:648]svaing file: ./data/processed/TM1-100090_512.npy\n","save file: ./data/processed/TM1-100093\n","audio mcep shape (36, 512)\n","[208:648]svaing file: ./data/processed/TM1-100093_0.npy\n","save file: ./data/processed/TM1-100013\n","audio mcep shape (36, 1024)\n","[209:648]svaing file: ./data/processed/TM1-100013_0.npy\n","[209:648]svaing file: ./data/processed/TM1-100013_512.npy\n","save file: ./data/processed/TM1-100009\n","audio mcep shape (36, 512)\n","[210:648]svaing file: ./data/processed/TM1-100009_0.npy\n","save file: ./data/processed/TM1-100146\n","audio mcep shape (36, 512)\n","[211:648]svaing file: ./data/processed/TM1-100146_0.npy\n","save file: ./data/processed/TM1-100010\n","audio mcep shape (36, 1024)\n","[212:648]svaing file: ./data/processed/TM1-100010_0.npy\n","[212:648]svaing file: ./data/processed/TM1-100010_512.npy\n","save file: ./data/processed/TM1-100135\n","audio mcep shape (36, 1024)\n","[213:648]svaing file: ./data/processed/TM1-100135_0.npy\n","[213:648]svaing file: ./data/processed/TM1-100135_512.npy\n","save file: ./data/processed/TM1-100113\n","audio mcep shape (36, 512)\n","[214:648]svaing file: ./data/processed/TM1-100113_0.npy\n","save file: ./data/processed/TM1-100071\n","audio mcep shape (36, 1024)\n","[215:648]svaing file: ./data/processed/TM1-100071_0.npy\n","[215:648]svaing file: ./data/processed/TM1-100071_512.npy\n","save file: ./data/processed/TM1-100154\n","audio mcep shape (36, 512)\n","[216:648]svaing file: ./data/processed/TM1-100154_0.npy\n","save file: ./data/processed/TM1-100044\n","audio mcep shape (36, 512)\n","[217:648]svaing file: ./data/processed/TM1-100044_0.npy\n","save file: ./data/processed/TM1-100063\n","audio mcep shape (36, 512)\n","[218:648]svaing file: ./data/processed/TM1-100063_0.npy\n","save file: ./data/processed/TM1-100040\n","audio mcep shape (36, 1024)\n","[219:648]svaing file: ./data/processed/TM1-100040_0.npy\n","[219:648]svaing file: ./data/processed/TM1-100040_512.npy\n","save file: ./data/processed/TM1-100029\n","audio mcep shape (36, 1024)\n","[220:648]svaing file: ./data/processed/TM1-100029_0.npy\n","[220:648]svaing file: ./data/processed/TM1-100029_512.npy\n","save file: ./data/processed/TM1-100143\n","audio mcep shape (36, 512)\n","[221:648]svaing file: ./data/processed/TM1-100143_0.npy\n","save file: ./data/processed/TM1-100050\n","audio mcep shape (36, 1024)\n","[222:648]svaing file: ./data/processed/TM1-100050_0.npy\n","[222:648]svaing file: ./data/processed/TM1-100050_512.npy\n","save file: ./data/processed/TM1-100012\n","audio mcep shape (36, 1024)\n","[223:648]svaing file: ./data/processed/TM1-100012_0.npy\n","[223:648]svaing file: ./data/processed/TM1-100012_512.npy\n","save file: ./data/processed/TM1-100049\n","audio mcep shape (36, 1024)\n","[224:648]svaing file: ./data/processed/TM1-100049_0.npy\n","[224:648]svaing file: ./data/processed/TM1-100049_512.npy\n","save file: ./data/processed/TM1-100148\n","audio mcep shape (36, 1536)\n","[225:648]svaing file: ./data/processed/TM1-100148_0.npy\n","[225:648]svaing file: ./data/processed/TM1-100148_512.npy\n","[225:648]svaing file: ./data/processed/TM1-100148_1024.npy\n","save file: ./data/processed/TM1-100061\n","audio mcep shape (36, 1024)\n","[226:648]svaing file: ./data/processed/TM1-100061_0.npy\n","[226:648]svaing file: ./data/processed/TM1-100061_512.npy\n","save file: ./data/processed/TM1-100055\n","audio mcep shape (36, 512)\n","[227:648]svaing file: ./data/processed/TM1-100055_0.npy\n","save file: ./data/processed/TM1-100025\n","audio mcep shape (36, 1536)\n","[228:648]svaing file: ./data/processed/TM1-100025_0.npy\n","[228:648]svaing file: ./data/processed/TM1-100025_512.npy\n","[228:648]svaing file: ./data/processed/TM1-100025_1024.npy\n","save file: ./data/processed/TM1-100017\n","audio mcep shape (36, 1024)\n","[229:648]svaing file: ./data/processed/TM1-100017_0.npy\n","[229:648]svaing file: ./data/processed/TM1-100017_512.npy\n","save file: ./data/processed/TM1-100030\n","audio mcep shape (36, 1024)\n","[230:648]svaing file: ./data/processed/TM1-100030_0.npy\n","[230:648]svaing file: ./data/processed/TM1-100030_512.npy\n","save file: ./data/processed/TM1-100064\n","audio mcep shape (36, 512)\n","[231:648]svaing file: ./data/processed/TM1-100064_0.npy\n","save file: ./data/processed/TM1-100092\n","audio mcep shape (36, 1024)\n","[232:648]svaing file: ./data/processed/TM1-100092_0.npy\n","[232:648]svaing file: ./data/processed/TM1-100092_512.npy\n","save file: ./data/processed/TM1-100060\n","audio mcep shape (36, 512)\n","[233:648]svaing file: ./data/processed/TM1-100060_0.npy\n","save file: ./data/processed/TM1-100162\n","audio mcep shape (36, 1024)\n","[234:648]svaing file: ./data/processed/TM1-100162_0.npy\n","[234:648]svaing file: ./data/processed/TM1-100162_512.npy\n","save file: ./data/processed/TM1-100004\n","audio mcep shape (36, 1024)\n","[235:648]svaing file: ./data/processed/TM1-100004_0.npy\n","[235:648]svaing file: ./data/processed/TM1-100004_512.npy\n","save file: ./data/processed/TM1-100033\n","audio mcep shape (36, 1024)\n","[236:648]svaing file: ./data/processed/TM1-100033_0.npy\n","[236:648]svaing file: ./data/processed/TM1-100033_512.npy\n","save file: ./data/processed/TM1-100144\n","audio mcep shape (36, 1024)\n","[237:648]svaing file: ./data/processed/TM1-100144_0.npy\n","[237:648]svaing file: ./data/processed/TM1-100144_512.npy\n","save file: ./data/processed/TM1-100065\n","audio mcep shape (36, 1024)\n","[238:648]svaing file: ./data/processed/TM1-100065_0.npy\n","[238:648]svaing file: ./data/processed/TM1-100065_512.npy\n","save file: ./data/processed/TM1-100140\n","audio mcep shape (36, 512)\n","[239:648]svaing file: ./data/processed/TM1-100140_0.npy\n","save file: ./data/processed/TM1-100027\n","audio mcep shape (36, 1536)\n","[240:648]svaing file: ./data/processed/TM1-100027_0.npy\n","[240:648]svaing file: ./data/processed/TM1-100027_512.npy\n","[240:648]svaing file: ./data/processed/TM1-100027_1024.npy\n","save file: ./data/processed/TM1-100078\n","audio mcep shape (36, 1024)\n","[241:648]svaing file: ./data/processed/TM1-100078_0.npy\n","[241:648]svaing file: ./data/processed/TM1-100078_512.npy\n","save file: ./data/processed/TM1-100155\n","audio mcep shape (36, 1536)\n","[242:648]svaing file: ./data/processed/TM1-100155_0.npy\n","[242:648]svaing file: ./data/processed/TM1-100155_512.npy\n","[242:648]svaing file: ./data/processed/TM1-100155_1024.npy\n","save file: ./data/processed/TM1-100011\n","audio mcep shape (36, 1024)\n","[243:648]svaing file: ./data/processed/TM1-100011_0.npy\n","[243:648]svaing file: ./data/processed/TM1-100011_512.npy\n","save file: ./data/processed/TM1-100019\n","audio mcep shape (36, 512)\n","[244:648]svaing file: ./data/processed/TM1-100019_0.npy\n","save file: ./data/processed/TM1-100104\n","audio mcep shape (36, 512)\n","[245:648]svaing file: ./data/processed/TM1-100104_0.npy\n","save file: ./data/processed/TM1-100038\n","audio mcep shape (36, 1024)\n","[246:648]svaing file: ./data/processed/TM1-100038_0.npy\n","[246:648]svaing file: ./data/processed/TM1-100038_512.npy\n","save file: ./data/processed/TM1-100043\n","audio mcep shape (36, 512)\n","[247:648]svaing file: ./data/processed/TM1-100043_0.npy\n","save file: ./data/processed/TM1-100075\n","audio mcep shape (36, 1024)\n","[248:648]svaing file: ./data/processed/TM1-100075_0.npy\n","[248:648]svaing file: ./data/processed/TM1-100075_512.npy\n","save file: ./data/processed/TM1-100152\n","audio mcep shape (36, 1024)\n","[249:648]svaing file: ./data/processed/TM1-100152_0.npy\n","[249:648]svaing file: ./data/processed/TM1-100152_512.npy\n","save file: ./data/processed/TM1-100108\n","audio mcep shape (36, 1024)\n","[250:648]svaing file: ./data/processed/TM1-100108_0.npy\n","[250:648]svaing file: ./data/processed/TM1-100108_512.npy\n","save file: ./data/processed/TM1-100101\n","audio mcep shape (36, 1024)\n","[251:648]svaing file: ./data/processed/TM1-100101_0.npy\n","[251:648]svaing file: ./data/processed/TM1-100101_512.npy\n","save file: ./data/processed/TM1-100031\n","audio mcep shape (36, 512)\n","[252:648]svaing file: ./data/processed/TM1-100031_0.npy\n","save file: ./data/processed/TM1-100114\n","audio mcep shape (36, 1536)\n","[253:648]svaing file: ./data/processed/TM1-100114_0.npy\n","[253:648]svaing file: ./data/processed/TM1-100114_512.npy\n","[253:648]svaing file: ./data/processed/TM1-100114_1024.npy\n","save file: ./data/processed/TM1-100123\n","audio mcep shape (36, 1024)\n","[254:648]svaing file: ./data/processed/TM1-100123_0.npy\n","[254:648]svaing file: ./data/processed/TM1-100123_512.npy\n","save file: ./data/processed/TM1-100034\n","audio mcep shape (36, 1536)\n","[255:648]svaing file: ./data/processed/TM1-100034_0.npy\n","[255:648]svaing file: ./data/processed/TM1-100034_512.npy\n","[255:648]svaing file: ./data/processed/TM1-100034_1024.npy\n","save file: ./data/processed/TM1-100145\n","audio mcep shape (36, 512)\n","[256:648]svaing file: ./data/processed/TM1-100145_0.npy\n","save file: ./data/processed/TM1-100020\n","audio mcep shape (36, 1024)\n","[257:648]svaing file: ./data/processed/TM1-100020_0.npy\n","[257:648]svaing file: ./data/processed/TM1-100020_512.npy\n","save file: ./data/processed/TM1-100037\n","audio mcep shape (36, 512)\n","[258:648]svaing file: ./data/processed/TM1-100037_0.npy\n","save file: ./data/processed/TM1-100158\n","audio mcep shape (36, 512)\n","[259:648]svaing file: ./data/processed/TM1-100158_0.npy\n","save file: ./data/processed/TM1-100070\n","audio mcep shape (36, 1536)\n","[260:648]svaing file: ./data/processed/TM1-100070_0.npy\n","[260:648]svaing file: ./data/processed/TM1-100070_512.npy\n","[260:648]svaing file: ./data/processed/TM1-100070_1024.npy\n","save file: ./data/processed/TM1-100062\n","audio mcep shape (36, 1024)\n","[261:648]svaing file: ./data/processed/TM1-100062_0.npy\n","[261:648]svaing file: ./data/processed/TM1-100062_512.npy\n","save file: ./data/processed/TM1-100045\n","audio mcep shape (36, 1024)\n","[262:648]svaing file: ./data/processed/TM1-100045_0.npy\n","[262:648]svaing file: ./data/processed/TM1-100045_512.npy\n","save file: ./data/processed/TM1-100121\n","audio mcep shape (36, 1024)\n","[263:648]svaing file: ./data/processed/TM1-100121_0.npy\n","[263:648]svaing file: ./data/processed/TM1-100121_512.npy\n","save file: ./data/processed/TM1-100089\n","audio mcep shape (36, 512)\n","[264:648]svaing file: ./data/processed/TM1-100089_0.npy\n","save file: ./data/processed/TM1-100117\n","audio mcep shape (36, 512)\n","[265:648]svaing file: ./data/processed/TM1-100117_0.npy\n","save file: ./data/processed/TM1-100156\n","audio mcep shape (36, 512)\n","[266:648]svaing file: ./data/processed/TM1-100156_0.npy\n","save file: ./data/processed/TM1-100094\n","audio mcep shape (36, 1024)\n","[267:648]svaing file: ./data/processed/TM1-100094_0.npy\n","[267:648]svaing file: ./data/processed/TM1-100094_512.npy\n","save file: ./data/processed/TM1-100059\n","audio mcep shape (36, 1024)\n","[268:648]svaing file: ./data/processed/TM1-100059_0.npy\n","[268:648]svaing file: ./data/processed/TM1-100059_512.npy\n","save file: ./data/processed/TM1-100110\n","audio mcep shape (36, 1024)\n","[269:648]svaing file: ./data/processed/TM1-100110_0.npy\n","[269:648]svaing file: ./data/processed/TM1-100110_512.npy\n","save file: ./data/processed/TM1-100126\n","audio mcep shape (36, 512)\n","[270:648]svaing file: ./data/processed/TM1-100126_0.npy\n","save file: ./data/processed/TM1-100002\n","audio mcep shape (36, 512)\n","[271:648]svaing file: ./data/processed/TM1-100002_0.npy\n","save file: ./data/processed/TM1-100153\n","audio mcep shape (36, 512)\n","[272:648]svaing file: ./data/processed/TM1-100153_0.npy\n","save file: ./data/processed/TM1-100041\n","audio mcep shape (36, 512)\n","[273:648]svaing file: ./data/processed/TM1-100041_0.npy\n","save file: ./data/processed/TM1-100085\n","audio mcep shape (36, 1024)\n","[274:648]svaing file: ./data/processed/TM1-100085_0.npy\n","[274:648]svaing file: ./data/processed/TM1-100085_512.npy\n","save file: ./data/processed/TM1-100021\n","audio mcep shape (36, 2048)\n","[275:648]svaing file: ./data/processed/TM1-100021_0.npy\n","[275:648]svaing file: ./data/processed/TM1-100021_512.npy\n","[275:648]svaing file: ./data/processed/TM1-100021_1024.npy\n","[275:648]svaing file: ./data/processed/TM1-100021_1536.npy\n","save file: ./data/processed/TM1-100082\n","audio mcep shape (36, 512)\n","[276:648]svaing file: ./data/processed/TM1-100082_0.npy\n","save file: ./data/processed/TM1-100039\n","audio mcep shape (36, 1024)\n","[277:648]svaing file: ./data/processed/TM1-100039_0.npy\n","[277:648]svaing file: ./data/processed/TM1-100039_512.npy\n","save file: ./data/processed/TM1-100116\n","audio mcep shape (36, 512)\n","[278:648]svaing file: ./data/processed/TM1-100116_0.npy\n","save file: ./data/processed/TM1-100007\n","audio mcep shape (36, 1024)\n","[279:648]svaing file: ./data/processed/TM1-100007_0.npy\n","[279:648]svaing file: ./data/processed/TM1-100007_512.npy\n","save file: ./data/processed/TM1-100133\n","audio mcep shape (36, 1536)\n","[280:648]svaing file: ./data/processed/TM1-100133_0.npy\n","[280:648]svaing file: ./data/processed/TM1-100133_512.npy\n","[280:648]svaing file: ./data/processed/TM1-100133_1024.npy\n","save file: ./data/processed/TM1-100022\n","audio mcep shape (36, 2048)\n","[281:648]svaing file: ./data/processed/TM1-100022_0.npy\n","[281:648]svaing file: ./data/processed/TM1-100022_512.npy\n","[281:648]svaing file: ./data/processed/TM1-100022_1024.npy\n","[281:648]svaing file: ./data/processed/TM1-100022_1536.npy\n","save file: ./data/processed/TM1-100150\n","audio mcep shape (36, 512)\n","[282:648]svaing file: ./data/processed/TM1-100150_0.npy\n","save file: ./data/processed/TM1-100023\n","audio mcep shape (36, 512)\n","[283:648]svaing file: ./data/processed/TM1-100023_0.npy\n","save file: ./data/processed/TM1-100036\n","audio mcep shape (36, 512)\n","[284:648]svaing file: ./data/processed/TM1-100036_0.npy\n","save file: ./data/processed/TM1-100107\n","audio mcep shape (36, 1024)\n","[285:648]svaing file: ./data/processed/TM1-100107_0.npy\n","[285:648]svaing file: ./data/processed/TM1-100107_512.npy\n","save file: ./data/processed/TM1-100151\n","audio mcep shape (36, 1024)\n","[286:648]svaing file: ./data/processed/TM1-100151_0.npy\n","[286:648]svaing file: ./data/processed/TM1-100151_512.npy\n","save file: ./data/processed/TM1-100058\n","audio mcep shape (36, 1024)\n","[287:648]svaing file: ./data/processed/TM1-100058_0.npy\n","[287:648]svaing file: ./data/processed/TM1-100058_512.npy\n","save file: ./data/processed/TM1-100048\n","audio mcep shape (36, 1024)\n","[288:648]svaing file: ./data/processed/TM1-100048_0.npy\n","[288:648]svaing file: ./data/processed/TM1-100048_512.npy\n","save file: ./data/processed/TM1-100139\n","audio mcep shape (36, 512)\n","[289:648]svaing file: ./data/processed/TM1-100139_0.npy\n","save file: ./data/processed/TM1-100051\n","audio mcep shape (36, 1024)\n","[290:648]svaing file: ./data/processed/TM1-100051_0.npy\n","[290:648]svaing file: ./data/processed/TM1-100051_512.npy\n","save file: ./data/processed/TM1-100105\n","audio mcep shape (36, 1536)\n","[291:648]svaing file: ./data/processed/TM1-100105_0.npy\n","[291:648]svaing file: ./data/processed/TM1-100105_512.npy\n","[291:648]svaing file: ./data/processed/TM1-100105_1024.npy\n","save file: ./data/processed/TM1-100014\n","audio mcep shape (36, 1024)\n","[292:648]svaing file: ./data/processed/TM1-100014_0.npy\n","[292:648]svaing file: ./data/processed/TM1-100014_512.npy\n","save file: ./data/processed/TM1-100136\n","audio mcep shape (36, 1536)\n","[293:648]svaing file: ./data/processed/TM1-100136_0.npy\n","[293:648]svaing file: ./data/processed/TM1-100136_512.npy\n","[293:648]svaing file: ./data/processed/TM1-100136_1024.npy\n","save file: ./data/processed/TM1-100106\n","audio mcep shape (36, 512)\n","[294:648]svaing file: ./data/processed/TM1-100106_0.npy\n","save file: ./data/processed/TM1-100099\n","audio mcep shape (36, 1024)\n","[295:648]svaing file: ./data/processed/TM1-100099_0.npy\n","[295:648]svaing file: ./data/processed/TM1-100099_512.npy\n","save file: ./data/processed/TM1-100083\n","audio mcep shape (36, 1024)\n","[296:648]svaing file: ./data/processed/TM1-100083_0.npy\n","[296:648]svaing file: ./data/processed/TM1-100083_512.npy\n","save file: ./data/processed/TM1-100067\n","audio mcep shape (36, 1024)\n","[297:648]svaing file: ./data/processed/TM1-100067_0.npy\n","[297:648]svaing file: ./data/processed/TM1-100067_512.npy\n","save file: ./data/processed/TM1-100053\n","audio mcep shape (36, 512)\n","[298:648]svaing file: ./data/processed/TM1-100053_0.npy\n","save file: ./data/processed/TM1-100005\n","audio mcep shape (36, 1024)\n","[299:648]svaing file: ./data/processed/TM1-100005_0.npy\n","[299:648]svaing file: ./data/processed/TM1-100005_512.npy\n","save file: ./data/processed/TM1-100159\n","audio mcep shape (36, 1024)\n","[300:648]svaing file: ./data/processed/TM1-100159_0.npy\n","[300:648]svaing file: ./data/processed/TM1-100159_512.npy\n","save file: ./data/processed/TM1-100137\n","audio mcep shape (36, 1024)\n","[301:648]svaing file: ./data/processed/TM1-100137_0.npy\n","[301:648]svaing file: ./data/processed/TM1-100137_512.npy\n","save file: ./data/processed/TM1-100122\n","audio mcep shape (36, 1024)\n","[302:648]svaing file: ./data/processed/TM1-100122_0.npy\n","[302:648]svaing file: ./data/processed/TM1-100122_512.npy\n","save file: ./data/processed/TM1-100081\n","audio mcep shape (36, 1536)\n","[303:648]svaing file: ./data/processed/TM1-100081_0.npy\n","[303:648]svaing file: ./data/processed/TM1-100081_512.npy\n","[303:648]svaing file: ./data/processed/TM1-100081_1024.npy\n","save file: ./data/processed/TM1-100003\n","audio mcep shape (36, 512)\n","[304:648]svaing file: ./data/processed/TM1-100003_0.npy\n","save file: ./data/processed/TM1-100157\n","audio mcep shape (36, 1024)\n","[305:648]svaing file: ./data/processed/TM1-100157_0.npy\n","[305:648]svaing file: ./data/processed/TM1-100157_512.npy\n","save file: ./data/processed/TM1-100054\n","audio mcep shape (36, 1024)\n","[306:648]svaing file: ./data/processed/TM1-100054_0.npy\n","[306:648]svaing file: ./data/processed/TM1-100054_512.npy\n","save file: ./data/processed/TM1-100141\n","audio mcep shape (36, 512)\n","[307:648]svaing file: ./data/processed/TM1-100141_0.npy\n","save file: ./data/processed/TM1-100024\n","audio mcep shape (36, 1024)\n","[308:648]svaing file: ./data/processed/TM1-100024_0.npy\n","[308:648]svaing file: ./data/processed/TM1-100024_512.npy\n","save file: ./data/processed/TM1-100147\n","audio mcep shape (36, 1024)\n","[309:648]svaing file: ./data/processed/TM1-100147_0.npy\n","[309:648]svaing file: ./data/processed/TM1-100147_512.npy\n","save file: ./data/processed/TM1-100091\n","audio mcep shape (36, 1024)\n","[310:648]svaing file: ./data/processed/TM1-100091_0.npy\n","[310:648]svaing file: ./data/processed/TM1-100091_512.npy\n","save file: ./data/processed/TM1-100087\n","audio mcep shape (36, 1024)\n","[311:648]svaing file: ./data/processed/TM1-100087_0.npy\n","[311:648]svaing file: ./data/processed/TM1-100087_512.npy\n","save file: ./data/processed/TM1-100072\n","audio mcep shape (36, 1024)\n","[312:648]svaing file: ./data/processed/TM1-100072_0.npy\n","[312:648]svaing file: ./data/processed/TM1-100072_512.npy\n","save file: ./data/processed/TM1-100074\n","audio mcep shape (36, 1024)\n","[313:648]svaing file: ./data/processed/TM1-100074_0.npy\n","[313:648]svaing file: ./data/processed/TM1-100074_512.npy\n","save file: ./data/processed/TM1-100118\n","audio mcep shape (36, 1536)\n","[314:648]svaing file: ./data/processed/TM1-100118_0.npy\n","[314:648]svaing file: ./data/processed/TM1-100118_512.npy\n","[314:648]svaing file: ./data/processed/TM1-100118_1024.npy\n","save file: ./data/processed/TM1-100047\n","audio mcep shape (36, 1024)\n","[315:648]svaing file: ./data/processed/TM1-100047_0.npy\n","[315:648]svaing file: ./data/processed/TM1-100047_512.npy\n","save file: ./data/processed/TM1-100015\n","audio mcep shape (36, 512)\n","[316:648]svaing file: ./data/processed/TM1-100015_0.npy\n","save file: ./data/processed/TM1-100097\n","audio mcep shape (36, 512)\n","[317:648]svaing file: ./data/processed/TM1-100097_0.npy\n","save file: ./data/processed/TM1-100124\n","audio mcep shape (36, 512)\n","[318:648]svaing file: ./data/processed/TM1-100124_0.npy\n","save file: ./data/processed/TM1-100120\n","audio mcep shape (36, 1024)\n","[319:648]svaing file: ./data/processed/TM1-100120_0.npy\n","[319:648]svaing file: ./data/processed/TM1-100120_512.npy\n","save file: ./data/processed/TM1-100102\n","audio mcep shape (36, 1024)\n","[320:648]svaing file: ./data/processed/TM1-100102_0.npy\n","[320:648]svaing file: ./data/processed/TM1-100102_512.npy\n","save file: ./data/processed/TM1-100086\n","audio mcep shape (36, 512)\n","[321:648]svaing file: ./data/processed/TM1-100086_0.npy\n","save file: ./data/processed/TM1-100125\n","audio mcep shape (36, 2048)\n","[322:648]svaing file: ./data/processed/TM1-100125_0.npy\n","[322:648]svaing file: ./data/processed/TM1-100125_512.npy\n","[322:648]svaing file: ./data/processed/TM1-100125_1024.npy\n","[322:648]svaing file: ./data/processed/TM1-100125_1536.npy\n","save file: ./data/processed/TM1-100035\n","audio mcep shape (36, 512)\n","[323:648]svaing file: ./data/processed/TM1-100035_0.npy\n","save file: ./data/processed/TM1-100088\n","audio mcep shape (36, 1024)\n","[324:648]svaing file: ./data/processed/TM1-100088_0.npy\n","[324:648]svaing file: ./data/processed/TM1-100088_512.npy\n","save file: ./data/processed/SF2-100048\n","audio mcep shape (36, 1024)\n","[325:648]svaing file: ./data/processed/SF2-100048_0.npy\n","[325:648]svaing file: ./data/processed/SF2-100048_512.npy\n","save file: ./data/processed/SF2-100080\n","audio mcep shape (36, 1024)\n","[326:648]svaing file: ./data/processed/SF2-100080_0.npy\n","[326:648]svaing file: ./data/processed/SF2-100080_512.npy\n","save file: ./data/processed/SF2-100149\n","audio mcep shape (36, 1536)\n","[327:648]svaing file: ./data/processed/SF2-100149_0.npy\n","[327:648]svaing file: ./data/processed/SF2-100149_512.npy\n","[327:648]svaing file: ./data/processed/SF2-100149_1024.npy\n","save file: ./data/processed/SF2-100022\n","audio mcep shape (36, 2048)\n","[328:648]svaing file: ./data/processed/SF2-100022_0.npy\n","[328:648]svaing file: ./data/processed/SF2-100022_512.npy\n","[328:648]svaing file: ./data/processed/SF2-100022_1024.npy\n","[328:648]svaing file: ./data/processed/SF2-100022_1536.npy\n","save file: ./data/processed/SF2-100154\n","audio mcep shape (36, 512)\n","[329:648]svaing file: ./data/processed/SF2-100154_0.npy\n","save file: ./data/processed/SF2-100026\n","audio mcep shape (36, 1024)\n","[330:648]svaing file: ./data/processed/SF2-100026_0.npy\n","[330:648]svaing file: ./data/processed/SF2-100026_512.npy\n","save file: ./data/processed/SF2-100012\n","audio mcep shape (36, 1536)\n","[331:648]svaing file: ./data/processed/SF2-100012_0.npy\n","[331:648]svaing file: ./data/processed/SF2-100012_512.npy\n","[331:648]svaing file: ./data/processed/SF2-100012_1024.npy\n","save file: ./data/processed/SF2-100111\n","audio mcep shape (36, 1536)\n","[332:648]svaing file: ./data/processed/SF2-100111_0.npy\n","[332:648]svaing file: ./data/processed/SF2-100111_512.npy\n","[332:648]svaing file: ./data/processed/SF2-100111_1024.npy\n","save file: ./data/processed/SF2-100002\n","audio mcep shape (36, 512)\n","[333:648]svaing file: ./data/processed/SF2-100002_0.npy\n","save file: ./data/processed/SF2-100140\n","audio mcep shape (36, 512)\n","[334:648]svaing file: ./data/processed/SF2-100140_0.npy\n","save file: ./data/processed/SF2-100050\n","audio mcep shape (36, 1024)\n","[335:648]svaing file: ./data/processed/SF2-100050_0.npy\n","[335:648]svaing file: ./data/processed/SF2-100050_512.npy\n","save file: ./data/processed/SF2-100102\n","audio mcep shape (36, 1024)\n","[336:648]svaing file: ./data/processed/SF2-100102_0.npy\n","[336:648]svaing file: ./data/processed/SF2-100102_512.npy\n","save file: ./data/processed/SF2-100138\n","audio mcep shape (36, 1024)\n","[337:648]svaing file: ./data/processed/SF2-100138_0.npy\n","[337:648]svaing file: ./data/processed/SF2-100138_512.npy\n","save file: ./data/processed/SF2-100028\n","audio mcep shape (36, 512)\n","[338:648]svaing file: ./data/processed/SF2-100028_0.npy\n","save file: ./data/processed/SF2-100023\n","audio mcep shape (36, 512)\n","[339:648]svaing file: ./data/processed/SF2-100023_0.npy\n","save file: ./data/processed/SF2-100105\n","audio mcep shape (36, 1536)\n","[340:648]svaing file: ./data/processed/SF2-100105_0.npy\n","[340:648]svaing file: ./data/processed/SF2-100105_512.npy\n","[340:648]svaing file: ./data/processed/SF2-100105_1024.npy\n","save file: ./data/processed/SF2-100016\n","audio mcep shape (36, 1024)\n","[341:648]svaing file: ./data/processed/SF2-100016_0.npy\n","[341:648]svaing file: ./data/processed/SF2-100016_512.npy\n","save file: ./data/processed/SF2-100160\n","audio mcep shape (36, 1536)\n","[342:648]svaing file: ./data/processed/SF2-100160_0.npy\n","[342:648]svaing file: ./data/processed/SF2-100160_512.npy\n","[342:648]svaing file: ./data/processed/SF2-100160_1024.npy\n","save file: ./data/processed/SF2-100100\n","audio mcep shape (36, 512)\n","[343:648]svaing file: ./data/processed/SF2-100100_0.npy\n","save file: ./data/processed/SF2-100020\n","audio mcep shape (36, 512)\n","[344:648]svaing file: ./data/processed/SF2-100020_0.npy\n","save file: ./data/processed/SF2-100086\n","audio mcep shape (36, 512)\n","[345:648]svaing file: ./data/processed/SF2-100086_0.npy\n","save file: ./data/processed/SF2-100041\n","audio mcep shape (36, 512)\n","[346:648]svaing file: ./data/processed/SF2-100041_0.npy\n","save file: ./data/processed/SF2-100128\n","audio mcep shape (36, 512)\n","[347:648]svaing file: ./data/processed/SF2-100128_0.npy\n","save file: ./data/processed/SF2-100008\n","audio mcep shape (36, 2048)\n","[348:648]svaing file: ./data/processed/SF2-100008_0.npy\n","[348:648]svaing file: ./data/processed/SF2-100008_512.npy\n","[348:648]svaing file: ./data/processed/SF2-100008_1024.npy\n","[348:648]svaing file: ./data/processed/SF2-100008_1536.npy\n","save file: ./data/processed/SF2-100131\n","audio mcep shape (36, 1024)\n","[349:648]svaing file: ./data/processed/SF2-100131_0.npy\n","[349:648]svaing file: ./data/processed/SF2-100131_512.npy\n","save file: ./data/processed/SF2-100095\n","audio mcep shape (36, 1024)\n","[350:648]svaing file: ./data/processed/SF2-100095_0.npy\n","[350:648]svaing file: ./data/processed/SF2-100095_512.npy\n","save file: ./data/processed/SF2-100117\n","audio mcep shape (36, 512)\n","[351:648]svaing file: ./data/processed/SF2-100117_0.npy\n","save file: ./data/processed/SF2-100133\n","audio mcep shape (36, 1536)\n","[352:648]svaing file: ./data/processed/SF2-100133_0.npy\n","[352:648]svaing file: ./data/processed/SF2-100133_512.npy\n","[352:648]svaing file: ./data/processed/SF2-100133_1024.npy\n","save file: ./data/processed/SF2-100097\n","audio mcep shape (36, 512)\n","[353:648]svaing file: ./data/processed/SF2-100097_0.npy\n","save file: ./data/processed/SF2-100021\n","audio mcep shape (36, 2048)\n","[354:648]svaing file: ./data/processed/SF2-100021_0.npy\n","[354:648]svaing file: ./data/processed/SF2-100021_512.npy\n","[354:648]svaing file: ./data/processed/SF2-100021_1024.npy\n","[354:648]svaing file: ./data/processed/SF2-100021_1536.npy\n","save file: ./data/processed/SF2-100047\n","audio mcep shape (36, 1024)\n","[355:648]svaing file: ./data/processed/SF2-100047_0.npy\n","[355:648]svaing file: ./data/processed/SF2-100047_512.npy\n","save file: ./data/processed/SF2-100010\n","audio mcep shape (36, 1024)\n","[356:648]svaing file: ./data/processed/SF2-100010_0.npy\n","[356:648]svaing file: ./data/processed/SF2-100010_512.npy\n","save file: ./data/processed/SF2-100001\n","audio mcep shape (36, 1024)\n","[357:648]svaing file: ./data/processed/SF2-100001_0.npy\n","[357:648]svaing file: ./data/processed/SF2-100001_512.npy\n","save file: ./data/processed/SF2-100019\n","audio mcep shape (36, 1024)\n","[358:648]svaing file: ./data/processed/SF2-100019_0.npy\n","[358:648]svaing file: ./data/processed/SF2-100019_512.npy\n","save file: ./data/processed/SF2-100141\n","audio mcep shape (36, 512)\n","[359:648]svaing file: ./data/processed/SF2-100141_0.npy\n","save file: ./data/processed/SF2-100152\n","audio mcep shape (36, 1536)\n","[360:648]svaing file: ./data/processed/SF2-100152_0.npy\n","[360:648]svaing file: ./data/processed/SF2-100152_512.npy\n","[360:648]svaing file: ./data/processed/SF2-100152_1024.npy\n","save file: ./data/processed/SF2-100071\n","audio mcep shape (36, 1024)\n","[361:648]svaing file: ./data/processed/SF2-100071_0.npy\n","[361:648]svaing file: ./data/processed/SF2-100071_512.npy\n","save file: ./data/processed/SF2-100076\n","audio mcep shape (36, 512)\n","[362:648]svaing file: ./data/processed/SF2-100076_0.npy\n","save file: ./data/processed/SF2-100031\n","audio mcep shape (36, 512)\n","[363:648]svaing file: ./data/processed/SF2-100031_0.npy\n","save file: ./data/processed/SF2-100081\n","audio mcep shape (36, 1536)\n","[364:648]svaing file: ./data/processed/SF2-100081_0.npy\n","[364:648]svaing file: ./data/processed/SF2-100081_512.npy\n","[364:648]svaing file: ./data/processed/SF2-100081_1024.npy\n","save file: ./data/processed/SF2-100101\n","audio mcep shape (36, 1024)\n","[365:648]svaing file: ./data/processed/SF2-100101_0.npy\n","[365:648]svaing file: ./data/processed/SF2-100101_512.npy\n","save file: ./data/processed/SF2-100120\n","audio mcep shape (36, 1024)\n","[366:648]svaing file: ./data/processed/SF2-100120_0.npy\n","[366:648]svaing file: ./data/processed/SF2-100120_512.npy\n","save file: ./data/processed/SF2-100096\n","audio mcep shape (36, 2048)\n","[367:648]svaing file: ./data/processed/SF2-100096_0.npy\n","[367:648]svaing file: ./data/processed/SF2-100096_512.npy\n","[367:648]svaing file: ./data/processed/SF2-100096_1024.npy\n","[367:648]svaing file: ./data/processed/SF2-100096_1536.npy\n","save file: ./data/processed/SF2-100148\n","audio mcep shape (36, 1536)\n","[368:648]svaing file: ./data/processed/SF2-100148_0.npy\n","[368:648]svaing file: ./data/processed/SF2-100148_512.npy\n","[368:648]svaing file: ./data/processed/SF2-100148_1024.npy\n","save file: ./data/processed/SF2-100017\n","audio mcep shape (36, 1024)\n","[369:648]svaing file: ./data/processed/SF2-100017_0.npy\n","[369:648]svaing file: ./data/processed/SF2-100017_512.npy\n","save file: ./data/processed/SF2-100094\n","audio mcep shape (36, 1024)\n","[370:648]svaing file: ./data/processed/SF2-100094_0.npy\n","[370:648]svaing file: ./data/processed/SF2-100094_512.npy\n","save file: ./data/processed/SF2-100157\n","audio mcep shape (36, 1024)\n","[371:648]svaing file: ./data/processed/SF2-100157_0.npy\n","[371:648]svaing file: ./data/processed/SF2-100157_512.npy\n","save file: ./data/processed/SF2-100137\n","audio mcep shape (36, 1024)\n","[372:648]svaing file: ./data/processed/SF2-100137_0.npy\n","[372:648]svaing file: ./data/processed/SF2-100137_512.npy\n","save file: ./data/processed/SF2-100063\n","audio mcep shape (36, 1024)\n","[373:648]svaing file: ./data/processed/SF2-100063_0.npy\n","[373:648]svaing file: ./data/processed/SF2-100063_512.npy\n","save file: ./data/processed/SF2-100088\n","audio mcep shape (36, 1536)\n","[374:648]svaing file: ./data/processed/SF2-100088_0.npy\n","[374:648]svaing file: ./data/processed/SF2-100088_512.npy\n","[374:648]svaing file: ./data/processed/SF2-100088_1024.npy\n","save file: ./data/processed/SF2-100004\n","audio mcep shape (36, 1024)\n","[375:648]svaing file: ./data/processed/SF2-100004_0.npy\n","[375:648]svaing file: ./data/processed/SF2-100004_512.npy\n","save file: ./data/processed/SF2-100006\n","audio mcep shape (36, 1024)\n","[376:648]svaing file: ./data/processed/SF2-100006_0.npy\n","[376:648]svaing file: ./data/processed/SF2-100006_512.npy\n","save file: ./data/processed/SF2-100114\n","audio mcep shape (36, 1536)\n","[377:648]svaing file: ./data/processed/SF2-100114_0.npy\n","[377:648]svaing file: ./data/processed/SF2-100114_512.npy\n","[377:648]svaing file: ./data/processed/SF2-100114_1024.npy\n","save file: ./data/processed/SF2-100029\n","audio mcep shape (36, 1024)\n","[378:648]svaing file: ./data/processed/SF2-100029_0.npy\n","[378:648]svaing file: ./data/processed/SF2-100029_512.npy\n","save file: ./data/processed/SF2-100014\n","audio mcep shape (36, 1024)\n","[379:648]svaing file: ./data/processed/SF2-100014_0.npy\n","[379:648]svaing file: ./data/processed/SF2-100014_512.npy\n","save file: ./data/processed/SF2-100070\n","audio mcep shape (36, 1536)\n","[380:648]svaing file: ./data/processed/SF2-100070_0.npy\n","[380:648]svaing file: ./data/processed/SF2-100070_512.npy\n","[380:648]svaing file: ./data/processed/SF2-100070_1024.npy\n","save file: ./data/processed/SF2-100127\n","audio mcep shape (36, 1024)\n","[381:648]svaing file: ./data/processed/SF2-100127_0.npy\n","[381:648]svaing file: ./data/processed/SF2-100127_512.npy\n","save file: ./data/processed/SF2-100155\n","audio mcep shape (36, 1536)\n","[382:648]svaing file: ./data/processed/SF2-100155_0.npy\n","[382:648]svaing file: ./data/processed/SF2-100155_512.npy\n","[382:648]svaing file: ./data/processed/SF2-100155_1024.npy\n","save file: ./data/processed/SF2-100059\n","audio mcep shape (36, 1024)\n","[383:648]svaing file: ./data/processed/SF2-100059_0.npy\n","[383:648]svaing file: ./data/processed/SF2-100059_512.npy\n","save file: ./data/processed/SF2-100024\n","audio mcep shape (36, 1024)\n","[384:648]svaing file: ./data/processed/SF2-100024_0.npy\n","[384:648]svaing file: ./data/processed/SF2-100024_512.npy\n","save file: ./data/processed/SF2-100129\n","audio mcep shape (36, 512)\n","[385:648]svaing file: ./data/processed/SF2-100129_0.npy\n","save file: ./data/processed/SF2-100142\n","audio mcep shape (36, 1536)\n","[386:648]svaing file: ./data/processed/SF2-100142_0.npy\n","[386:648]svaing file: ./data/processed/SF2-100142_512.npy\n","[386:648]svaing file: ./data/processed/SF2-100142_1024.npy\n","save file: ./data/processed/SF2-100037\n","audio mcep shape (36, 512)\n","[387:648]svaing file: ./data/processed/SF2-100037_0.npy\n","save file: ./data/processed/SF2-100135\n","audio mcep shape (36, 1024)\n","[388:648]svaing file: ./data/processed/SF2-100135_0.npy\n","[388:648]svaing file: ./data/processed/SF2-100135_512.npy\n","save file: ./data/processed/SF2-100159\n","audio mcep shape (36, 512)\n","[389:648]svaing file: ./data/processed/SF2-100159_0.npy\n","save file: ./data/processed/SF2-100106\n","audio mcep shape (36, 1024)\n","[390:648]svaing file: ./data/processed/SF2-100106_0.npy\n","[390:648]svaing file: ./data/processed/SF2-100106_512.npy\n","save file: ./data/processed/SF2-100139\n","audio mcep shape (36, 1024)\n","[391:648]svaing file: ./data/processed/SF2-100139_0.npy\n","[391:648]svaing file: ./data/processed/SF2-100139_512.npy\n","save file: ./data/processed/SF2-100035\n","audio mcep shape (36, 512)\n","[392:648]svaing file: ./data/processed/SF2-100035_0.npy\n","save file: ./data/processed/SF2-100146\n","audio mcep shape (36, 512)\n","[393:648]svaing file: ./data/processed/SF2-100146_0.npy\n","save file: ./data/processed/SF2-100113\n","audio mcep shape (36, 1024)\n","[394:648]svaing file: ./data/processed/SF2-100113_0.npy\n","[394:648]svaing file: ./data/processed/SF2-100113_512.npy\n","save file: ./data/processed/SF2-100143\n","audio mcep shape (36, 512)\n","[395:648]svaing file: ./data/processed/SF2-100143_0.npy\n","save file: ./data/processed/SF2-100082\n","audio mcep shape (36, 512)\n","[396:648]svaing file: ./data/processed/SF2-100082_0.npy\n","save file: ./data/processed/SF2-100083\n","audio mcep shape (36, 1024)\n","[397:648]svaing file: ./data/processed/SF2-100083_0.npy\n","[397:648]svaing file: ./data/processed/SF2-100083_512.npy\n","save file: ./data/processed/SF2-100074\n","audio mcep shape (36, 1024)\n","[398:648]svaing file: ./data/processed/SF2-100074_0.npy\n","[398:648]svaing file: ./data/processed/SF2-100074_512.npy\n","save file: ./data/processed/SF2-100057\n","audio mcep shape (36, 1536)\n","[399:648]svaing file: ./data/processed/SF2-100057_0.npy\n","[399:648]svaing file: ./data/processed/SF2-100057_512.npy\n","[399:648]svaing file: ./data/processed/SF2-100057_1024.npy\n","save file: ./data/processed/SF2-100130\n","audio mcep shape (36, 1024)\n","[400:648]svaing file: ./data/processed/SF2-100130_0.npy\n","[400:648]svaing file: ./data/processed/SF2-100130_512.npy\n","save file: ./data/processed/SF2-100109\n","audio mcep shape (36, 1024)\n","[401:648]svaing file: ./data/processed/SF2-100109_0.npy\n","[401:648]svaing file: ./data/processed/SF2-100109_512.npy\n","save file: ./data/processed/SF2-100151\n","audio mcep shape (36, 1024)\n","[402:648]svaing file: ./data/processed/SF2-100151_0.npy\n","[402:648]svaing file: ./data/processed/SF2-100151_512.npy\n","save file: ./data/processed/SF2-100033\n","audio mcep shape (36, 1024)\n","[403:648]svaing file: ./data/processed/SF2-100033_0.npy\n","[403:648]svaing file: ./data/processed/SF2-100033_512.npy\n","save file: ./data/processed/SF2-100058\n","audio mcep shape (36, 1024)\n","[404:648]svaing file: ./data/processed/SF2-100058_0.npy\n","[404:648]svaing file: ./data/processed/SF2-100058_512.npy\n","save file: ./data/processed/SF2-100079\n","audio mcep shape (36, 1024)\n","[405:648]svaing file: ./data/processed/SF2-100079_0.npy\n","[405:648]svaing file: ./data/processed/SF2-100079_512.npy\n","save file: ./data/processed/SF2-100116\n","audio mcep shape (36, 1024)\n","[406:648]svaing file: ./data/processed/SF2-100116_0.npy\n","[406:648]svaing file: ./data/processed/SF2-100116_512.npy\n","save file: ./data/processed/SF2-100161\n","audio mcep shape (36, 1024)\n","[407:648]svaing file: ./data/processed/SF2-100161_0.npy\n","[407:648]svaing file: ./data/processed/SF2-100161_512.npy\n","save file: ./data/processed/SF2-100115\n","audio mcep shape (36, 1536)\n","[408:648]svaing file: ./data/processed/SF2-100115_0.npy\n","[408:648]svaing file: ./data/processed/SF2-100115_512.npy\n","[408:648]svaing file: ./data/processed/SF2-100115_1024.npy\n","save file: ./data/processed/SF2-100073\n","audio mcep shape (36, 1024)\n","[409:648]svaing file: ./data/processed/SF2-100073_0.npy\n","[409:648]svaing file: ./data/processed/SF2-100073_512.npy\n","save file: ./data/processed/SF2-100091\n","audio mcep shape (36, 1024)\n","[410:648]svaing file: ./data/processed/SF2-100091_0.npy\n","[410:648]svaing file: ./data/processed/SF2-100091_512.npy\n","save file: ./data/processed/SF2-100108\n","audio mcep shape (36, 1024)\n","[411:648]svaing file: ./data/processed/SF2-100108_0.npy\n","[411:648]svaing file: ./data/processed/SF2-100108_512.npy\n","save file: ./data/processed/SF2-100103\n","audio mcep shape (36, 1024)\n","[412:648]svaing file: ./data/processed/SF2-100103_0.npy\n","[412:648]svaing file: ./data/processed/SF2-100103_512.npy\n","save file: ./data/processed/SF2-100053\n","audio mcep shape (36, 512)\n","[413:648]svaing file: ./data/processed/SF2-100053_0.npy\n","save file: ./data/processed/SF2-100003\n","audio mcep shape (36, 1024)\n","[414:648]svaing file: ./data/processed/SF2-100003_0.npy\n","[414:648]svaing file: ./data/processed/SF2-100003_512.npy\n","save file: ./data/processed/SF2-100104\n","audio mcep shape (36, 512)\n","[415:648]svaing file: ./data/processed/SF2-100104_0.npy\n","save file: ./data/processed/SF2-100005\n","audio mcep shape (36, 1024)\n","[416:648]svaing file: ./data/processed/SF2-100005_0.npy\n","[416:648]svaing file: ./data/processed/SF2-100005_512.npy\n","save file: ./data/processed/SF2-100015\n","audio mcep shape (36, 512)\n","[417:648]svaing file: ./data/processed/SF2-100015_0.npy\n","save file: ./data/processed/SF2-100007\n","audio mcep shape (36, 1024)\n","[418:648]svaing file: ./data/processed/SF2-100007_0.npy\n","[418:648]svaing file: ./data/processed/SF2-100007_512.npy\n","save file: ./data/processed/SF2-100068\n","audio mcep shape (36, 1024)\n","[419:648]svaing file: ./data/processed/SF2-100068_0.npy\n","[419:648]svaing file: ./data/processed/SF2-100068_512.npy\n","save file: ./data/processed/SF2-100087\n","audio mcep shape (36, 1024)\n","[420:648]svaing file: ./data/processed/SF2-100087_0.npy\n","[420:648]svaing file: ./data/processed/SF2-100087_512.npy\n","save file: ./data/processed/SF2-100125\n","audio mcep shape (36, 2048)\n","[421:648]svaing file: ./data/processed/SF2-100125_0.npy\n","[421:648]svaing file: ./data/processed/SF2-100125_512.npy\n","[421:648]svaing file: ./data/processed/SF2-100125_1024.npy\n","[421:648]svaing file: ./data/processed/SF2-100125_1536.npy\n","save file: ./data/processed/SF2-100044\n","audio mcep shape (36, 512)\n","[422:648]svaing file: ./data/processed/SF2-100044_0.npy\n","save file: ./data/processed/SF2-100061\n","audio mcep shape (36, 1024)\n","[423:648]svaing file: ./data/processed/SF2-100061_0.npy\n","[423:648]svaing file: ./data/processed/SF2-100061_512.npy\n","save file: ./data/processed/SF2-100090\n","audio mcep shape (36, 1024)\n","[424:648]svaing file: ./data/processed/SF2-100090_0.npy\n","[424:648]svaing file: ./data/processed/SF2-100090_512.npy\n","save file: ./data/processed/SF2-100077\n","audio mcep shape (36, 1536)\n","[425:648]svaing file: ./data/processed/SF2-100077_0.npy\n","[425:648]svaing file: ./data/processed/SF2-100077_512.npy\n","[425:648]svaing file: ./data/processed/SF2-100077_1024.npy\n","save file: ./data/processed/SF2-100032\n","audio mcep shape (36, 1024)\n","[426:648]svaing file: ./data/processed/SF2-100032_0.npy\n","[426:648]svaing file: ./data/processed/SF2-100032_512.npy\n","save file: ./data/processed/SF2-100156\n","audio mcep shape (36, 512)\n","[427:648]svaing file: ./data/processed/SF2-100156_0.npy\n","save file: ./data/processed/SF2-100025\n","audio mcep shape (36, 1536)\n","[428:648]svaing file: ./data/processed/SF2-100025_0.npy\n","[428:648]svaing file: ./data/processed/SF2-100025_512.npy\n","[428:648]svaing file: ./data/processed/SF2-100025_1024.npy\n","save file: ./data/processed/SF2-100134\n","audio mcep shape (36, 512)\n","[429:648]svaing file: ./data/processed/SF2-100134_0.npy\n","save file: ./data/processed/SF2-100027\n","audio mcep shape (36, 1536)\n","[430:648]svaing file: ./data/processed/SF2-100027_0.npy\n","[430:648]svaing file: ./data/processed/SF2-100027_512.npy\n","[430:648]svaing file: ./data/processed/SF2-100027_1024.npy\n","save file: ./data/processed/SF2-100018\n","audio mcep shape (36, 512)\n","[431:648]svaing file: ./data/processed/SF2-100018_0.npy\n","save file: ./data/processed/SF2-100065\n","audio mcep shape (36, 1024)\n","[432:648]svaing file: ./data/processed/SF2-100065_0.npy\n","[432:648]svaing file: ./data/processed/SF2-100065_512.npy\n","save file: ./data/processed/SF2-100064\n","audio mcep shape (36, 1024)\n","[433:648]svaing file: ./data/processed/SF2-100064_0.npy\n","[433:648]svaing file: ./data/processed/SF2-100064_512.npy\n","save file: ./data/processed/SF2-100011\n","audio mcep shape (36, 1024)\n","[434:648]svaing file: ./data/processed/SF2-100011_0.npy\n","[434:648]svaing file: ./data/processed/SF2-100011_512.npy\n","save file: ./data/processed/SF2-100042\n","audio mcep shape (36, 1024)\n","[435:648]svaing file: ./data/processed/SF2-100042_0.npy\n","[435:648]svaing file: ./data/processed/SF2-100042_512.npy\n","save file: ./data/processed/SF2-100043\n","audio mcep shape (36, 512)\n","[436:648]svaing file: ./data/processed/SF2-100043_0.npy\n","save file: ./data/processed/SF2-100162\n","audio mcep shape (36, 1024)\n","[437:648]svaing file: ./data/processed/SF2-100162_0.npy\n","[437:648]svaing file: ./data/processed/SF2-100162_512.npy\n","save file: ./data/processed/SF2-100013\n","audio mcep shape (36, 1024)\n","[438:648]svaing file: ./data/processed/SF2-100013_0.npy\n","[438:648]svaing file: ./data/processed/SF2-100013_512.npy\n","save file: ./data/processed/SF2-100034\n","audio mcep shape (36, 1536)\n","[439:648]svaing file: ./data/processed/SF2-100034_0.npy\n","[439:648]svaing file: ./data/processed/SF2-100034_512.npy\n","[439:648]svaing file: ./data/processed/SF2-100034_1024.npy\n","save file: ./data/processed/SF2-100055\n","audio mcep shape (36, 512)\n","[440:648]svaing file: ./data/processed/SF2-100055_0.npy\n","save file: ./data/processed/SF2-100153\n","audio mcep shape (36, 512)\n","[441:648]svaing file: ./data/processed/SF2-100153_0.npy\n","save file: ./data/processed/SF2-100124\n","audio mcep shape (36, 512)\n","[442:648]svaing file: ./data/processed/SF2-100124_0.npy\n","save file: ./data/processed/SF2-100069\n","audio mcep shape (36, 512)\n","[443:648]svaing file: ./data/processed/SF2-100069_0.npy\n","save file: ./data/processed/SF2-100030\n","audio mcep shape (36, 1024)\n","[444:648]svaing file: ./data/processed/SF2-100030_0.npy\n","[444:648]svaing file: ./data/processed/SF2-100030_512.npy\n","save file: ./data/processed/SF2-100060\n","audio mcep shape (36, 512)\n","[445:648]svaing file: ./data/processed/SF2-100060_0.npy\n","save file: ./data/processed/SF2-100045\n","audio mcep shape (36, 1024)\n","[446:648]svaing file: ./data/processed/SF2-100045_0.npy\n","[446:648]svaing file: ./data/processed/SF2-100045_512.npy\n","save file: ./data/processed/SF2-100084\n","audio mcep shape (36, 512)\n","[447:648]svaing file: ./data/processed/SF2-100084_0.npy\n","save file: ./data/processed/SF2-100049\n","audio mcep shape (36, 1024)\n","[448:648]svaing file: ./data/processed/SF2-100049_0.npy\n","[448:648]svaing file: ./data/processed/SF2-100049_512.npy\n","save file: ./data/processed/SF2-100085\n","audio mcep shape (36, 1024)\n","[449:648]svaing file: ./data/processed/SF2-100085_0.npy\n","[449:648]svaing file: ./data/processed/SF2-100085_512.npy\n","save file: ./data/processed/SF2-100009\n","audio mcep shape (36, 1024)\n","[450:648]svaing file: ./data/processed/SF2-100009_0.npy\n","[450:648]svaing file: ./data/processed/SF2-100009_512.npy\n","save file: ./data/processed/SF2-100054\n","audio mcep shape (36, 1024)\n","[451:648]svaing file: ./data/processed/SF2-100054_0.npy\n","[451:648]svaing file: ./data/processed/SF2-100054_512.npy\n","save file: ./data/processed/SF2-100038\n","audio mcep shape (36, 1024)\n","[452:648]svaing file: ./data/processed/SF2-100038_0.npy\n","[452:648]svaing file: ./data/processed/SF2-100038_512.npy\n","save file: ./data/processed/SF2-100123\n","audio mcep shape (36, 1024)\n","[453:648]svaing file: ./data/processed/SF2-100123_0.npy\n","[453:648]svaing file: ./data/processed/SF2-100123_512.npy\n","save file: ./data/processed/SF2-100075\n","audio mcep shape (36, 1024)\n","[454:648]svaing file: ./data/processed/SF2-100075_0.npy\n","[454:648]svaing file: ./data/processed/SF2-100075_512.npy\n","save file: ./data/processed/SF2-100072\n","audio mcep shape (36, 1536)\n","[455:648]svaing file: ./data/processed/SF2-100072_0.npy\n","[455:648]svaing file: ./data/processed/SF2-100072_512.npy\n","[455:648]svaing file: ./data/processed/SF2-100072_1024.npy\n","save file: ./data/processed/SF2-100040\n","audio mcep shape (36, 1024)\n","[456:648]svaing file: ./data/processed/SF2-100040_0.npy\n","[456:648]svaing file: ./data/processed/SF2-100040_512.npy\n","save file: ./data/processed/SF2-100119\n","audio mcep shape (36, 1024)\n","[457:648]svaing file: ./data/processed/SF2-100119_0.npy\n","[457:648]svaing file: ./data/processed/SF2-100119_512.npy\n","save file: ./data/processed/SF2-100150\n","audio mcep shape (36, 512)\n","[458:648]svaing file: ./data/processed/SF2-100150_0.npy\n","save file: ./data/processed/SF2-100145\n","audio mcep shape (36, 1024)\n","[459:648]svaing file: ./data/processed/SF2-100145_0.npy\n","[459:648]svaing file: ./data/processed/SF2-100145_512.npy\n","save file: ./data/processed/SF2-100112\n","audio mcep shape (36, 512)\n","[460:648]svaing file: ./data/processed/SF2-100112_0.npy\n","save file: ./data/processed/SF2-100121\n","audio mcep shape (36, 1024)\n","[461:648]svaing file: ./data/processed/SF2-100121_0.npy\n","[461:648]svaing file: ./data/processed/SF2-100121_512.npy\n","save file: ./data/processed/SF2-100126\n","audio mcep shape (36, 1024)\n","[462:648]svaing file: ./data/processed/SF2-100126_0.npy\n","[462:648]svaing file: ./data/processed/SF2-100126_512.npy\n","save file: ./data/processed/SF2-100158\n","audio mcep shape (36, 512)\n","[463:648]svaing file: ./data/processed/SF2-100158_0.npy\n","save file: ./data/processed/SF2-100098\n","audio mcep shape (36, 1536)\n","[464:648]svaing file: ./data/processed/SF2-100098_0.npy\n","[464:648]svaing file: ./data/processed/SF2-100098_512.npy\n","[464:648]svaing file: ./data/processed/SF2-100098_1024.npy\n","save file: ./data/processed/SF2-100093\n","audio mcep shape (36, 512)\n","[465:648]svaing file: ./data/processed/SF2-100093_0.npy\n","save file: ./data/processed/SF2-100052\n","audio mcep shape (36, 512)\n","[466:648]svaing file: ./data/processed/SF2-100052_0.npy\n","save file: ./data/processed/SF2-100110\n","audio mcep shape (36, 1024)\n","[467:648]svaing file: ./data/processed/SF2-100110_0.npy\n","[467:648]svaing file: ./data/processed/SF2-100110_512.npy\n","save file: ./data/processed/SF2-100078\n","audio mcep shape (36, 1024)\n","[468:648]svaing file: ./data/processed/SF2-100078_0.npy\n","[468:648]svaing file: ./data/processed/SF2-100078_512.npy\n","save file: ./data/processed/SF2-100089\n","audio mcep shape (36, 1024)\n","[469:648]svaing file: ./data/processed/SF2-100089_0.npy\n","[469:648]svaing file: ./data/processed/SF2-100089_512.npy\n","save file: ./data/processed/SF2-100039\n","audio mcep shape (36, 1024)\n","[470:648]svaing file: ./data/processed/SF2-100039_0.npy\n","[470:648]svaing file: ./data/processed/SF2-100039_512.npy\n","save file: ./data/processed/SF2-100107\n","audio mcep shape (36, 1024)\n","[471:648]svaing file: ./data/processed/SF2-100107_0.npy\n","[471:648]svaing file: ./data/processed/SF2-100107_512.npy\n","save file: ./data/processed/SF2-100147\n","audio mcep shape (36, 512)\n","[472:648]svaing file: ./data/processed/SF2-100147_0.npy\n","save file: ./data/processed/SF2-100132\n","audio mcep shape (36, 512)\n","[473:648]svaing file: ./data/processed/SF2-100132_0.npy\n","save file: ./data/processed/SF2-100099\n","audio mcep shape (36, 1024)\n","[474:648]svaing file: ./data/processed/SF2-100099_0.npy\n","[474:648]svaing file: ./data/processed/SF2-100099_512.npy\n","save file: ./data/processed/SF2-100092\n","audio mcep shape (36, 1024)\n","[475:648]svaing file: ./data/processed/SF2-100092_0.npy\n","[475:648]svaing file: ./data/processed/SF2-100092_512.npy\n","save file: ./data/processed/SF2-100067\n","audio mcep shape (36, 1024)\n","[476:648]svaing file: ./data/processed/SF2-100067_0.npy\n","[476:648]svaing file: ./data/processed/SF2-100067_512.npy\n","save file: ./data/processed/SF2-100122\n","audio mcep shape (36, 1024)\n","[477:648]svaing file: ./data/processed/SF2-100122_0.npy\n","[477:648]svaing file: ./data/processed/SF2-100122_512.npy\n","save file: ./data/processed/SF2-100036\n","audio mcep shape (36, 1024)\n","[478:648]svaing file: ./data/processed/SF2-100036_0.npy\n","[478:648]svaing file: ./data/processed/SF2-100036_512.npy\n","save file: ./data/processed/SF2-100066\n","audio mcep shape (36, 1024)\n","[479:648]svaing file: ./data/processed/SF2-100066_0.npy\n","[479:648]svaing file: ./data/processed/SF2-100066_512.npy\n","save file: ./data/processed/SF2-100118\n","audio mcep shape (36, 1536)\n","[480:648]svaing file: ./data/processed/SF2-100118_0.npy\n","[480:648]svaing file: ./data/processed/SF2-100118_512.npy\n","[480:648]svaing file: ./data/processed/SF2-100118_1024.npy\n","save file: ./data/processed/SF2-100051\n","audio mcep shape (36, 1024)\n","[481:648]svaing file: ./data/processed/SF2-100051_0.npy\n","[481:648]svaing file: ./data/processed/SF2-100051_512.npy\n","save file: ./data/processed/SF2-100062\n","audio mcep shape (36, 1024)\n","[482:648]svaing file: ./data/processed/SF2-100062_0.npy\n","[482:648]svaing file: ./data/processed/SF2-100062_512.npy\n","save file: ./data/processed/SF2-100046\n","audio mcep shape (36, 1024)\n","[483:648]svaing file: ./data/processed/SF2-100046_0.npy\n","[483:648]svaing file: ./data/processed/SF2-100046_512.npy\n","save file: ./data/processed/SF2-100136\n","audio mcep shape (36, 1536)\n","[484:648]svaing file: ./data/processed/SF2-100136_0.npy\n","[484:648]svaing file: ./data/processed/SF2-100136_512.npy\n","[484:648]svaing file: ./data/processed/SF2-100136_1024.npy\n","save file: ./data/processed/SF2-100144\n","audio mcep shape (36, 1536)\n","[485:648]svaing file: ./data/processed/SF2-100144_0.npy\n","[485:648]svaing file: ./data/processed/SF2-100144_512.npy\n","[485:648]svaing file: ./data/processed/SF2-100144_1024.npy\n","save file: ./data/processed/SF2-100056\n","audio mcep shape (36, 1024)\n","[486:648]svaing file: ./data/processed/SF2-100056_0.npy\n","[486:648]svaing file: ./data/processed/SF2-100056_512.npy\n","save file: ./data/processed/SF1-100078\n","audio mcep shape (36, 1024)\n","[487:648]svaing file: ./data/processed/SF1-100078_0.npy\n","[487:648]svaing file: ./data/processed/SF1-100078_512.npy\n","save file: ./data/processed/SF1-100066\n","audio mcep shape (36, 1024)\n","[488:648]svaing file: ./data/processed/SF1-100066_0.npy\n","[488:648]svaing file: ./data/processed/SF1-100066_512.npy\n","save file: ./data/processed/SF1-100008\n","audio mcep shape (36, 1536)\n","[489:648]svaing file: ./data/processed/SF1-100008_0.npy\n","[489:648]svaing file: ./data/processed/SF1-100008_512.npy\n","[489:648]svaing file: ./data/processed/SF1-100008_1024.npy\n","save file: ./data/processed/SF1-100046\n","audio mcep shape (36, 1024)\n","[490:648]svaing file: ./data/processed/SF1-100046_0.npy\n","[490:648]svaing file: ./data/processed/SF1-100046_512.npy\n","save file: ./data/processed/SF1-100156\n","audio mcep shape (36, 512)\n","[491:648]svaing file: ./data/processed/SF1-100156_0.npy\n","save file: ./data/processed/SF1-100135\n","audio mcep shape (36, 1024)\n","[492:648]svaing file: ./data/processed/SF1-100135_0.npy\n","[492:648]svaing file: ./data/processed/SF1-100135_512.npy\n","save file: ./data/processed/SF1-100049\n","audio mcep shape (36, 1024)\n","[493:648]svaing file: ./data/processed/SF1-100049_0.npy\n","[493:648]svaing file: ./data/processed/SF1-100049_512.npy\n","save file: ./data/processed/SF1-100152\n","audio mcep shape (36, 1024)\n","[494:648]svaing file: ./data/processed/SF1-100152_0.npy\n","[494:648]svaing file: ./data/processed/SF1-100152_512.npy\n","save file: ./data/processed/SF1-100090\n","audio mcep shape (36, 1024)\n","[495:648]svaing file: ./data/processed/SF1-100090_0.npy\n","[495:648]svaing file: ./data/processed/SF1-100090_512.npy\n","save file: ./data/processed/SF1-100130\n","audio mcep shape (36, 1024)\n","[496:648]svaing file: ./data/processed/SF1-100130_0.npy\n","[496:648]svaing file: ./data/processed/SF1-100130_512.npy\n","save file: ./data/processed/SF1-100077\n","audio mcep shape (36, 1536)\n","[497:648]svaing file: ./data/processed/SF1-100077_0.npy\n","[497:648]svaing file: ./data/processed/SF1-100077_512.npy\n","[497:648]svaing file: ./data/processed/SF1-100077_1024.npy\n","save file: ./data/processed/SF1-100079\n","audio mcep shape (36, 1024)\n","[498:648]svaing file: ./data/processed/SF1-100079_0.npy\n","[498:648]svaing file: ./data/processed/SF1-100079_512.npy\n","save file: ./data/processed/SF1-100065\n","audio mcep shape (36, 1024)\n","[499:648]svaing file: ./data/processed/SF1-100065_0.npy\n","[499:648]svaing file: ./data/processed/SF1-100065_512.npy\n","save file: ./data/processed/SF1-100060\n","audio mcep shape (36, 512)\n","[500:648]svaing file: ./data/processed/SF1-100060_0.npy\n","save file: ./data/processed/SF1-100038\n","audio mcep shape (36, 1024)\n","[501:648]svaing file: ./data/processed/SF1-100038_0.npy\n","[501:648]svaing file: ./data/processed/SF1-100038_512.npy\n","save file: ./data/processed/SF1-100033\n","audio mcep shape (36, 1024)\n","[502:648]svaing file: ./data/processed/SF1-100033_0.npy\n","[502:648]svaing file: ./data/processed/SF1-100033_512.npy\n","save file: ./data/processed/SF1-100149\n","audio mcep shape (36, 1536)\n","[503:648]svaing file: ./data/processed/SF1-100149_0.npy\n","[503:648]svaing file: ./data/processed/SF1-100149_512.npy\n","[503:648]svaing file: ./data/processed/SF1-100149_1024.npy\n","save file: ./data/processed/SF1-100095\n","audio mcep shape (36, 1024)\n","[504:648]svaing file: ./data/processed/SF1-100095_0.npy\n","[504:648]svaing file: ./data/processed/SF1-100095_512.npy\n","save file: ./data/processed/SF1-100148\n","audio mcep shape (36, 1536)\n","[505:648]svaing file: ./data/processed/SF1-100148_0.npy\n","[505:648]svaing file: ./data/processed/SF1-100148_512.npy\n","[505:648]svaing file: ./data/processed/SF1-100148_1024.npy\n","save file: ./data/processed/SF1-100155\n","audio mcep shape (36, 1536)\n","[506:648]svaing file: ./data/processed/SF1-100155_0.npy\n","[506:648]svaing file: ./data/processed/SF1-100155_512.npy\n","[506:648]svaing file: ./data/processed/SF1-100155_1024.npy\n","save file: ./data/processed/SF1-100006\n","audio mcep shape (36, 1024)\n","[507:648]svaing file: ./data/processed/SF1-100006_0.npy\n","[507:648]svaing file: ./data/processed/SF1-100006_512.npy\n","save file: ./data/processed/SF1-100134\n","audio mcep shape (36, 512)\n","[508:648]svaing file: ./data/processed/SF1-100134_0.npy\n","save file: ./data/processed/SF1-100103\n","audio mcep shape (36, 1024)\n","[509:648]svaing file: ./data/processed/SF1-100103_0.npy\n","[509:648]svaing file: ./data/processed/SF1-100103_512.npy\n","save file: ./data/processed/SF1-100018\n","audio mcep shape (36, 1024)\n","[510:648]svaing file: ./data/processed/SF1-100018_0.npy\n","[510:648]svaing file: ./data/processed/SF1-100018_512.npy\n","save file: ./data/processed/SF1-100128\n","audio mcep shape (36, 512)\n","[511:648]svaing file: ./data/processed/SF1-100128_0.npy\n","save file: ./data/processed/SF1-100012\n","audio mcep shape (36, 1024)\n","[512:648]svaing file: ./data/processed/SF1-100012_0.npy\n","[512:648]svaing file: ./data/processed/SF1-100012_512.npy\n","save file: ./data/processed/SF1-100092\n","audio mcep shape (36, 1024)\n","[513:648]svaing file: ./data/processed/SF1-100092_0.npy\n","[513:648]svaing file: ./data/processed/SF1-100092_512.npy\n","save file: ./data/processed/SF1-100068\n","audio mcep shape (36, 512)\n","[514:648]svaing file: ./data/processed/SF1-100068_0.npy\n","save file: ./data/processed/SF1-100162\n","audio mcep shape (36, 1024)\n","[515:648]svaing file: ./data/processed/SF1-100162_0.npy\n","[515:648]svaing file: ./data/processed/SF1-100162_512.npy\n","save file: ./data/processed/SF1-100106\n","audio mcep shape (36, 512)\n","[516:648]svaing file: ./data/processed/SF1-100106_0.npy\n","save file: ./data/processed/SF1-100069\n","audio mcep shape (36, 512)\n","[517:648]svaing file: ./data/processed/SF1-100069_0.npy\n","save file: ./data/processed/SF1-100009\n","audio mcep shape (36, 1024)\n","[518:648]svaing file: ./data/processed/SF1-100009_0.npy\n","[518:648]svaing file: ./data/processed/SF1-100009_512.npy\n","save file: ./data/processed/SF1-100114\n","audio mcep shape (36, 1536)\n","[519:648]svaing file: ./data/processed/SF1-100114_0.npy\n","[519:648]svaing file: ./data/processed/SF1-100114_512.npy\n","[519:648]svaing file: ./data/processed/SF1-100114_1024.npy\n","save file: ./data/processed/SF1-100013\n","audio mcep shape (36, 1024)\n","[520:648]svaing file: ./data/processed/SF1-100013_0.npy\n","[520:648]svaing file: ./data/processed/SF1-100013_512.npy\n","save file: ./data/processed/SF1-100101\n","audio mcep shape (36, 1024)\n","[521:648]svaing file: ./data/processed/SF1-100101_0.npy\n","[521:648]svaing file: ./data/processed/SF1-100101_512.npy\n","save file: ./data/processed/SF1-100144\n","audio mcep shape (36, 1024)\n","[522:648]svaing file: ./data/processed/SF1-100144_0.npy\n","[522:648]svaing file: ./data/processed/SF1-100144_512.npy\n","save file: ./data/processed/SF1-100113\n","audio mcep shape (36, 512)\n","[523:648]svaing file: ./data/processed/SF1-100113_0.npy\n","save file: ./data/processed/SF1-100094\n","audio mcep shape (36, 1024)\n","[524:648]svaing file: ./data/processed/SF1-100094_0.npy\n","[524:648]svaing file: ./data/processed/SF1-100094_512.npy\n","save file: ./data/processed/SF1-100020\n","audio mcep shape (36, 512)\n","[525:648]svaing file: ./data/processed/SF1-100020_0.npy\n","save file: ./data/processed/SF1-100075\n","audio mcep shape (36, 1024)\n","[526:648]svaing file: ./data/processed/SF1-100075_0.npy\n","[526:648]svaing file: ./data/processed/SF1-100075_512.npy\n","save file: ./data/processed/SF1-100142\n","audio mcep shape (36, 1536)\n","[527:648]svaing file: ./data/processed/SF1-100142_0.npy\n","[527:648]svaing file: ./data/processed/SF1-100142_512.npy\n","[527:648]svaing file: ./data/processed/SF1-100142_1024.npy\n","save file: ./data/processed/SF1-100143\n","audio mcep shape (36, 512)\n","[528:648]svaing file: ./data/processed/SF1-100143_0.npy\n","save file: ./data/processed/SF1-100096\n","audio mcep shape (36, 2048)\n","[529:648]svaing file: ./data/processed/SF1-100096_0.npy\n","[529:648]svaing file: ./data/processed/SF1-100096_512.npy\n","[529:648]svaing file: ./data/processed/SF1-100096_1024.npy\n","[529:648]svaing file: ./data/processed/SF1-100096_1536.npy\n","save file: ./data/processed/SF1-100011\n","audio mcep shape (36, 1536)\n","[530:648]svaing file: ./data/processed/SF1-100011_0.npy\n","[530:648]svaing file: ./data/processed/SF1-100011_512.npy\n","[530:648]svaing file: ./data/processed/SF1-100011_1024.npy\n","save file: ./data/processed/SF1-100026\n","audio mcep shape (36, 1024)\n","[531:648]svaing file: ./data/processed/SF1-100026_0.npy\n","[531:648]svaing file: ./data/processed/SF1-100026_512.npy\n","save file: ./data/processed/SF1-100089\n","audio mcep shape (36, 512)\n","[532:648]svaing file: ./data/processed/SF1-100089_0.npy\n","save file: ./data/processed/SF1-100076\n","audio mcep shape (36, 512)\n","[533:648]svaing file: ./data/processed/SF1-100076_0.npy\n","save file: ./data/processed/SF1-100063\n","audio mcep shape (36, 1024)\n","[534:648]svaing file: ./data/processed/SF1-100063_0.npy\n","[534:648]svaing file: ./data/processed/SF1-100063_512.npy\n","save file: ./data/processed/SF1-100057\n","audio mcep shape (36, 1536)\n","[535:648]svaing file: ./data/processed/SF1-100057_0.npy\n","[535:648]svaing file: ./data/processed/SF1-100057_512.npy\n","[535:648]svaing file: ./data/processed/SF1-100057_1024.npy\n","save file: ./data/processed/SF1-100071\n","audio mcep shape (36, 1024)\n","[536:648]svaing file: ./data/processed/SF1-100071_0.npy\n","[536:648]svaing file: ./data/processed/SF1-100071_512.npy\n","save file: ./data/processed/SF1-100044\n","audio mcep shape (36, 512)\n","[537:648]svaing file: ./data/processed/SF1-100044_0.npy\n","save file: ./data/processed/SF1-100112\n","audio mcep shape (36, 512)\n","[538:648]svaing file: ./data/processed/SF1-100112_0.npy\n","save file: ./data/processed/SF1-100052\n","audio mcep shape (36, 512)\n","[539:648]svaing file: ./data/processed/SF1-100052_0.npy\n","save file: ./data/processed/SF1-100032\n","audio mcep shape (36, 1024)\n","[540:648]svaing file: ./data/processed/SF1-100032_0.npy\n","[540:648]svaing file: ./data/processed/SF1-100032_512.npy\n","save file: ./data/processed/SF1-100161\n","audio mcep shape (36, 1024)\n","[541:648]svaing file: ./data/processed/SF1-100161_0.npy\n","[541:648]svaing file: ./data/processed/SF1-100161_512.npy\n","save file: ./data/processed/SF1-100019\n","audio mcep shape (36, 512)\n","[542:648]svaing file: ./data/processed/SF1-100019_0.npy\n","save file: ./data/processed/SF1-100016\n","audio mcep shape (36, 1024)\n","[543:648]svaing file: ./data/processed/SF1-100016_0.npy\n","[543:648]svaing file: ./data/processed/SF1-100016_512.npy\n","save file: ./data/processed/SF1-100127\n","audio mcep shape (36, 1024)\n","[544:648]svaing file: ./data/processed/SF1-100127_0.npy\n","[544:648]svaing file: ./data/processed/SF1-100127_512.npy\n","save file: ./data/processed/SF1-100154\n","audio mcep shape (36, 512)\n","[545:648]svaing file: ./data/processed/SF1-100154_0.npy\n","save file: ./data/processed/SF1-100104\n","audio mcep shape (36, 512)\n","[546:648]svaing file: ./data/processed/SF1-100104_0.npy\n","save file: ./data/processed/SF1-100100\n","audio mcep shape (36, 512)\n","[547:648]svaing file: ./data/processed/SF1-100100_0.npy\n","save file: ./data/processed/SF1-100119\n","audio mcep shape (36, 512)\n","[548:648]svaing file: ./data/processed/SF1-100119_0.npy\n","save file: ./data/processed/SF1-100004\n","audio mcep shape (36, 512)\n","[549:648]svaing file: ./data/processed/SF1-100004_0.npy\n","save file: ./data/processed/SF1-100010\n","audio mcep shape (36, 1024)\n","[550:648]svaing file: ./data/processed/SF1-100010_0.npy\n","[550:648]svaing file: ./data/processed/SF1-100010_512.npy\n","save file: ./data/processed/SF1-100043\n","audio mcep shape (36, 512)\n","[551:648]svaing file: ./data/processed/SF1-100043_0.npy\n","save file: ./data/processed/SF1-100001\n","audio mcep shape (36, 1024)\n","[552:648]svaing file: ./data/processed/SF1-100001_0.npy\n","[552:648]svaing file: ./data/processed/SF1-100001_512.npy\n","save file: ./data/processed/SF1-100140\n","audio mcep shape (36, 512)\n","[553:648]svaing file: ./data/processed/SF1-100140_0.npy\n","save file: ./data/processed/SF1-100160\n","audio mcep shape (36, 1536)\n","[554:648]svaing file: ./data/processed/SF1-100160_0.npy\n","[554:648]svaing file: ./data/processed/SF1-100160_512.npy\n","[554:648]svaing file: ./data/processed/SF1-100160_1024.npy\n","save file: ./data/processed/SF1-100115\n","audio mcep shape (36, 1024)\n","[555:648]svaing file: ./data/processed/SF1-100115_0.npy\n","[555:648]svaing file: ./data/processed/SF1-100115_512.npy\n","save file: ./data/processed/SF1-100064\n","audio mcep shape (36, 1024)\n","[556:648]svaing file: ./data/processed/SF1-100064_0.npy\n","[556:648]svaing file: ./data/processed/SF1-100064_512.npy\n","save file: ./data/processed/SF1-100131\n","audio mcep shape (36, 1024)\n","[557:648]svaing file: ./data/processed/SF1-100131_0.npy\n","[557:648]svaing file: ./data/processed/SF1-100131_512.npy\n","save file: ./data/processed/SF1-100050\n","audio mcep shape (36, 1024)\n","[558:648]svaing file: ./data/processed/SF1-100050_0.npy\n","[558:648]svaing file: ./data/processed/SF1-100050_512.npy\n","save file: ./data/processed/SF1-100080\n","audio mcep shape (36, 1024)\n","[559:648]svaing file: ./data/processed/SF1-100080_0.npy\n","[559:648]svaing file: ./data/processed/SF1-100080_512.npy\n","save file: ./data/processed/SF1-100031\n","audio mcep shape (36, 1024)\n","[560:648]svaing file: ./data/processed/SF1-100031_0.npy\n","[560:648]svaing file: ./data/processed/SF1-100031_512.npy\n","save file: ./data/processed/SF1-100111\n","audio mcep shape (36, 1536)\n","[561:648]svaing file: ./data/processed/SF1-100111_0.npy\n","[561:648]svaing file: ./data/processed/SF1-100111_512.npy\n","[561:648]svaing file: ./data/processed/SF1-100111_1024.npy\n","save file: ./data/processed/SF1-100025\n","audio mcep shape (36, 1536)\n","[562:648]svaing file: ./data/processed/SF1-100025_0.npy\n","[562:648]svaing file: ./data/processed/SF1-100025_512.npy\n","[562:648]svaing file: ./data/processed/SF1-100025_1024.npy\n","save file: ./data/processed/SF1-100138\n","audio mcep shape (36, 512)\n","[563:648]svaing file: ./data/processed/SF1-100138_0.npy\n","save file: ./data/processed/SF1-100158\n","audio mcep shape (36, 512)\n","[564:648]svaing file: ./data/processed/SF1-100158_0.npy\n","save file: ./data/processed/SF1-100098\n","audio mcep shape (36, 2048)\n","[565:648]svaing file: ./data/processed/SF1-100098_0.npy\n","[565:648]svaing file: ./data/processed/SF1-100098_512.npy\n","[565:648]svaing file: ./data/processed/SF1-100098_1024.npy\n","[565:648]svaing file: ./data/processed/SF1-100098_1536.npy\n","save file: ./data/processed/SF1-100109\n","audio mcep shape (36, 512)\n","[566:648]svaing file: ./data/processed/SF1-100109_0.npy\n","save file: ./data/processed/SF1-100123\n","audio mcep shape (36, 1024)\n","[567:648]svaing file: ./data/processed/SF1-100123_0.npy\n","[567:648]svaing file: ./data/processed/SF1-100123_512.npy\n","save file: ./data/processed/SF1-100042\n","audio mcep shape (36, 1024)\n","[568:648]svaing file: ./data/processed/SF1-100042_0.npy\n","[568:648]svaing file: ./data/processed/SF1-100042_512.npy\n","save file: ./data/processed/SF1-100129\n","audio mcep shape (36, 512)\n","[569:648]svaing file: ./data/processed/SF1-100129_0.npy\n","save file: ./data/processed/SF1-100017\n","audio mcep shape (36, 1024)\n","[570:648]svaing file: ./data/processed/SF1-100017_0.npy\n","[570:648]svaing file: ./data/processed/SF1-100017_512.npy\n","save file: ./data/processed/SF1-100061\n","audio mcep shape (36, 1024)\n","[571:648]svaing file: ./data/processed/SF1-100061_0.npy\n","[571:648]svaing file: ./data/processed/SF1-100061_512.npy\n","save file: ./data/processed/SF1-100027\n","audio mcep shape (36, 1024)\n","[572:648]svaing file: ./data/processed/SF1-100027_0.npy\n","[572:648]svaing file: ./data/processed/SF1-100027_512.npy\n","save file: ./data/processed/SF1-100084\n","audio mcep shape (36, 512)\n","[573:648]svaing file: ./data/processed/SF1-100084_0.npy\n","save file: ./data/processed/SF1-100073\n","audio mcep shape (36, 1024)\n","[574:648]svaing file: ./data/processed/SF1-100073_0.npy\n","[574:648]svaing file: ./data/processed/SF1-100073_512.npy\n","save file: ./data/processed/SF1-100029\n","audio mcep shape (36, 1024)\n","[575:648]svaing file: ./data/processed/SF1-100029_0.npy\n","[575:648]svaing file: ./data/processed/SF1-100029_512.npy\n","save file: ./data/processed/SF1-100108\n","audio mcep shape (36, 1024)\n","[576:648]svaing file: ./data/processed/SF1-100108_0.npy\n","[576:648]svaing file: ./data/processed/SF1-100108_512.npy\n","save file: ./data/processed/SF1-100118\n","audio mcep shape (36, 1536)\n","[577:648]svaing file: ./data/processed/SF1-100118_0.npy\n","[577:648]svaing file: ./data/processed/SF1-100118_512.npy\n","[577:648]svaing file: ./data/processed/SF1-100118_1024.npy\n","save file: ./data/processed/SF1-100146\n","audio mcep shape (36, 1024)\n","[578:648]svaing file: ./data/processed/SF1-100146_0.npy\n","[578:648]svaing file: ./data/processed/SF1-100146_512.npy\n","save file: ./data/processed/SF1-100040\n","audio mcep shape (36, 1024)\n","[579:648]svaing file: ./data/processed/SF1-100040_0.npy\n","[579:648]svaing file: ./data/processed/SF1-100040_512.npy\n","save file: ./data/processed/SF1-100056\n","audio mcep shape (36, 1024)\n","[580:648]svaing file: ./data/processed/SF1-100056_0.npy\n","[580:648]svaing file: ./data/processed/SF1-100056_512.npy\n","save file: ./data/processed/SF1-100028\n","audio mcep shape (36, 512)\n","[581:648]svaing file: ./data/processed/SF1-100028_0.npy\n","save file: ./data/processed/SF1-100126\n","audio mcep shape (36, 512)\n","[582:648]svaing file: ./data/processed/SF1-100126_0.npy\n","save file: ./data/processed/SF1-100055\n","audio mcep shape (36, 512)\n","[583:648]svaing file: ./data/processed/SF1-100055_0.npy\n","save file: ./data/processed/SF1-100093\n","audio mcep shape (36, 512)\n","[584:648]svaing file: ./data/processed/SF1-100093_0.npy\n","save file: ./data/processed/SF1-100117\n","audio mcep shape (36, 512)\n","[585:648]svaing file: ./data/processed/SF1-100117_0.npy\n","save file: ./data/processed/SF1-100132\n","audio mcep shape (36, 512)\n","[586:648]svaing file: ./data/processed/SF1-100132_0.npy\n","save file: ./data/processed/SF1-100030\n","audio mcep shape (36, 1024)\n","[587:648]svaing file: ./data/processed/SF1-100030_0.npy\n","[587:648]svaing file: ./data/processed/SF1-100030_512.npy\n","save file: ./data/processed/SF1-100102\n","audio mcep shape (36, 512)\n","[588:648]svaing file: ./data/processed/SF1-100102_0.npy\n","save file: ./data/processed/SF1-100047\n","audio mcep shape (36, 1024)\n","[589:648]svaing file: ./data/processed/SF1-100047_0.npy\n","[589:648]svaing file: ./data/processed/SF1-100047_512.npy\n","save file: ./data/processed/SF1-100051\n","audio mcep shape (36, 1024)\n","[590:648]svaing file: ./data/processed/SF1-100051_0.npy\n","[590:648]svaing file: ./data/processed/SF1-100051_512.npy\n","save file: ./data/processed/SF1-100133\n","audio mcep shape (36, 1536)\n","[591:648]svaing file: ./data/processed/SF1-100133_0.npy\n","[591:648]svaing file: ./data/processed/SF1-100133_512.npy\n","[591:648]svaing file: ./data/processed/SF1-100133_1024.npy\n","save file: ./data/processed/SF1-100021\n","audio mcep shape (36, 1536)\n","[592:648]svaing file: ./data/processed/SF1-100021_0.npy\n","[592:648]svaing file: ./data/processed/SF1-100021_512.npy\n","[592:648]svaing file: ./data/processed/SF1-100021_1024.npy\n","save file: ./data/processed/SF1-100120\n","audio mcep shape (36, 512)\n","[593:648]svaing file: ./data/processed/SF1-100120_0.npy\n","save file: ./data/processed/SF1-100091\n","audio mcep shape (36, 1024)\n","[594:648]svaing file: ./data/processed/SF1-100091_0.npy\n","[594:648]svaing file: ./data/processed/SF1-100091_512.npy\n","save file: ./data/processed/SF1-100097\n","audio mcep shape (36, 512)\n","[595:648]svaing file: ./data/processed/SF1-100097_0.npy\n","save file: ./data/processed/SF1-100007\n","audio mcep shape (36, 512)\n","[596:648]svaing file: ./data/processed/SF1-100007_0.npy\n","save file: ./data/processed/SF1-100150\n","audio mcep shape (36, 512)\n","[597:648]svaing file: ./data/processed/SF1-100150_0.npy\n","save file: ./data/processed/SF1-100141\n","audio mcep shape (36, 512)\n","[598:648]svaing file: ./data/processed/SF1-100141_0.npy\n","save file: ./data/processed/SF1-100116\n","audio mcep shape (36, 1024)\n","[599:648]svaing file: ./data/processed/SF1-100116_0.npy\n","[599:648]svaing file: ./data/processed/SF1-100116_512.npy\n","save file: ./data/processed/SF1-100137\n","audio mcep shape (36, 1024)\n","[600:648]svaing file: ./data/processed/SF1-100137_0.npy\n","[600:648]svaing file: ./data/processed/SF1-100137_512.npy\n","save file: ./data/processed/SF1-100072\n","audio mcep shape (36, 1024)\n","[601:648]svaing file: ./data/processed/SF1-100072_0.npy\n","[601:648]svaing file: ./data/processed/SF1-100072_512.npy\n","save file: ./data/processed/SF1-100107\n","audio mcep shape (36, 1024)\n","[602:648]svaing file: ./data/processed/SF1-100107_0.npy\n","[602:648]svaing file: ./data/processed/SF1-100107_512.npy\n","save file: ./data/processed/SF1-100034\n","audio mcep shape (36, 1024)\n","[603:648]svaing file: ./data/processed/SF1-100034_0.npy\n","[603:648]svaing file: ./data/processed/SF1-100034_512.npy\n","save file: ./data/processed/SF1-100024\n","audio mcep shape (36, 1024)\n","[604:648]svaing file: ./data/processed/SF1-100024_0.npy\n","[604:648]svaing file: ./data/processed/SF1-100024_512.npy\n","save file: ./data/processed/SF1-100002\n","audio mcep shape (36, 512)\n","[605:648]svaing file: ./data/processed/SF1-100002_0.npy\n","save file: ./data/processed/SF1-100121\n","audio mcep shape (36, 1024)\n","[606:648]svaing file: ./data/processed/SF1-100121_0.npy\n","[606:648]svaing file: ./data/processed/SF1-100121_512.npy\n","save file: ./data/processed/SF1-100124\n","audio mcep shape (36, 512)\n","[607:648]svaing file: ./data/processed/SF1-100124_0.npy\n","save file: ./data/processed/SF1-100139\n","audio mcep shape (36, 1024)\n","[608:648]svaing file: ./data/processed/SF1-100139_0.npy\n","[608:648]svaing file: ./data/processed/SF1-100139_512.npy\n","save file: ./data/processed/SF1-100067\n","audio mcep shape (36, 1024)\n","[609:648]svaing file: ./data/processed/SF1-100067_0.npy\n","[609:648]svaing file: ./data/processed/SF1-100067_512.npy\n","save file: ./data/processed/SF1-100074\n","audio mcep shape (36, 1024)\n","[610:648]svaing file: ./data/processed/SF1-100074_0.npy\n","[610:648]svaing file: ./data/processed/SF1-100074_512.npy\n","save file: ./data/processed/SF1-100086\n","audio mcep shape (36, 512)\n","[611:648]svaing file: ./data/processed/SF1-100086_0.npy\n","save file: ./data/processed/SF1-100088\n","audio mcep shape (36, 1536)\n","[612:648]svaing file: ./data/processed/SF1-100088_0.npy\n","[612:648]svaing file: ./data/processed/SF1-100088_512.npy\n","[612:648]svaing file: ./data/processed/SF1-100088_1024.npy\n","save file: ./data/processed/SF1-100151\n","audio mcep shape (36, 1024)\n","[613:648]svaing file: ./data/processed/SF1-100151_0.npy\n","[613:648]svaing file: ./data/processed/SF1-100151_512.npy\n","save file: ./data/processed/SF1-100058\n","audio mcep shape (36, 1024)\n","[614:648]svaing file: ./data/processed/SF1-100058_0.npy\n","[614:648]svaing file: ./data/processed/SF1-100058_512.npy\n","save file: ./data/processed/SF1-100041\n","audio mcep shape (36, 512)\n","[615:648]svaing file: ./data/processed/SF1-100041_0.npy\n","save file: ./data/processed/SF1-100083\n","audio mcep shape (36, 1024)\n","[616:648]svaing file: ./data/processed/SF1-100083_0.npy\n","[616:648]svaing file: ./data/processed/SF1-100083_512.npy\n","save file: ./data/processed/SF1-100054\n","audio mcep shape (36, 1024)\n","[617:648]svaing file: ./data/processed/SF1-100054_0.npy\n","[617:648]svaing file: ./data/processed/SF1-100054_512.npy\n","save file: ./data/processed/SF1-100085\n","audio mcep shape (36, 1024)\n","[618:648]svaing file: ./data/processed/SF1-100085_0.npy\n","[618:648]svaing file: ./data/processed/SF1-100085_512.npy\n","save file: ./data/processed/SF1-100145\n","audio mcep shape (36, 512)\n","[619:648]svaing file: ./data/processed/SF1-100145_0.npy\n","save file: ./data/processed/SF1-100105\n","audio mcep shape (36, 1536)\n","[620:648]svaing file: ./data/processed/SF1-100105_0.npy\n","[620:648]svaing file: ./data/processed/SF1-100105_512.npy\n","[620:648]svaing file: ./data/processed/SF1-100105_1024.npy\n","save file: ./data/processed/SF1-100099\n","audio mcep shape (36, 1024)\n","[621:648]svaing file: ./data/processed/SF1-100099_0.npy\n","[621:648]svaing file: ./data/processed/SF1-100099_512.npy\n","save file: ./data/processed/SF1-100070\n","audio mcep shape (36, 1536)\n","[622:648]svaing file: ./data/processed/SF1-100070_0.npy\n","[622:648]svaing file: ./data/processed/SF1-100070_512.npy\n","[622:648]svaing file: ./data/processed/SF1-100070_1024.npy\n","save file: ./data/processed/SF1-100157\n","audio mcep shape (36, 1024)\n","[623:648]svaing file: ./data/processed/SF1-100157_0.npy\n","[623:648]svaing file: ./data/processed/SF1-100157_512.npy\n","save file: ./data/processed/SF1-100003\n","audio mcep shape (36, 1024)\n","[624:648]svaing file: ./data/processed/SF1-100003_0.npy\n","[624:648]svaing file: ./data/processed/SF1-100003_512.npy\n","save file: ./data/processed/SF1-100036\n","audio mcep shape (36, 512)\n","[625:648]svaing file: ./data/processed/SF1-100036_0.npy\n","save file: ./data/processed/SF1-100037\n","audio mcep shape (36, 512)\n","[626:648]svaing file: ./data/processed/SF1-100037_0.npy\n","save file: ./data/processed/SF1-100087\n","audio mcep shape (36, 1024)\n","[627:648]svaing file: ./data/processed/SF1-100087_0.npy\n","[627:648]svaing file: ./data/processed/SF1-100087_512.npy\n","save file: ./data/processed/SF1-100045\n","audio mcep shape (36, 1024)\n","[628:648]svaing file: ./data/processed/SF1-100045_0.npy\n","[628:648]svaing file: ./data/processed/SF1-100045_512.npy\n","save file: ./data/processed/SF1-100147\n","audio mcep shape (36, 512)\n","[629:648]svaing file: ./data/processed/SF1-100147_0.npy\n","save file: ./data/processed/SF1-100035\n","audio mcep shape (36, 512)\n","[630:648]svaing file: ./data/processed/SF1-100035_0.npy\n","save file: ./data/processed/SF1-100125\n","audio mcep shape (36, 2048)\n","[631:648]svaing file: ./data/processed/SF1-100125_0.npy\n","[631:648]svaing file: ./data/processed/SF1-100125_512.npy\n","[631:648]svaing file: ./data/processed/SF1-100125_1024.npy\n","[631:648]svaing file: ./data/processed/SF1-100125_1536.npy\n","save file: ./data/processed/SF1-100059\n","audio mcep shape (36, 1024)\n","[632:648]svaing file: ./data/processed/SF1-100059_0.npy\n","[632:648]svaing file: ./data/processed/SF1-100059_512.npy\n","save file: ./data/processed/SF1-100153\n","audio mcep shape (36, 512)\n","[633:648]svaing file: ./data/processed/SF1-100153_0.npy\n","save file: ./data/processed/SF1-100053\n","audio mcep shape (36, 512)\n","[634:648]svaing file: ./data/processed/SF1-100053_0.npy\n","save file: ./data/processed/SF1-100110\n","audio mcep shape (36, 1024)\n","[635:648]svaing file: ./data/processed/SF1-100110_0.npy\n","[635:648]svaing file: ./data/processed/SF1-100110_512.npy\n","save file: ./data/processed/SF1-100062\n","audio mcep shape (36, 1024)\n","[636:648]svaing file: ./data/processed/SF1-100062_0.npy\n","[636:648]svaing file: ./data/processed/SF1-100062_512.npy\n","save file: ./data/processed/SF1-100005\n","audio mcep shape (36, 1024)\n","[637:648]svaing file: ./data/processed/SF1-100005_0.npy\n","[637:648]svaing file: ./data/processed/SF1-100005_512.npy\n","save file: ./data/processed/SF1-100039\n","audio mcep shape (36, 1024)\n","[638:648]svaing file: ./data/processed/SF1-100039_0.npy\n","[638:648]svaing file: ./data/processed/SF1-100039_512.npy\n","save file: ./data/processed/SF1-100122\n","audio mcep shape (36, 1024)\n","[639:648]svaing file: ./data/processed/SF1-100122_0.npy\n","[639:648]svaing file: ./data/processed/SF1-100122_512.npy\n","save file: ./data/processed/SF1-100081\n","audio mcep shape (36, 1536)\n","[640:648]svaing file: ./data/processed/SF1-100081_0.npy\n","[640:648]svaing file: ./data/processed/SF1-100081_512.npy\n","[640:648]svaing file: ./data/processed/SF1-100081_1024.npy\n","save file: ./data/processed/SF1-100048\n","audio mcep shape (36, 1024)\n","[641:648]svaing file: ./data/processed/SF1-100048_0.npy\n","[641:648]svaing file: ./data/processed/SF1-100048_512.npy\n","save file: ./data/processed/SF1-100015\n","audio mcep shape (36, 512)\n","[642:648]svaing file: ./data/processed/SF1-100015_0.npy\n","save file: ./data/processed/SF1-100136\n","audio mcep shape (36, 1024)\n","[643:648]svaing file: ./data/processed/SF1-100136_0.npy\n","[643:648]svaing file: ./data/processed/SF1-100136_512.npy\n","save file: ./data/processed/SF1-100014\n","audio mcep shape (36, 1024)\n","[644:648]svaing file: ./data/processed/SF1-100014_0.npy\n","[644:648]svaing file: ./data/processed/SF1-100014_512.npy\n","save file: ./data/processed/SF1-100159\n","audio mcep shape (36, 1024)\n","[645:648]svaing file: ./data/processed/SF1-100159_0.npy\n","[645:648]svaing file: ./data/processed/SF1-100159_512.npy\n","save file: ./data/processed/SF1-100023\n","audio mcep shape (36, 512)\n","[646:648]svaing file: ./data/processed/SF1-100023_0.npy\n","save file: ./data/processed/SF1-100022\n","audio mcep shape (36, 2048)\n","[647:648]svaing file: ./data/processed/SF1-100022_0.npy\n","[647:648]svaing file: ./data/processed/SF1-100022_512.npy\n","[647:648]svaing file: ./data/processed/SF1-100022_1024.npy\n","[647:648]svaing file: ./data/processed/SF1-100022_1536.npy\n","save file: ./data/processed/SF1-100082\n","audio mcep shape (36, 512)\n","[648:648]svaing file: ./data/processed/SF1-100082_0.npy\n","4.622359930616016 0.18149443343852004\n","save: /content/drive/My Drive/GAN/./etc/TM2-stats.npz\n","4.802003878990561 0.21657566737274403\n","save: /content/drive/My Drive/GAN/./etc/TM1-stats.npz\n","5.4840924506688244 0.25029441717939904\n","save: /content/drive/My Drive/GAN/./etc/SF2-stats.npz\n","5.399196348673834 0.23966063954956976\n","save: /content/drive/My Drive/GAN/./etc/SF1-stats.npz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0WIwQ_P_v4sb","executionInfo":{"status":"ok","timestamp":1604046325238,"user_tz":-330,"elapsed":38804,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"5e89324f-ad6f-4a11-d125-521e90ae9965","colab":{"base_uri":"https://localhost:8080/","height":878}},"source":["!pip install tensorflow==1.8.0\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n","\u001b[K     |████████████████████████████████| 49.1MB 78kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.33.1)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.10.0)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (3.12.4)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.35.1)\n","Collecting tensorboard<1.9.0,>=1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 41.1MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.18.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0) (50.3.2)\n","Collecting html5lib==0.9999999\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K     |████████████████████████████████| 890kB 38.8MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.0.1)\n","Collecting bleach==1.5.0\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.3.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.3.1)\n","Building wheels for collected packages: html5lib\n","  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=4f79d5bf80be72376c47d6d2b5deae249c723fa9a889b509187e917f322251b3\n","  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","Successfully built html5lib\n","Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 3.2.1\n","    Uninstalling bleach-3.2.1:\n","      Successfully uninstalled bleach-3.2.1\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLilDNUPwoig","executionInfo":{"status":"ok","timestamp":1604046400275,"user_tz":-330,"elapsed":2544,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"5f056ded-8131-45a9-b6dd-78bcb7a86139","colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow\n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["1.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTksfSPf36GQ"},"source":["import tensorflow as tf\n","\n","\n","def gated_linear_layer(inputs, gates, name=None):\n","\n","    activation = tf.multiply(x=inputs, y=tf.sigmoid(gates), name=name)\n","\n","    return activation\n","\n","\n","def instance_norm_layer(inputs, epsilon=1e-05, activation_fn=None, name=None):\n","\n","    instance_norm_layer = tf.contrib.layers.instance_norm(\n","        inputs=inputs, center=True, scale=True, epsilon=epsilon, activation_fn=activation_fn, scope=name)\n","\n","    return instance_norm_layer\n","\n","\n","def conv1d_layer(inputs, filters, kernel_size, strides=1, padding='same', activation=None, kernel_initializer=None, name=None):\n","\n","    conv_layer = tf.layers.conv1d(\n","        inputs=inputs,\n","        filters=filters,\n","        kernel_size=kernel_size,\n","        strides=strides,\n","        padding=padding,\n","        activation=activation,\n","        kernel_initializer=kernel_initializer,\n","        name=name)\n","\n","    return conv_layer\n","\n","\n","def conv2d_layer(inputs, filters, kernel_size, strides, padding: list = None, activation=None, kernel_initializer=None, name=None):\n","\n","    p = tf.constant([[0, 0], [padding[0], padding[0]], [padding[1], padding[1]], [0, 0]])\n","    out = tf.pad(inputs, p, name=name + 'conv2d_pad')\n","\n","    conv_layer = tf.layers.conv2d(\n","        inputs=out,\n","        filters=filters,\n","        kernel_size=kernel_size,\n","        strides=strides,\n","        padding='valid',\n","        activation=activation,\n","        kernel_initializer=kernel_initializer,\n","        name=name)\n","\n","    return conv_layer\n","\n","\n","def residual1d_block(inputs, filters=1024, kernel_size=3, strides=1, name_prefix='residule_block_'):\n","\n","    h1 = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_conv')\n","    h1_norm = instance_norm_layer(inputs=h1, activation_fn=None, name=name_prefix + 'h1_norm')\n","    h1_gates = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_gates')\n","    h1_norm_gates = instance_norm_layer(inputs=h1_gates, activation_fn=None, name=name_prefix + 'h1_norm_gates')\n","    h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name=name_prefix + 'h1_glu')\n","    h2 = conv1d_layer(inputs=h1_glu, filters=filters // 2, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h2_conv')\n","    h2_norm = instance_norm_layer(inputs=h2, activation_fn=None, name=name_prefix + 'h2_norm')\n","\n","    h3 = inputs + h2_norm\n","\n","    return h3\n","\n","\n","def downsample1d_block(inputs, filters, kernel_size, strides, name_prefix='downsample1d_block_'):\n","\n","    h1 = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_conv')\n","    h1_norm = instance_norm_layer(inputs=h1, activation_fn=None, name=name_prefix + 'h1_norm')\n","    h1_gates = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_gates')\n","    h1_norm_gates = instance_norm_layer(inputs=h1_gates, activation_fn=None, name=name_prefix + 'h1_norm_gates')\n","    h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name=name_prefix + 'h1_glu')\n","\n","    return h1_glu\n","\n","\n","def downsample2d_block(inputs, filters, kernel_size, strides, padding: list = None, name_prefix='downsample2d_block_'):\n","\n","    h1 = conv2d_layer(\n","        inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=None, name=name_prefix + 'h1_conv')\n","    h1_norm = instance_norm_layer(inputs=h1, activation_fn=None, name=name_prefix + 'h1_norm')\n","    h1_gates = conv2d_layer(\n","        inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=None, name=name_prefix + 'h1_gates')\n","    h1_norm_gates = instance_norm_layer(inputs=h1_gates, activation_fn=None, name=name_prefix + 'h1_norm_gates')\n","    h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name=name_prefix + 'h1_glu')\n","\n","    return h1_glu\n","\n","\n","def upsample1d_block(inputs, filters, kernel_size, strides, shuffle_size=2, name_prefix='upsample1d_block_'):\n","\n","    h1 = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_conv')\n","    h1_shuffle = pixel_shuffler(inputs=h1, shuffle_size=shuffle_size, name=name_prefix + 'h1_shuffle')\n","    h1_norm = instance_norm_layer(inputs=h1_shuffle, activation_fn=None, name=name_prefix + 'h1_norm')\n","\n","    h1_gates = conv1d_layer(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, activation=None, name=name_prefix + 'h1_gates')\n","    h1_shuffle_gates = pixel_shuffler(inputs=h1_gates, shuffle_size=shuffle_size, name=name_prefix + 'h1_shuffle_gates')\n","    h1_norm_gates = instance_norm_layer(inputs=h1_shuffle_gates, activation_fn=None, name=name_prefix + 'h1_norm_gates')\n","\n","    h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name=name_prefix + 'h1_glu')\n","\n","    return h1_glu\n","\n","\n","def upsample2d_block(inputs, filters, kernel_size, strides, name_prefix='upsample2d_block_'):\n","\n","    # t1=tf.layers.Conv2DTranspose(filters,kernel_size,strides, padding='same',name=name_prefix+'conv1')(inputs)\n","    # t1 = tf.layers.batch_normalization()\n","\n","    t1 = tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides, padding='same')(inputs)\n","    # t2 = tf.keras.layers.BatchNormalization()(t1)\n","    t2 = tf.contrib.layers.instance_norm(t1, scope=name_prefix + 'instance1')\n","\n","    x1_gates = tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides, padding='same')(inputs)\n","\n","    # x1_norm_gates = tf.keras.layers.BatchNormalization()(x1_gates)\n","    x1_norm_gates = tf.contrib.layers.instance_norm(x1_gates, scope=name_prefix + 'instance2')\n","    x1_glu = gated_linear_layer(t2, x1_norm_gates)\n","\n","    return x1_glu\n","\n","\n","def pixel_shuffler(inputs, shuffle_size=2, name=None):\n","\n","    n = tf.shape(inputs)[0]\n","    w = tf.shape(inputs)[1]\n","    c = inputs.get_shape().as_list()[2]\n","\n","    oc = c // shuffle_size\n","    ow = w * shuffle_size\n","\n","    outputs = tf.reshape(tensor=inputs, shape=[n, ow, oc], name=name)\n","\n","    return outputs\n","\n","\n","def generator_gatedcnn(inputs, speaker_id=None, reuse=False, scope_name='generator_gatedcnn'):\n","    #input shape [batchsize, h, w, c]\n","    #speaker_id [batchsize, one_hot_vector]\n","    #one_hot_vector：[0,1,0,0]\n","    with tf.variable_scope(scope_name) as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        else:\n","            assert scope.reuse is False\n","\n","        #downsample\n","        d1 = downsample2d_block(inputs, filters=32, kernel_size=[3, 9], strides=[1, 1], padding=[1, 4], name_prefix='down_1')\n","        print(f'd1: {d1.shape.as_list()}')\n","\n","        d2 = downsample2d_block(d1, filters=64, kernel_size=[4, 8], strides=[2, 2], padding=[1, 3], name_prefix='down_2')\n","        print(f'd2: {d2.shape.as_list()}')\n","\n","        d3 = downsample2d_block(d2, filters=128, kernel_size=[4, 8], strides=[2, 2], padding=[1, 3], name_prefix='down_3')\n","        print(f'd3: {d3.shape.as_list()}')\n","\n","        d4 = downsample2d_block(d3, filters=64, kernel_size=[3, 5], strides=[1, 1], padding=[1, 2], name_prefix='down_4')\n","        print(f'd4: {d4.shape.as_list()}')\n","        d5 = downsample2d_block(d4, filters=5, kernel_size=[9, 5], strides=[9, 1], padding=[1, 2], name_prefix='down_5')\n","\n","        #upsample\n","        speaker_id = tf.convert_to_tensor(speaker_id, dtype=tf.float32)\n","        c_cast = tf.cast(tf.reshape(speaker_id, [-1, 1, 1, speaker_id.shape.dims[-1].value]), tf.float32)\n","        c = tf.tile(c_cast, [1, d5.shape.dims[1].value, d5.shape.dims[2].value, 1])\n","        print(c.shape.as_list())\n","        concated = tf.concat([d5, c], axis=-1)\n","        # print(concated.shape.as_list())\n","\n","        u1 = upsample2d_block(concated, 64, kernel_size=[9, 5], strides=[9, 1], name_prefix='gen_up_u1')\n","        print(f'u1.shape :{u1.shape.as_list()}')\n","\n","        c1 = tf.tile(c_cast, [1, u1.shape.dims[1].value, u1.shape.dims[2].value, 1])\n","        print(f'c1 shape: {c1.shape}')\n","        u1_concat = tf.concat([u1, c1], axis=-1)\n","        print(f'u1_concat.shape :{u1_concat.shape.as_list()}')\n","\n","        u2 = upsample2d_block(u1_concat, 128, [3, 5], [1, 1], name_prefix='gen_up_u2')\n","        print(f'u2.shape :{u2.shape.as_list()}')\n","        c2 = tf.tile(c_cast, [1, u2.shape[1], u2.shape[2], 1])\n","        u2_concat = tf.concat([u2, c2], axis=-1)\n","\n","        u3 = upsample2d_block(u2_concat, 64, [4, 8], [2, 2], name_prefix='gen_up_u3')\n","        print(f'u3.shape :{u3.shape.as_list()}')\n","        c3 = tf.tile(c_cast, [1, u3.shape[1], u3.shape[2], 1])\n","        u3_concat = tf.concat([u3, c3], axis=-1)\n","\n","        u4 = upsample2d_block(u3_concat, 32, [4, 8], [2, 2], name_prefix='gen_up_u4')\n","        print(f'u4.shape :{u4.shape.as_list()}')\n","        c4 = tf.tile(c_cast, [1, u4.shape[1], u4.shape[2], 1])\n","        u4_concat = tf.concat([u4, c4], axis=-1)\n","        print(f'u4_concat.shape :{u4_concat.shape.as_list()}')\n","\n","        u5 = tf.layers.Conv2DTranspose(filters=1, kernel_size=[3, 9], strides=[1, 1], padding='same', name='generator_last_deconv')(u4_concat)\n","        print(f'u5.shape :{u5.shape.as_list()}')\n","\n","        return u5\n","\n","\n","def discriminator(inputs, speaker_id, reuse=False, scope_name='discriminator'):\n","\n","    # inputs has shape [batch_size, height,width, channels]\n","\n","    with tf.variable_scope(scope_name) as scope:\n","        # Discriminator would be reused in CycleGAN\n","        if reuse:\n","            scope.reuse_variables()\n","        else:\n","            assert scope.reuse is False\n","        #convert data type to float32\n","        c_cast = tf.cast(tf.reshape(speaker_id, [-1, 1, 1, speaker_id.shape[-1]]), tf.float32)\n","        c = tf.tile(c_cast, [1, inputs.shape[1], inputs.shape[2], 1])\n","\n","        concated = tf.concat([inputs, c], axis=-1)\n","\n","        # Downsample\n","        d1 = downsample2d_block(\n","            inputs=concated, filters=32, kernel_size=[3, 9], strides=[1, 1], padding=[1, 4], name_prefix='downsample2d_dis_block1_')\n","        c1 = tf.tile(c_cast, [1, d1.shape[1], d1.shape[2], 1])\n","        d1_concat = tf.concat([d1, c1], axis=-1)\n","\n","        d2 = downsample2d_block(\n","            inputs=d1_concat, filters=32, kernel_size=[3, 8], strides=[1, 2], padding=[1, 3], name_prefix='downsample2d_dis_block2_')\n","        c2 = tf.tile(c_cast, [1, d2.shape[1], d2.shape[2], 1])\n","        d2_concat = tf.concat([d2, c2], axis=-1)\n","\n","        d3 = downsample2d_block(\n","            inputs=d2_concat, filters=32, kernel_size=[3, 8], strides=[1, 2], padding=[1, 3], name_prefix='downsample2d_dis_block3_')\n","        c3 = tf.tile(c_cast, [1, d3.shape[1], d3.shape[2], 1])\n","        d3_concat = tf.concat([d3, c3], axis=-1)\n","\n","        d4 = downsample2d_block(\n","            inputs=d3_concat, filters=32, kernel_size=[3, 6], strides=[1, 2], padding=[1, 2], name_prefix='downsample2d_diss_block4_')\n","        c4 = tf.tile(c_cast, [1, d4.shape[1], d4.shape[2], 1])\n","        d4_concat = tf.concat([d4, c4], axis=-1)\n","\n","        c1 = conv2d_layer(d4_concat, filters=1, kernel_size=[36, 5], strides=[36, 1], padding=[0, 1], name='discriminator-last-conv')\n","\n","        c1_red = tf.reduce_mean(c1, keepdims=True)\n","\n","        return c1_red\n","\n","\n","def domain_classifier(inputs, reuse=False, scope_name='classifier'):\n","\n","    with tf.variable_scope(scope_name) as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        else:\n","            assert scope.reuse is False\n","\n","        #   add slice input shape [batchsize, 8, 512, 1]\n","        #get one slice\n","        one_slice = inputs[:, 0:8, :, :]\n","\n","        d1 = tf.layers.conv2d(one_slice, 8, kernel_size=[4, 4], padding='same', name=scope_name + '_conv2d01')\n","        d1_p = tf.layers.max_pooling2d(d1, [2, 2], strides=[2, 2], name=scope_name + 'p1')\n","        print(f'domain_classifier_d1: {d1.shape}')\n","        print(f'domain_classifier_d1_p: {d1_p.shape}')\n","\n","        d2 = tf.layers.conv2d(d1_p, 16, [4, 4], padding='same', name=scope_name + '_conv2d02')\n","        d2_p = tf.layers.max_pooling2d(d2, [2, 2], strides=[2, 2], name=scope_name + 'p2')\n","        print(f'domain_classifier_d12: {d2.shape}')\n","        print(f'domain_classifier_d2_p: {d2_p.shape}')\n","\n","        d3 = tf.layers.conv2d(d2_p, 32, [4, 4], padding='same', name=scope_name + '_conv2d03')\n","        d3_p = tf.layers.max_pooling2d(d3, [2, 2], strides=[2, 2], name=scope_name + 'p3')\n","        print(f'domain_classifier_d3: {d3.shape}')\n","        print(f'domain_classifier_d3_p: {d3_p.shape}')\n","\n","        d4 = tf.layers.conv2d(d3_p, 16, [3, 4], padding='same', name=scope_name + '_conv2d04')\n","        d4_p = tf.layers.max_pooling2d(d4, [1, 2], strides=[1, 2], name=scope_name + 'p4')\n","        print(f'domain_classifier_d4: {d4.shape}')\n","        print(f'domain_classifier_d4_p: {d4_p.shape}')\n","\n","        d5 = tf.layers.conv2d(d4_p, 4, [1, 4], padding='same', name=scope_name + '_conv2d05')\n","        d5_p = tf.layers.max_pooling2d(d5, [1, 2], strides=[1, 2], name=scope_name + 'p5')\n","        print(f'domain_classifier_d5: {d5.shape}')\n","        print(f'domain_classifier_d5_p: {d5_p.shape}')\n","\n","        p = tf.keras.layers.GlobalAveragePooling2D()(d5_p)\n","\n","        o_r = tf.reshape(p, [-1, 1, 1, p.shape.dims[1].value])\n","        print(f'classifier_output: {o_r.shape}')\n","\n","        return o_r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_yWcErBhGmD","outputId":"10cab5e7-0282-4219-8a10-f794222e1673","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","\n","import os\n","import numpy as np\n","import argparse\n","import time\n","import librosa\n","import glob\n","from preprocess import *\n","from model import *\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from utility import *\n","\n","\n","def get_files_labels(pattern: str):\n","    files = glob.glob(pattern)\n","    names = []\n","    for f in files:\n","        t = os.path.normpath(f).rsplit(os.sep, maxsplit=1)[1]  #'./data/processed/SF2-100008_11.npy'\n","        name = t.rsplit('.', maxsplit=1)[0]\n","        names.append(name)\n","\n","    return files, names\n","\n","\n","def train(processed_dir: str, test_wav_dir: str):\n","    timestr = time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime())  #like '2018-10-10-14-47'\n","\n","    all_speaker = get_speakers()\n","    label_enc = LabelEncoder()\n","    label_enc.fit(all_speaker)\n","\n","    lambda_cycle = 10\n","    lambda_identity = 5\n","    lambda_classifier = 3\n","\n","    generator_learning_rate = 0.0001\n","    generator_learning_rate_decay = generator_learning_rate / 20000\n","    discriminator_learning_rate = 0.0001\n","    discriminator_learning_rate_decay = discriminator_learning_rate / 20000\n","    domain_classifier_learning_rate = 0.0001\n","    domain_classifier_learning_rate_decay = domain_classifier_learning_rate / 20000\n","    #====================load data================#\n","    print('Loading Data...')\n","\n","    files, names = get_files_labels(os.path.join(processed_dir, '*.npy'))\n","    assert len(files) > 0\n","\n","    normlizer = Normalizer()\n","\n","    exclude_dict = {}  #key that not appear in the value list.(eg. SF1:[TM1**.wav,TM2**.wav,SF2**.wav ... ])\n","    for s in all_speaker:\n","        p = os.path.join(processed_dir, '*.npy')  #'./data/processed/*.npy'\n","        temp = [fn for fn in glob.glob(p) if fn.find(s) == -1]\n","        exclude_dict[s] = temp\n","\n","    print('Loading Data Done.')\n","\n","    #====================create model=============#\n","    BATCHSIZE = 1\n","    model = StarGANVC(num_features=FEATURE_DIM, frames=FRAMES, batchsize=BATCHSIZE)\n","    #====================start train==============#\n","    EPOCH = 200\n","   # print(BATCHSIZE)\n","    num_samples = len(files)\n","    #num_samples = 10\n","    print(num_samples)\n","    print(\"training started..................................................................\")\n","    for epoch in range(1, EPOCH+1, 1):\n","        start_time_epoch = time.time()\n","\n","        files_shuffled, names_shuffled = shuffle(files, names)\n","\n","        for i in range(num_samples // BATCHSIZE):\n","                      \n","            num_iterations = num_samples // BATCHSIZE * (epoch-1) + i\n","            #print(num_iterations)\n","\n","            if num_iterations > 100000:\n","                domain_classifier_learning_rate = max(0, domain_classifier_learning_rate - domain_classifier_learning_rate_decay)\n","                generator_learning_rate = max(0, generator_learning_rate - generator_learning_rate_decay)\n","                discriminator_learning_rate = max(0, discriminator_learning_rate - discriminator_learning_rate_decay)\n","\n","            if discriminator_learning_rate == 0 or generator_learning_rate == 0:\n","                print('Early stop training.')\n","                break\n","\n","            start = i * BATCHSIZE\n","            end = (i + 1) * BATCHSIZE\n","\n","            if end > num_samples:\n","                end = num_samples\n","\n","            X, X_t, y, y_t = [], [], [], []\n","\n","            #get target file paths\n","            batchnames = names_shuffled[start:end]\n","            pre_targets = []\n","            for name in batchnames:\n","                name = name.split(sep='-')[0]  #SF1\n","                t = np.random.choice(exclude_dict[name], 1)[0]\n","                pre_targets.append(t)\n","\n","            #one batch train data\n","            for one_filename, one_name, one_target in zip(files_shuffled[start:end], names_shuffled[start:end], pre_targets):\n","\n","                #target name\n","                t = os.path.normpath(one_target).rsplit(os.sep, maxsplit=1)[1]  #'./data/processed/SF2-100008_11.npy'\n","                target_speaker_name = t.rsplit('.', maxsplit=1)[0].split('-')[0]\n","\n","                #source name\n","                speaker_name = one_name.split('-')[0]  #SF1\n","\n","                #shape [36,512]\n","                one_file = np.load(one_filename)\n","                one_file = normlizer.forward_process(one_file, speaker_name)\n","\n","                #shape [36,512,1]\n","                one_file = np.reshape(one_file, [one_file.shape[0], one_file.shape[1], 1])\n","                X.append(one_file)\n","\n","                #source label\n","                temp_index = label_enc.transform([speaker_name])[0]\n","                temp_arr_s = np.zeros([\n","                    len(all_speaker),\n","                ])\n","                temp_arr_s[temp_index] = 1\n","                y.append(temp_arr_s)\n","\n","                #load target files and labels\n","                one_file_t = np.load(one_target)\n","                one_file_t = normlizer.forward_process(one_file_t, target_speaker_name)\n","\n","                #[36,512,1]\n","                one_file_t = np.reshape(one_file_t, [one_file_t.shape[0], one_file_t.shape[1], 1])\n","                X_t.append(one_file_t)\n","\n","                #target label\n","                temp_index_t = label_enc.transform([target_speaker_name])[0]\n","                temp_arr_t = np.zeros([\n","                    len(all_speaker),\n","                ])\n","                temp_arr_t[temp_index_t] = 1\n","                y_t.append(temp_arr_t)\n","\n","\n","            generator_loss, discriminator_loss, domain_classifier_loss = model.train(\\\n","            input_source=X, input_target=X_t, source_label=y, \\\n","            target_label=y_t, generator_learning_rate=generator_learning_rate,\\\n","             discriminator_learning_rate=discriminator_learning_rate,\\\n","            classifier_learning_rate=domain_classifier_learning_rate, \\\n","            lambda_identity=lambda_identity, lambda_cycle=lambda_cycle,\\\n","            lambda_classifier=lambda_classifier\n","            )\n","\n","            if num_iterations % 10 == 0:\n","                print('Iteration: {:07d},Generator Loss : {:.3f}, Discriminator Loss : {:.3f}, domain_classifier_loss: {:.3f}'\\\n","                .format(num_iterations, generator_loss, discriminator_loss, domain_classifier_loss))\n","\n","        #=======================test model==========================\n","\n","        file_path = os.path.join('out/', f'{epoch}_{timestr}')\n","        if epoch % 1 == 0:\n","            print('============test model============')\n","            #out put path\n","            os.makedirs(file_path, exist_ok=True)                \n","\n","            tempfiles = []\n","            for one_speaker in all_speaker:\n","                p = os.path.join(test_wav_dir, f'{one_speaker}/*.wav')\n","                wavs = glob.glob(p)\n","                tempfiles.append(wavs[0])\n","                tempfiles.append(wavs[1])  #'./data/fourspeakers_test/200006.wav'\n","\n","            for one_file in tempfiles:\n","                _, speaker, name = os.path.normpath(one_file).rsplit(os.sep, maxsplit=2)\n","                wav_, fs = librosa.load(one_file, sr=SAMPLE_RATE, mono=True, dtype=np.float64)\n","                wav, pad_length = pad_wav_to_get_fixed_frames(wav_, frames=FRAMES)\n","\n","                f0, timeaxis = pyworld.harvest(wav, fs)\n","                sp = pyworld.cheaptrick(wav, f0, timeaxis, fs, fft_size=FFTSIZE)\n","                ap = pyworld.d4c(wav, f0, timeaxis, fs, fft_size=FFTSIZE)\n","                coded_sp = pyworld.code_spectral_envelope(sp, fs, FEATURE_DIM)\n","\n","                #one audio file to multiple slices(that's one_test_sample),every slice is an input\n","                one_test_sample = []\n","                csp_transpose = coded_sp.T  #36x512 36x128...\n","                for i in range(0, csp_transpose.shape[1] - FRAMES + 1, FRAMES):\n","                    t = csp_transpose[:, i:i + FRAMES]\n","                    t = normlizer.forward_process(t, speaker)\n","                    t = np.reshape(t, [t.shape[0], t.shape[1], 1])\n","                    one_test_sample.append(t)\n","\n","                #target label 1->2, 2->3, 3->0, 0->1\n","                one_test_sample_label = np.zeros([len(one_test_sample), len(all_speaker)])\n","                temp_index = label_enc.transform([speaker])[0]\n","                temp_index = (temp_index + 2) % len(all_speaker)\n","\n","                for i in range(len(one_test_sample)):\n","                    one_test_sample_label[i][temp_index] = 1\n","\n","                #get conversion target name ,like SF1\n","                target_name = label_enc.inverse_transform([temp_index])[0]\n","\n","                generated_results = model.test(one_test_sample, one_test_sample_label)\n","\n","                reshpaped_res = []\n","                for one in generated_results:\n","                    t = np.reshape(one, [one.shape[0], one.shape[1]])\n","                    t = normlizer.backward_process(t, target_name)\n","                    reshpaped_res.append(t)\n","                #collect the generated slices, and concate the array to be a whole representation of the whole audio\n","                c = []\n","                for one_slice in reshpaped_res:\n","                    one_slice = np.ascontiguousarray(one_slice.T, dtype=np.float64)\n","                    decoded_sp = pyworld.decode_spectral_envelope(one_slice, SAMPLE_RATE, fft_size=FFTSIZE)\n","                    c.append(decoded_sp)\n","\n","                concated = np.concatenate((c), axis=0)\n","\n","                #f0 convert\n","                f0 = normlizer.pitch_conversion(f0, speaker, target_name)\n","                synwav = pyworld.synthesize(f0, concated, ap, fs)\n","                #remove synthesized wav paded length\n","                synwav = synwav[:-pad_length]\n","\n","                #save synthesized wav to file\n","                wavname = f'{speaker}-{target_name}+{name}'\n","                wavpath = os.path.join(file_path, 'wavs')\n","                if not os.path.exists(wavpath):\n","                    os.makedirs(wavpath, exist_ok=True)\n","                librosa.output.write_wav(f'{wavpath}/{wavname}', synwav, sr=fs)\n","                print(f'[save]:{wavpath}/{wavname}')\n","\n","            print('============test finished!============')\n","\n","        if epoch % 1 == 0:\n","            print('============save model============')\n","            model_path = os.path.join(file_path, 'model')\n","            os.makedirs(model_path, exist_ok=True)\n","            print(f'[save]: {model_path}')\n","            model.save(directory=model_path, filename=MODEL_NAME)\n","\n","        end_time_epoch = time.time()\n","        time_elapsed_epoch = end_time_epoch - start_time_epoch\n","\n","        print('Time Elapsed for Epoch %d: %02d:%02d:%02d' % (epoch, time_elapsed_epoch // 3600, (time_elapsed_epoch % 3600 // 60),\n","                                                               (time_elapsed_epoch % 60 // 1)))\n","\n","\n","if __name__ == '__main__':\n","\n","    processed_dir = './data/processed'\n","    test_wav_dir = './data/fourspeakers_test'\n","\n","    parser = argparse.ArgumentParser(description='Train StarGAN Voice conversion model.')\n","\n","    parser.add_argument('--processed_dir', type=str, help='train dataset directory that contains processed npy and npz files', default=processed_dir)\n","    parser.add_argument('--test_wav_dir', type=str, help='test directory that contains raw audios', default=test_wav_dir)\n","    parser.add_argument('-f')\n","    argv = parser.parse_args()\n","\n","    processed_dir = argv.processed_dir\n","    test_wav_dir = argv.test_wav_dir\n","\n","    start_time = time.time()\n","\n","    train(processed_dir, test_wav_dir)\n","\n","    end_time = time.time()\n","    time_elapsed = end_time - start_time\n","\n","    print('Training Time: %02d:%02d:%02d' % \\\n","    (time_elapsed // 3600, (time_elapsed % 3600 // 60), (time_elapsed % 60 // 1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Data...\n","found stat file: ./etc/TM2-stats.npz\n","found stat file: ./etc/TM1-stats.npz\n","found stat file: ./etc/SF2-stats.npz\n","found stat file: ./etc/SF1-stats.npz\n","Loading Data Done.\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","domain_classifier_d1: (?, 8, 512, 8)\n","domain_classifier_d1_p: (?, 4, 256, 8)\n","domain_classifier_d12: (?, 4, 256, 16)\n","domain_classifier_d2_p: (?, 2, 128, 16)\n","domain_classifier_d3: (?, 2, 128, 32)\n","domain_classifier_d3_p: (?, 1, 64, 32)\n","domain_classifier_d4: (?, 1, 64, 16)\n","domain_classifier_d4_p: (?, 1, 32, 16)\n","domain_classifier_d5: (?, 1, 32, 4)\n","domain_classifier_d5_p: (?, 1, 16, 4)\n","classifier_output: (?, 1, 1, 4)\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","domain_classifier_d1: (?, 8, 512, 8)\n","domain_classifier_d1_p: (?, 4, 256, 8)\n","domain_classifier_d12: (?, 4, 256, 16)\n","domain_classifier_d2_p: (?, 2, 128, 16)\n","domain_classifier_d3: (?, 2, 128, 32)\n","domain_classifier_d3_p: (?, 1, 64, 32)\n","domain_classifier_d4: (?, 1, 64, 16)\n","domain_classifier_d4_p: (?, 1, 32, 16)\n","domain_classifier_d5: (?, 1, 32, 4)\n","domain_classifier_d5_p: (?, 1, 16, 4)\n","classifier_output: (?, 1, 1, 4)\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","1170\n","training started..................................................................\n","Iteration: 0000000,Generator Loss : 0.799, Discriminator Loss : 9.829, domain_classifier_loss: 1.191\n","Iteration: 0000010,Generator Loss : 0.597, Discriminator Loss : 9.020, domain_classifier_loss: 1.484\n","Iteration: 0000020,Generator Loss : 0.741, Discriminator Loss : 8.386, domain_classifier_loss: 1.456\n","Iteration: 0000030,Generator Loss : 0.650, Discriminator Loss : 7.629, domain_classifier_loss: 1.491\n","Iteration: 0000040,Generator Loss : 1.321, Discriminator Loss : 7.739, domain_classifier_loss: 1.150\n","Iteration: 0000050,Generator Loss : 0.673, Discriminator Loss : 7.062, domain_classifier_loss: 1.535\n","Iteration: 0000060,Generator Loss : 2.316, Discriminator Loss : 6.036, domain_classifier_loss: 1.510\n","Iteration: 0000070,Generator Loss : 3.126, Discriminator Loss : 6.840, domain_classifier_loss: 1.451\n","Iteration: 0000080,Generator Loss : 1.590, Discriminator Loss : 5.567, domain_classifier_loss: 1.471\n","Iteration: 0000090,Generator Loss : 3.528, Discriminator Loss : 3.283, domain_classifier_loss: 1.395\n","Iteration: 0000100,Generator Loss : 4.189, Discriminator Loss : 4.468, domain_classifier_loss: 1.367\n","Iteration: 0000110,Generator Loss : 2.489, Discriminator Loss : 4.567, domain_classifier_loss: 1.450\n","Iteration: 0000120,Generator Loss : 1.367, Discriminator Loss : 3.213, domain_classifier_loss: 1.478\n","Iteration: 0000130,Generator Loss : 2.005, Discriminator Loss : 3.432, domain_classifier_loss: 1.301\n","Iteration: 0000140,Generator Loss : 2.574, Discriminator Loss : 4.357, domain_classifier_loss: 1.316\n","Iteration: 0000150,Generator Loss : 1.468, Discriminator Loss : 3.060, domain_classifier_loss: 1.295\n","Iteration: 0000160,Generator Loss : 2.362, Discriminator Loss : 2.677, domain_classifier_loss: 1.269\n","Iteration: 0000170,Generator Loss : 1.532, Discriminator Loss : 4.242, domain_classifier_loss: 1.665\n","Iteration: 0000180,Generator Loss : 1.013, Discriminator Loss : 4.088, domain_classifier_loss: 1.249\n","Iteration: 0000190,Generator Loss : 1.809, Discriminator Loss : 3.955, domain_classifier_loss: 1.307\n","Iteration: 0000200,Generator Loss : 1.728, Discriminator Loss : 4.277, domain_classifier_loss: 1.201\n","Iteration: 0000210,Generator Loss : 0.823, Discriminator Loss : 4.349, domain_classifier_loss: 1.715\n","Iteration: 0000220,Generator Loss : 1.382, Discriminator Loss : 2.954, domain_classifier_loss: 1.203\n","Iteration: 0000230,Generator Loss : 1.589, Discriminator Loss : 2.988, domain_classifier_loss: 1.248\n","Iteration: 0000240,Generator Loss : 0.939, Discriminator Loss : 4.448, domain_classifier_loss: 1.646\n","Iteration: 0000250,Generator Loss : 1.510, Discriminator Loss : 3.719, domain_classifier_loss: 1.603\n","Iteration: 0000260,Generator Loss : 1.346, Discriminator Loss : 2.797, domain_classifier_loss: 1.212\n","Iteration: 0000270,Generator Loss : 1.198, Discriminator Loss : 3.902, domain_classifier_loss: 1.471\n","Iteration: 0000280,Generator Loss : 0.274, Discriminator Loss : 4.710, domain_classifier_loss: 1.449\n","Iteration: 0000290,Generator Loss : 0.755, Discriminator Loss : 3.732, domain_classifier_loss: 1.463\n","Iteration: 0000300,Generator Loss : 0.508, Discriminator Loss : 4.311, domain_classifier_loss: 1.421\n","Iteration: 0000310,Generator Loss : 1.065, Discriminator Loss : 3.346, domain_classifier_loss: 1.455\n","Iteration: 0000320,Generator Loss : 1.680, Discriminator Loss : 3.298, domain_classifier_loss: 1.282\n","Iteration: 0000330,Generator Loss : 0.779, Discriminator Loss : 3.627, domain_classifier_loss: 1.380\n","Iteration: 0000340,Generator Loss : 1.332, Discriminator Loss : 3.693, domain_classifier_loss: 1.459\n","Iteration: 0000350,Generator Loss : 1.702, Discriminator Loss : 3.319, domain_classifier_loss: 1.292\n","Iteration: 0000360,Generator Loss : 0.819, Discriminator Loss : 3.427, domain_classifier_loss: 1.410\n","Iteration: 0000370,Generator Loss : 1.781, Discriminator Loss : 3.243, domain_classifier_loss: 1.407\n","Iteration: 0000380,Generator Loss : 0.617, Discriminator Loss : 3.124, domain_classifier_loss: 1.466\n","Iteration: 0000390,Generator Loss : 1.582, Discriminator Loss : 3.023, domain_classifier_loss: 1.409\n","Iteration: 0000400,Generator Loss : 1.161, Discriminator Loss : 3.903, domain_classifier_loss: 1.370\n","Iteration: 0000410,Generator Loss : 0.861, Discriminator Loss : 3.210, domain_classifier_loss: 1.266\n","Iteration: 0000420,Generator Loss : 0.922, Discriminator Loss : 5.099, domain_classifier_loss: 1.487\n","Iteration: 0000430,Generator Loss : 1.574, Discriminator Loss : 3.027, domain_classifier_loss: 1.266\n","Iteration: 0000440,Generator Loss : 1.823, Discriminator Loss : 3.695, domain_classifier_loss: 1.520\n","Iteration: 0000450,Generator Loss : 1.080, Discriminator Loss : 3.553, domain_classifier_loss: 1.538\n","Iteration: 0000460,Generator Loss : 2.807, Discriminator Loss : 2.848, domain_classifier_loss: 1.448\n","Iteration: 0000470,Generator Loss : 2.288, Discriminator Loss : 3.540, domain_classifier_loss: 1.328\n","Iteration: 0000480,Generator Loss : 1.055, Discriminator Loss : 3.887, domain_classifier_loss: 1.417\n","Iteration: 0000490,Generator Loss : 0.620, Discriminator Loss : 4.182, domain_classifier_loss: 1.285\n","Iteration: 0000500,Generator Loss : 1.305, Discriminator Loss : 3.814, domain_classifier_loss: 1.294\n","Iteration: 0000510,Generator Loss : 1.239, Discriminator Loss : 4.121, domain_classifier_loss: 1.414\n","Iteration: 0000520,Generator Loss : 2.366, Discriminator Loss : 3.400, domain_classifier_loss: 1.365\n","Iteration: 0000530,Generator Loss : 1.278, Discriminator Loss : 3.477, domain_classifier_loss: 1.366\n","Iteration: 0000540,Generator Loss : 1.553, Discriminator Loss : 4.003, domain_classifier_loss: 1.552\n","Iteration: 0000550,Generator Loss : 0.830, Discriminator Loss : 3.650, domain_classifier_loss: 1.313\n","Iteration: 0000560,Generator Loss : 1.547, Discriminator Loss : 2.923, domain_classifier_loss: 1.406\n","Iteration: 0000570,Generator Loss : 1.687, Discriminator Loss : 3.735, domain_classifier_loss: 1.318\n","Iteration: 0000580,Generator Loss : 1.654, Discriminator Loss : 4.036, domain_classifier_loss: 1.563\n","Iteration: 0000590,Generator Loss : 2.413, Discriminator Loss : 3.896, domain_classifier_loss: 1.537\n","Iteration: 0000600,Generator Loss : 1.275, Discriminator Loss : 3.115, domain_classifier_loss: 1.327\n","Iteration: 0000610,Generator Loss : 1.193, Discriminator Loss : 2.902, domain_classifier_loss: 1.360\n","Iteration: 0000620,Generator Loss : 1.168, Discriminator Loss : 3.669, domain_classifier_loss: 1.566\n","Iteration: 0000630,Generator Loss : 0.953, Discriminator Loss : 3.092, domain_classifier_loss: 1.210\n","Iteration: 0000640,Generator Loss : 1.252, Discriminator Loss : 3.522, domain_classifier_loss: 1.172\n","Iteration: 0000650,Generator Loss : 0.943, Discriminator Loss : 3.097, domain_classifier_loss: 1.416\n","Iteration: 0000660,Generator Loss : 1.073, Discriminator Loss : 3.534, domain_classifier_loss: 1.391\n","Iteration: 0000670,Generator Loss : 0.929, Discriminator Loss : 3.354, domain_classifier_loss: 1.433\n","Iteration: 0000680,Generator Loss : 0.533, Discriminator Loss : 4.349, domain_classifier_loss: 1.310\n","Iteration: 0000690,Generator Loss : 2.545, Discriminator Loss : 4.002, domain_classifier_loss: 1.351\n","Iteration: 0000700,Generator Loss : 1.362, Discriminator Loss : 3.661, domain_classifier_loss: 1.344\n","Iteration: 0000710,Generator Loss : 0.838, Discriminator Loss : 2.958, domain_classifier_loss: 1.447\n","Iteration: 0000720,Generator Loss : 1.912, Discriminator Loss : 3.565, domain_classifier_loss: 1.320\n","Iteration: 0000730,Generator Loss : 1.468, Discriminator Loss : 3.295, domain_classifier_loss: 1.490\n","Iteration: 0000740,Generator Loss : 1.383, Discriminator Loss : 3.201, domain_classifier_loss: 1.267\n","Iteration: 0000750,Generator Loss : 2.763, Discriminator Loss : 2.426, domain_classifier_loss: 1.516\n","Iteration: 0000760,Generator Loss : 0.872, Discriminator Loss : 2.941, domain_classifier_loss: 1.358\n","Iteration: 0000770,Generator Loss : 1.360, Discriminator Loss : 3.148, domain_classifier_loss: 1.176\n","Iteration: 0000780,Generator Loss : 1.590, Discriminator Loss : 2.792, domain_classifier_loss: 1.174\n","Iteration: 0000790,Generator Loss : 2.348, Discriminator Loss : 3.172, domain_classifier_loss: 1.428\n","Iteration: 0000800,Generator Loss : 0.852, Discriminator Loss : 3.358, domain_classifier_loss: 1.351\n","Iteration: 0000810,Generator Loss : 0.993, Discriminator Loss : 2.859, domain_classifier_loss: 1.220\n","Iteration: 0000820,Generator Loss : 2.055, Discriminator Loss : 3.137, domain_classifier_loss: 1.630\n","Iteration: 0000830,Generator Loss : 0.674, Discriminator Loss : 3.028, domain_classifier_loss: 1.330\n","Iteration: 0000840,Generator Loss : 1.361, Discriminator Loss : 2.946, domain_classifier_loss: 1.417\n","Iteration: 0000850,Generator Loss : 0.832, Discriminator Loss : 2.727, domain_classifier_loss: 1.141\n","Iteration: 0000860,Generator Loss : 0.712, Discriminator Loss : 2.990, domain_classifier_loss: 1.337\n","Iteration: 0000870,Generator Loss : 1.083, Discriminator Loss : 3.095, domain_classifier_loss: 1.315\n","Iteration: 0000880,Generator Loss : 0.643, Discriminator Loss : 3.196, domain_classifier_loss: 1.258\n","Iteration: 0000890,Generator Loss : 1.018, Discriminator Loss : 2.966, domain_classifier_loss: 1.185\n","Iteration: 0000900,Generator Loss : 0.806, Discriminator Loss : 3.419, domain_classifier_loss: 1.508\n","Iteration: 0000910,Generator Loss : 1.187, Discriminator Loss : 3.017, domain_classifier_loss: 1.421\n","Iteration: 0000920,Generator Loss : 0.554, Discriminator Loss : 3.306, domain_classifier_loss: 1.476\n","Iteration: 0000930,Generator Loss : 1.255, Discriminator Loss : 3.019, domain_classifier_loss: 1.347\n","Iteration: 0000940,Generator Loss : 0.887, Discriminator Loss : 2.843, domain_classifier_loss: 1.151\n","Iteration: 0000950,Generator Loss : 1.399, Discriminator Loss : 2.879, domain_classifier_loss: 1.370\n","Iteration: 0000960,Generator Loss : 0.987, Discriminator Loss : 2.910, domain_classifier_loss: 1.222\n","Iteration: 0000970,Generator Loss : 1.772, Discriminator Loss : 2.608, domain_classifier_loss: 1.243\n","Iteration: 0000980,Generator Loss : 1.209, Discriminator Loss : 2.844, domain_classifier_loss: 1.292\n","Iteration: 0000990,Generator Loss : 1.397, Discriminator Loss : 3.008, domain_classifier_loss: 1.399\n","Iteration: 0001000,Generator Loss : 1.059, Discriminator Loss : 2.956, domain_classifier_loss: 1.277\n","Iteration: 0001010,Generator Loss : 0.499, Discriminator Loss : 3.148, domain_classifier_loss: 1.177\n","Iteration: 0001020,Generator Loss : 0.800, Discriminator Loss : 3.435, domain_classifier_loss: 1.209\n","Iteration: 0001030,Generator Loss : 1.272, Discriminator Loss : 2.873, domain_classifier_loss: 1.322\n","Iteration: 0001040,Generator Loss : 0.913, Discriminator Loss : 3.249, domain_classifier_loss: 1.605\n","Iteration: 0001050,Generator Loss : 1.068, Discriminator Loss : 3.143, domain_classifier_loss: 1.328\n","Iteration: 0001060,Generator Loss : 1.508, Discriminator Loss : 2.959, domain_classifier_loss: 1.666\n","Iteration: 0001070,Generator Loss : 0.990, Discriminator Loss : 2.996, domain_classifier_loss: 1.287\n","Iteration: 0001080,Generator Loss : 1.232, Discriminator Loss : 2.861, domain_classifier_loss: 1.261\n","Iteration: 0001090,Generator Loss : 0.985, Discriminator Loss : 3.207, domain_classifier_loss: 1.272\n","Iteration: 0001100,Generator Loss : 0.884, Discriminator Loss : 2.863, domain_classifier_loss: 1.284\n","Iteration: 0001110,Generator Loss : 1.043, Discriminator Loss : 3.388, domain_classifier_loss: 1.501\n","Iteration: 0001120,Generator Loss : 1.207, Discriminator Loss : 2.836, domain_classifier_loss: 1.295\n","Iteration: 0001130,Generator Loss : 0.594, Discriminator Loss : 2.684, domain_classifier_loss: 0.856\n","Iteration: 0001140,Generator Loss : 1.357, Discriminator Loss : 2.337, domain_classifier_loss: 0.916\n","Iteration: 0001150,Generator Loss : 1.045, Discriminator Loss : 3.258, domain_classifier_loss: 1.356\n","Iteration: 0001160,Generator Loss : 1.267, Discriminator Loss : 3.014, domain_classifier_loss: 1.335\n","============test model============\n","[save]:out/1_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/1_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/1_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/1_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/1_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/1_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/1_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/1_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/1_2020-10-29-05-37/model\n","Time Elapsed for Epoch 1: 01:23:10\n","Iteration: 0001170,Generator Loss : 1.064, Discriminator Loss : 3.523, domain_classifier_loss: 1.608\n","Iteration: 0001180,Generator Loss : 0.660, Discriminator Loss : 3.368, domain_classifier_loss: 1.345\n","Iteration: 0001190,Generator Loss : 0.927, Discriminator Loss : 2.898, domain_classifier_loss: 1.308\n","Iteration: 0001200,Generator Loss : 0.981, Discriminator Loss : 3.043, domain_classifier_loss: 1.242\n","Iteration: 0001210,Generator Loss : 1.046, Discriminator Loss : 3.015, domain_classifier_loss: 1.298\n","Iteration: 0001220,Generator Loss : 0.590, Discriminator Loss : 3.317, domain_classifier_loss: 1.282\n","Iteration: 0001230,Generator Loss : 0.911, Discriminator Loss : 3.319, domain_classifier_loss: 1.415\n","Iteration: 0001240,Generator Loss : 1.770, Discriminator Loss : 2.762, domain_classifier_loss: 1.373\n","Iteration: 0001250,Generator Loss : 0.724, Discriminator Loss : 3.158, domain_classifier_loss: 1.215\n","Iteration: 0001260,Generator Loss : 0.607, Discriminator Loss : 3.007, domain_classifier_loss: 1.120\n","Iteration: 0001270,Generator Loss : 1.068, Discriminator Loss : 3.006, domain_classifier_loss: 1.481\n","Iteration: 0001280,Generator Loss : 0.544, Discriminator Loss : 3.610, domain_classifier_loss: 1.441\n","Iteration: 0001290,Generator Loss : 1.303, Discriminator Loss : 2.800, domain_classifier_loss: 1.111\n","Iteration: 0001300,Generator Loss : 1.161, Discriminator Loss : 3.236, domain_classifier_loss: 1.274\n","Iteration: 0001310,Generator Loss : 1.559, Discriminator Loss : 3.186, domain_classifier_loss: 1.283\n","Iteration: 0001320,Generator Loss : 1.703, Discriminator Loss : 3.236, domain_classifier_loss: 1.380\n","Iteration: 0001330,Generator Loss : 1.026, Discriminator Loss : 3.653, domain_classifier_loss: 1.498\n","Iteration: 0001340,Generator Loss : 0.681, Discriminator Loss : 3.704, domain_classifier_loss: 1.191\n","Iteration: 0001350,Generator Loss : 1.212, Discriminator Loss : 3.557, domain_classifier_loss: 1.466\n","Iteration: 0001360,Generator Loss : 0.866, Discriminator Loss : 3.621, domain_classifier_loss: 1.448\n","Iteration: 0001370,Generator Loss : 1.054, Discriminator Loss : 3.682, domain_classifier_loss: 1.376\n","Iteration: 0001380,Generator Loss : 1.250, Discriminator Loss : 3.256, domain_classifier_loss: 1.310\n","Iteration: 0001390,Generator Loss : 1.495, Discriminator Loss : 3.920, domain_classifier_loss: 1.249\n","Iteration: 0001400,Generator Loss : 1.058, Discriminator Loss : 3.802, domain_classifier_loss: 1.266\n","Iteration: 0001410,Generator Loss : 1.098, Discriminator Loss : 4.703, domain_classifier_loss: 1.436\n","Iteration: 0001420,Generator Loss : 1.547, Discriminator Loss : 2.997, domain_classifier_loss: 1.084\n","Iteration: 0001430,Generator Loss : 0.880, Discriminator Loss : 3.357, domain_classifier_loss: 1.312\n","Iteration: 0001440,Generator Loss : 0.880, Discriminator Loss : 3.302, domain_classifier_loss: 1.438\n","Iteration: 0001450,Generator Loss : 0.687, Discriminator Loss : 3.185, domain_classifier_loss: 1.412\n","Iteration: 0001460,Generator Loss : 1.156, Discriminator Loss : 2.770, domain_classifier_loss: 1.434\n","Iteration: 0001470,Generator Loss : 0.442, Discriminator Loss : 3.694, domain_classifier_loss: 1.398\n","Iteration: 0001480,Generator Loss : 0.965, Discriminator Loss : 3.770, domain_classifier_loss: 1.287\n","Iteration: 0001490,Generator Loss : 0.814, Discriminator Loss : 4.086, domain_classifier_loss: 1.416\n","Iteration: 0001500,Generator Loss : 0.950, Discriminator Loss : 3.401, domain_classifier_loss: 1.391\n","Iteration: 0001510,Generator Loss : 0.753, Discriminator Loss : 3.681, domain_classifier_loss: 1.313\n","Iteration: 0001520,Generator Loss : 0.579, Discriminator Loss : 3.298, domain_classifier_loss: 1.153\n","Iteration: 0001530,Generator Loss : 0.512, Discriminator Loss : 3.147, domain_classifier_loss: 1.135\n","Iteration: 0001540,Generator Loss : 0.895, Discriminator Loss : 3.300, domain_classifier_loss: 1.170\n","Iteration: 0001550,Generator Loss : 1.360, Discriminator Loss : 2.645, domain_classifier_loss: 1.061\n","Iteration: 0001560,Generator Loss : 0.766, Discriminator Loss : 3.115, domain_classifier_loss: 1.275\n","Iteration: 0001570,Generator Loss : 0.482, Discriminator Loss : 3.534, domain_classifier_loss: 1.246\n","Iteration: 0001580,Generator Loss : 0.740, Discriminator Loss : 3.049, domain_classifier_loss: 1.268\n","Iteration: 0001590,Generator Loss : 0.803, Discriminator Loss : 2.976, domain_classifier_loss: 1.007\n","Iteration: 0001600,Generator Loss : 2.063, Discriminator Loss : 2.845, domain_classifier_loss: 1.090\n","Iteration: 0001610,Generator Loss : 0.739, Discriminator Loss : 2.691, domain_classifier_loss: 0.795\n","Iteration: 0001620,Generator Loss : 1.060, Discriminator Loss : 3.060, domain_classifier_loss: 1.596\n","Iteration: 0001630,Generator Loss : 1.338, Discriminator Loss : 2.982, domain_classifier_loss: 1.201\n","Iteration: 0001640,Generator Loss : 1.786, Discriminator Loss : 3.284, domain_classifier_loss: 1.238\n","Iteration: 0001650,Generator Loss : 0.857, Discriminator Loss : 3.277, domain_classifier_loss: 1.302\n","Iteration: 0001660,Generator Loss : 1.206, Discriminator Loss : 2.473, domain_classifier_loss: 1.224\n","Iteration: 0001670,Generator Loss : 2.185, Discriminator Loss : 2.447, domain_classifier_loss: 0.882\n","Iteration: 0001680,Generator Loss : 1.176, Discriminator Loss : 2.897, domain_classifier_loss: 1.093\n","Iteration: 0001690,Generator Loss : 0.873, Discriminator Loss : 3.584, domain_classifier_loss: 1.389\n","Iteration: 0001700,Generator Loss : 1.122, Discriminator Loss : 2.921, domain_classifier_loss: 1.142\n","Iteration: 0001710,Generator Loss : 0.676, Discriminator Loss : 3.016, domain_classifier_loss: 1.107\n","Iteration: 0001720,Generator Loss : 0.928, Discriminator Loss : 2.724, domain_classifier_loss: 1.151\n","Iteration: 0001730,Generator Loss : 0.404, Discriminator Loss : 3.924, domain_classifier_loss: 2.209\n","Iteration: 0001740,Generator Loss : 0.685, Discriminator Loss : 2.646, domain_classifier_loss: 1.106\n","Iteration: 0001750,Generator Loss : 0.599, Discriminator Loss : 2.041, domain_classifier_loss: 0.689\n","Iteration: 0001760,Generator Loss : 0.879, Discriminator Loss : 4.010, domain_classifier_loss: 1.647\n","Iteration: 0001770,Generator Loss : 1.164, Discriminator Loss : 2.439, domain_classifier_loss: 1.156\n","Iteration: 0001780,Generator Loss : 1.118, Discriminator Loss : 2.851, domain_classifier_loss: 0.878\n","Iteration: 0001790,Generator Loss : 1.032, Discriminator Loss : 3.388, domain_classifier_loss: 1.210\n","Iteration: 0001800,Generator Loss : 1.179, Discriminator Loss : 2.455, domain_classifier_loss: 0.898\n","Iteration: 0001810,Generator Loss : 0.727, Discriminator Loss : 3.011, domain_classifier_loss: 1.320\n","Iteration: 0001820,Generator Loss : 0.914, Discriminator Loss : 3.105, domain_classifier_loss: 1.231\n","Iteration: 0001830,Generator Loss : 0.901, Discriminator Loss : 2.292, domain_classifier_loss: 1.025\n","Iteration: 0001840,Generator Loss : 2.187, Discriminator Loss : 2.201, domain_classifier_loss: 0.700\n","Iteration: 0001850,Generator Loss : 0.546, Discriminator Loss : 2.921, domain_classifier_loss: 1.150\n","Iteration: 0001860,Generator Loss : 0.777, Discriminator Loss : 3.108, domain_classifier_loss: 1.264\n","Iteration: 0001870,Generator Loss : 1.577, Discriminator Loss : 2.909, domain_classifier_loss: 1.396\n","Iteration: 0001880,Generator Loss : 1.954, Discriminator Loss : 2.392, domain_classifier_loss: 0.588\n","Iteration: 0001890,Generator Loss : 0.572, Discriminator Loss : 3.193, domain_classifier_loss: 1.368\n","Iteration: 0001900,Generator Loss : 0.825, Discriminator Loss : 3.177, domain_classifier_loss: 1.223\n","Iteration: 0001910,Generator Loss : 1.218, Discriminator Loss : 2.992, domain_classifier_loss: 0.787\n","Iteration: 0001920,Generator Loss : 1.055, Discriminator Loss : 2.275, domain_classifier_loss: 0.739\n","Iteration: 0001930,Generator Loss : 1.350, Discriminator Loss : 2.633, domain_classifier_loss: 0.954\n","Iteration: 0001940,Generator Loss : 1.485, Discriminator Loss : 2.493, domain_classifier_loss: 0.335\n","Iteration: 0001950,Generator Loss : 0.789, Discriminator Loss : 2.435, domain_classifier_loss: 1.536\n","Iteration: 0001960,Generator Loss : 1.077, Discriminator Loss : 2.168, domain_classifier_loss: 0.470\n","Iteration: 0001970,Generator Loss : 0.784, Discriminator Loss : 3.588, domain_classifier_loss: 1.336\n","Iteration: 0001980,Generator Loss : 0.624, Discriminator Loss : 3.136, domain_classifier_loss: 1.067\n","Iteration: 0001990,Generator Loss : 0.795, Discriminator Loss : 2.055, domain_classifier_loss: 1.276\n","Iteration: 0002000,Generator Loss : 0.752, Discriminator Loss : 2.468, domain_classifier_loss: 1.055\n","Iteration: 0002010,Generator Loss : 2.189, Discriminator Loss : 2.329, domain_classifier_loss: 1.037\n","Iteration: 0002020,Generator Loss : 1.024, Discriminator Loss : 2.695, domain_classifier_loss: 0.688\n","Iteration: 0002030,Generator Loss : 0.880, Discriminator Loss : 2.850, domain_classifier_loss: 1.194\n","Iteration: 0002040,Generator Loss : 1.747, Discriminator Loss : 3.139, domain_classifier_loss: 0.798\n","Iteration: 0002050,Generator Loss : 1.182, Discriminator Loss : 3.019, domain_classifier_loss: 0.656\n","Iteration: 0002060,Generator Loss : 1.445, Discriminator Loss : 3.221, domain_classifier_loss: 1.510\n","Iteration: 0002070,Generator Loss : 1.023, Discriminator Loss : 3.054, domain_classifier_loss: 1.260\n","Iteration: 0002080,Generator Loss : 1.292, Discriminator Loss : 1.663, domain_classifier_loss: 0.815\n","Iteration: 0002090,Generator Loss : 1.428, Discriminator Loss : 2.639, domain_classifier_loss: 0.261\n","Iteration: 0002100,Generator Loss : 1.929, Discriminator Loss : 2.491, domain_classifier_loss: 0.957\n","Iteration: 0002110,Generator Loss : 0.770, Discriminator Loss : 2.124, domain_classifier_loss: 0.993\n","Iteration: 0002120,Generator Loss : 0.991, Discriminator Loss : 3.887, domain_classifier_loss: 1.315\n","Iteration: 0002130,Generator Loss : 0.698, Discriminator Loss : 3.084, domain_classifier_loss: 1.167\n","Iteration: 0002140,Generator Loss : 1.181, Discriminator Loss : 3.248, domain_classifier_loss: 1.011\n","Iteration: 0002150,Generator Loss : 0.863, Discriminator Loss : 3.496, domain_classifier_loss: 1.302\n","Iteration: 0002160,Generator Loss : 0.847, Discriminator Loss : 2.706, domain_classifier_loss: 0.710\n","Iteration: 0002170,Generator Loss : 1.275, Discriminator Loss : 3.046, domain_classifier_loss: 0.769\n","Iteration: 0002180,Generator Loss : 0.746, Discriminator Loss : 2.366, domain_classifier_loss: 0.646\n","Iteration: 0002190,Generator Loss : 2.408, Discriminator Loss : 2.422, domain_classifier_loss: 1.191\n","Iteration: 0002200,Generator Loss : 0.717, Discriminator Loss : 2.743, domain_classifier_loss: 0.840\n","Iteration: 0002210,Generator Loss : 0.823, Discriminator Loss : 2.381, domain_classifier_loss: 0.669\n","Iteration: 0002220,Generator Loss : 0.760, Discriminator Loss : 2.551, domain_classifier_loss: 0.805\n","Iteration: 0002230,Generator Loss : 1.004, Discriminator Loss : 1.887, domain_classifier_loss: 0.246\n","Iteration: 0002240,Generator Loss : 1.827, Discriminator Loss : 2.650, domain_classifier_loss: 0.938\n","Iteration: 0002250,Generator Loss : 1.266, Discriminator Loss : 2.611, domain_classifier_loss: 0.473\n","Iteration: 0002260,Generator Loss : 1.309, Discriminator Loss : 2.299, domain_classifier_loss: 0.842\n","Iteration: 0002270,Generator Loss : 0.758, Discriminator Loss : 2.525, domain_classifier_loss: 0.562\n","Iteration: 0002280,Generator Loss : 0.939, Discriminator Loss : 2.273, domain_classifier_loss: 0.963\n","Iteration: 0002290,Generator Loss : 1.292, Discriminator Loss : 2.920, domain_classifier_loss: 1.009\n","Iteration: 0002300,Generator Loss : 1.000, Discriminator Loss : 3.527, domain_classifier_loss: 0.486\n","Iteration: 0002310,Generator Loss : 1.099, Discriminator Loss : 2.426, domain_classifier_loss: 0.144\n","Iteration: 0002320,Generator Loss : 0.879, Discriminator Loss : 3.086, domain_classifier_loss: 0.517\n","Iteration: 0002330,Generator Loss : 0.835, Discriminator Loss : 1.492, domain_classifier_loss: 0.484\n","============test model============\n","[save]:out/2_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/2_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/2_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/2_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/2_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/2_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/2_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/2_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/2_2020-10-29-05-37/model\n","Time Elapsed for Epoch 2: 01:22:51\n","Iteration: 0002340,Generator Loss : 1.713, Discriminator Loss : 2.619, domain_classifier_loss: 1.160\n","Iteration: 0002350,Generator Loss : 0.734, Discriminator Loss : 3.683, domain_classifier_loss: 1.163\n","Iteration: 0002360,Generator Loss : 2.042, Discriminator Loss : 2.479, domain_classifier_loss: 0.897\n","Iteration: 0002370,Generator Loss : 0.542, Discriminator Loss : 3.455, domain_classifier_loss: 0.818\n","Iteration: 0002380,Generator Loss : 1.072, Discriminator Loss : 2.674, domain_classifier_loss: 0.989\n","Iteration: 0002390,Generator Loss : 2.670, Discriminator Loss : 3.201, domain_classifier_loss: 0.770\n","Iteration: 0002400,Generator Loss : 0.610, Discriminator Loss : 2.791, domain_classifier_loss: 1.783\n","Iteration: 0002410,Generator Loss : 1.853, Discriminator Loss : 2.909, domain_classifier_loss: 1.490\n","Iteration: 0002420,Generator Loss : 1.159, Discriminator Loss : 2.618, domain_classifier_loss: 0.911\n","Iteration: 0002430,Generator Loss : 0.909, Discriminator Loss : 2.520, domain_classifier_loss: 1.114\n","Iteration: 0002440,Generator Loss : 1.292, Discriminator Loss : 2.969, domain_classifier_loss: 0.793\n","Iteration: 0002450,Generator Loss : 0.816, Discriminator Loss : 3.009, domain_classifier_loss: 1.036\n","Iteration: 0002460,Generator Loss : 1.613, Discriminator Loss : 2.807, domain_classifier_loss: 0.796\n","Iteration: 0002470,Generator Loss : 0.555, Discriminator Loss : 1.986, domain_classifier_loss: 0.530\n","Iteration: 0002480,Generator Loss : 0.562, Discriminator Loss : 3.294, domain_classifier_loss: 0.772\n","Iteration: 0002490,Generator Loss : 1.615, Discriminator Loss : 2.694, domain_classifier_loss: 0.679\n","Iteration: 0002500,Generator Loss : 1.226, Discriminator Loss : 2.965, domain_classifier_loss: 0.508\n","Iteration: 0002510,Generator Loss : 0.662, Discriminator Loss : 3.677, domain_classifier_loss: 0.638\n","Iteration: 0002520,Generator Loss : 0.481, Discriminator Loss : 2.719, domain_classifier_loss: 0.975\n","Iteration: 0002530,Generator Loss : 0.937, Discriminator Loss : 2.629, domain_classifier_loss: 0.817\n","Iteration: 0002540,Generator Loss : 0.958, Discriminator Loss : 2.895, domain_classifier_loss: 0.911\n","Iteration: 0002550,Generator Loss : 0.571, Discriminator Loss : 2.447, domain_classifier_loss: 0.390\n","Iteration: 0002560,Generator Loss : 1.880, Discriminator Loss : 2.038, domain_classifier_loss: 0.114\n","Iteration: 0002570,Generator Loss : 0.567, Discriminator Loss : 2.100, domain_classifier_loss: 0.619\n","Iteration: 0002580,Generator Loss : 0.516, Discriminator Loss : 2.493, domain_classifier_loss: 0.211\n","Iteration: 0002590,Generator Loss : 0.705, Discriminator Loss : 3.854, domain_classifier_loss: 0.848\n","Iteration: 0002600,Generator Loss : 0.908, Discriminator Loss : 2.234, domain_classifier_loss: 1.239\n","Iteration: 0002610,Generator Loss : 0.791, Discriminator Loss : 3.861, domain_classifier_loss: 0.878\n","Iteration: 0002620,Generator Loss : 0.785, Discriminator Loss : 3.724, domain_classifier_loss: 1.330\n","Iteration: 0002630,Generator Loss : 2.229, Discriminator Loss : 2.189, domain_classifier_loss: 0.022\n","Iteration: 0002640,Generator Loss : 0.943, Discriminator Loss : 3.239, domain_classifier_loss: 0.796\n","Iteration: 0002650,Generator Loss : 1.103, Discriminator Loss : 2.824, domain_classifier_loss: 0.951\n","Iteration: 0002660,Generator Loss : 1.269, Discriminator Loss : 2.084, domain_classifier_loss: 0.837\n","Iteration: 0002670,Generator Loss : 1.023, Discriminator Loss : 2.104, domain_classifier_loss: 1.058\n","Iteration: 0002680,Generator Loss : 1.799, Discriminator Loss : 1.770, domain_classifier_loss: 0.342\n","Iteration: 0002690,Generator Loss : 0.587, Discriminator Loss : 2.365, domain_classifier_loss: 0.089\n","Iteration: 0002700,Generator Loss : 0.657, Discriminator Loss : 1.728, domain_classifier_loss: 0.340\n","Iteration: 0002710,Generator Loss : 0.740, Discriminator Loss : 2.639, domain_classifier_loss: 1.146\n","Iteration: 0002720,Generator Loss : 0.423, Discriminator Loss : 2.586, domain_classifier_loss: 0.792\n","Iteration: 0002730,Generator Loss : 0.444, Discriminator Loss : 2.477, domain_classifier_loss: 0.712\n","Iteration: 0002740,Generator Loss : 0.555, Discriminator Loss : 2.358, domain_classifier_loss: 0.707\n","Iteration: 0002750,Generator Loss : 0.659, Discriminator Loss : 2.772, domain_classifier_loss: 0.766\n","Iteration: 0002760,Generator Loss : 0.756, Discriminator Loss : 2.576, domain_classifier_loss: 0.671\n","Iteration: 0002770,Generator Loss : 0.685, Discriminator Loss : 2.261, domain_classifier_loss: 0.258\n","Iteration: 0002780,Generator Loss : 0.815, Discriminator Loss : 2.381, domain_classifier_loss: 0.528\n","Iteration: 0002790,Generator Loss : 1.011, Discriminator Loss : 1.729, domain_classifier_loss: 0.239\n","Iteration: 0002800,Generator Loss : 1.031, Discriminator Loss : 4.068, domain_classifier_loss: 0.452\n","Iteration: 0002810,Generator Loss : 1.882, Discriminator Loss : 2.082, domain_classifier_loss: 0.845\n","Iteration: 0002820,Generator Loss : 0.841, Discriminator Loss : 2.007, domain_classifier_loss: 0.566\n","Iteration: 0002830,Generator Loss : 1.432, Discriminator Loss : 2.203, domain_classifier_loss: 0.690\n","Iteration: 0002840,Generator Loss : 1.122, Discriminator Loss : 1.474, domain_classifier_loss: 0.143\n","Iteration: 0002850,Generator Loss : 0.814, Discriminator Loss : 1.836, domain_classifier_loss: 0.062\n","Iteration: 0002860,Generator Loss : 0.758, Discriminator Loss : 1.911, domain_classifier_loss: 1.848\n","Iteration: 0002870,Generator Loss : 0.866, Discriminator Loss : 1.805, domain_classifier_loss: 0.625\n","Iteration: 0002880,Generator Loss : 1.005, Discriminator Loss : 3.355, domain_classifier_loss: 0.389\n","Iteration: 0002890,Generator Loss : 0.702, Discriminator Loss : 3.140, domain_classifier_loss: 1.181\n","Iteration: 0002900,Generator Loss : 0.987, Discriminator Loss : 2.600, domain_classifier_loss: 0.030\n","Iteration: 0002910,Generator Loss : 0.925, Discriminator Loss : 2.327, domain_classifier_loss: 0.527\n","Iteration: 0002920,Generator Loss : 1.333, Discriminator Loss : 2.507, domain_classifier_loss: 0.881\n","Iteration: 0002930,Generator Loss : 0.663, Discriminator Loss : 2.259, domain_classifier_loss: 0.052\n","Iteration: 0002940,Generator Loss : 0.478, Discriminator Loss : 2.845, domain_classifier_loss: 0.667\n","Iteration: 0002950,Generator Loss : 1.033, Discriminator Loss : 2.041, domain_classifier_loss: 0.132\n","Iteration: 0002960,Generator Loss : 0.599, Discriminator Loss : 2.902, domain_classifier_loss: 0.294\n","Iteration: 0002970,Generator Loss : 1.324, Discriminator Loss : 2.111, domain_classifier_loss: 0.035\n","Iteration: 0002980,Generator Loss : 0.701, Discriminator Loss : 2.010, domain_classifier_loss: 0.134\n","Iteration: 0002990,Generator Loss : 0.977, Discriminator Loss : 3.341, domain_classifier_loss: 0.772\n","Iteration: 0003000,Generator Loss : 1.640, Discriminator Loss : 3.370, domain_classifier_loss: 0.976\n","Iteration: 0003010,Generator Loss : 1.463, Discriminator Loss : 1.725, domain_classifier_loss: 0.757\n","Iteration: 0003020,Generator Loss : 1.016, Discriminator Loss : 1.698, domain_classifier_loss: 0.960\n","Iteration: 0003030,Generator Loss : 1.059, Discriminator Loss : 1.898, domain_classifier_loss: 1.492\n","Iteration: 0003040,Generator Loss : 0.568, Discriminator Loss : 2.436, domain_classifier_loss: 0.680\n","Iteration: 0003050,Generator Loss : 0.956, Discriminator Loss : 1.724, domain_classifier_loss: 0.435\n","Iteration: 0003060,Generator Loss : 0.540, Discriminator Loss : 2.938, domain_classifier_loss: 0.055\n","Iteration: 0003070,Generator Loss : 0.509, Discriminator Loss : 2.246, domain_classifier_loss: 0.527\n","Iteration: 0003080,Generator Loss : 1.269, Discriminator Loss : 2.964, domain_classifier_loss: 0.170\n","Iteration: 0003090,Generator Loss : 0.850, Discriminator Loss : 1.839, domain_classifier_loss: 0.411\n","Iteration: 0003100,Generator Loss : 0.681, Discriminator Loss : 2.656, domain_classifier_loss: 0.396\n","Iteration: 0003110,Generator Loss : 1.067, Discriminator Loss : 2.436, domain_classifier_loss: 0.104\n","Iteration: 0003120,Generator Loss : 0.801, Discriminator Loss : 2.162, domain_classifier_loss: 0.309\n","Iteration: 0003130,Generator Loss : 0.787, Discriminator Loss : 2.645, domain_classifier_loss: 0.642\n","Iteration: 0003140,Generator Loss : 0.865, Discriminator Loss : 2.520, domain_classifier_loss: 1.633\n","Iteration: 0003150,Generator Loss : 0.820, Discriminator Loss : 2.540, domain_classifier_loss: 1.129\n","Iteration: 0003160,Generator Loss : 1.452, Discriminator Loss : 2.002, domain_classifier_loss: 0.127\n","Iteration: 0003170,Generator Loss : 0.940, Discriminator Loss : 2.160, domain_classifier_loss: 0.384\n","Iteration: 0003180,Generator Loss : 0.508, Discriminator Loss : 2.421, domain_classifier_loss: 0.135\n","Iteration: 0003190,Generator Loss : 0.864, Discriminator Loss : 2.035, domain_classifier_loss: 0.132\n","Iteration: 0003200,Generator Loss : 1.351, Discriminator Loss : 2.376, domain_classifier_loss: 0.035\n","Iteration: 0003210,Generator Loss : 1.415, Discriminator Loss : 2.374, domain_classifier_loss: 0.412\n","Iteration: 0003220,Generator Loss : 0.659, Discriminator Loss : 1.652, domain_classifier_loss: 0.527\n","Iteration: 0003230,Generator Loss : 1.175, Discriminator Loss : 2.220, domain_classifier_loss: 0.675\n","Iteration: 0003240,Generator Loss : 0.863, Discriminator Loss : 1.662, domain_classifier_loss: 0.038\n","Iteration: 0003250,Generator Loss : 0.720, Discriminator Loss : 2.337, domain_classifier_loss: 0.644\n","Iteration: 0003260,Generator Loss : 0.705, Discriminator Loss : 2.154, domain_classifier_loss: 0.384\n","Iteration: 0003270,Generator Loss : 0.741, Discriminator Loss : 2.222, domain_classifier_loss: 0.129\n","Iteration: 0003280,Generator Loss : 0.437, Discriminator Loss : 1.801, domain_classifier_loss: 0.864\n","Iteration: 0003290,Generator Loss : 0.592, Discriminator Loss : 1.769, domain_classifier_loss: 0.101\n","Iteration: 0003300,Generator Loss : 0.749, Discriminator Loss : 1.978, domain_classifier_loss: 0.190\n","Iteration: 0003310,Generator Loss : 0.681, Discriminator Loss : 2.837, domain_classifier_loss: 0.297\n","Iteration: 0003320,Generator Loss : 0.702, Discriminator Loss : 2.945, domain_classifier_loss: 0.046\n","Iteration: 0003330,Generator Loss : 1.094, Discriminator Loss : 3.439, domain_classifier_loss: 0.992\n","Iteration: 0003340,Generator Loss : 0.805, Discriminator Loss : 2.135, domain_classifier_loss: 0.571\n","Iteration: 0003350,Generator Loss : 0.544, Discriminator Loss : 2.705, domain_classifier_loss: 0.965\n","Iteration: 0003360,Generator Loss : 0.723, Discriminator Loss : 3.379, domain_classifier_loss: 0.929\n","Iteration: 0003370,Generator Loss : 1.001, Discriminator Loss : 1.996, domain_classifier_loss: 0.572\n","Iteration: 0003380,Generator Loss : 0.767, Discriminator Loss : 2.698, domain_classifier_loss: 0.329\n","Iteration: 0003390,Generator Loss : 1.598, Discriminator Loss : 3.052, domain_classifier_loss: 0.328\n","Iteration: 0003400,Generator Loss : 0.651, Discriminator Loss : 2.213, domain_classifier_loss: 0.871\n","Iteration: 0003410,Generator Loss : 0.989, Discriminator Loss : 4.686, domain_classifier_loss: 0.435\n","Iteration: 0003420,Generator Loss : 0.465, Discriminator Loss : 3.004, domain_classifier_loss: 1.178\n","Iteration: 0003430,Generator Loss : 0.616, Discriminator Loss : 2.170, domain_classifier_loss: 0.356\n","Iteration: 0003440,Generator Loss : 0.824, Discriminator Loss : 2.861, domain_classifier_loss: 0.297\n","Iteration: 0003450,Generator Loss : 0.844, Discriminator Loss : 1.765, domain_classifier_loss: 0.199\n","Iteration: 0003460,Generator Loss : 0.649, Discriminator Loss : 1.820, domain_classifier_loss: 0.253\n","Iteration: 0003470,Generator Loss : 1.003, Discriminator Loss : 2.952, domain_classifier_loss: 0.600\n","Iteration: 0003480,Generator Loss : 0.795, Discriminator Loss : 3.005, domain_classifier_loss: 0.561\n","Iteration: 0003490,Generator Loss : 0.955, Discriminator Loss : 1.516, domain_classifier_loss: 0.955\n","Iteration: 0003500,Generator Loss : 0.758, Discriminator Loss : 2.580, domain_classifier_loss: 0.096\n","============test model============\n","[save]:out/3_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/3_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/3_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/3_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/3_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/3_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/3_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/3_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/3_2020-10-29-05-37/model\n","Time Elapsed for Epoch 3: 01:22:43\n","Iteration: 0003510,Generator Loss : 0.896, Discriminator Loss : 2.032, domain_classifier_loss: 0.620\n","Iteration: 0003520,Generator Loss : 1.059, Discriminator Loss : 2.067, domain_classifier_loss: 0.263\n","Iteration: 0003530,Generator Loss : 0.473, Discriminator Loss : 1.807, domain_classifier_loss: 0.025\n","Iteration: 0003540,Generator Loss : 1.006, Discriminator Loss : 1.710, domain_classifier_loss: 0.968\n","Iteration: 0003550,Generator Loss : 0.854, Discriminator Loss : 2.058, domain_classifier_loss: 0.007\n","Iteration: 0003560,Generator Loss : 0.805, Discriminator Loss : 2.133, domain_classifier_loss: 1.905\n","Iteration: 0003570,Generator Loss : 1.379, Discriminator Loss : 2.607, domain_classifier_loss: 0.939\n","Iteration: 0003580,Generator Loss : 1.079, Discriminator Loss : 3.355, domain_classifier_loss: 0.103\n","Iteration: 0003590,Generator Loss : 0.684, Discriminator Loss : 2.115, domain_classifier_loss: 0.598\n","Iteration: 0003600,Generator Loss : 1.038, Discriminator Loss : 2.397, domain_classifier_loss: 0.408\n","Iteration: 0003610,Generator Loss : 0.664, Discriminator Loss : 1.994, domain_classifier_loss: 0.078\n","Iteration: 0003620,Generator Loss : 0.858, Discriminator Loss : 2.741, domain_classifier_loss: 1.660\n","Iteration: 0003630,Generator Loss : 1.073, Discriminator Loss : 1.768, domain_classifier_loss: 0.030\n","Iteration: 0003640,Generator Loss : 1.999, Discriminator Loss : 1.551, domain_classifier_loss: 0.773\n","Iteration: 0003650,Generator Loss : 1.617, Discriminator Loss : 1.699, domain_classifier_loss: 0.009\n","Iteration: 0003660,Generator Loss : 0.964, Discriminator Loss : 4.340, domain_classifier_loss: 0.099\n","Iteration: 0003670,Generator Loss : 0.707, Discriminator Loss : 3.465, domain_classifier_loss: 0.694\n","Iteration: 0003680,Generator Loss : 0.526, Discriminator Loss : 2.114, domain_classifier_loss: 0.225\n","Iteration: 0003690,Generator Loss : 1.058, Discriminator Loss : 1.364, domain_classifier_loss: 0.061\n","Iteration: 0003700,Generator Loss : 1.353, Discriminator Loss : 1.419, domain_classifier_loss: 0.002\n","Iteration: 0003710,Generator Loss : 1.166, Discriminator Loss : 2.907, domain_classifier_loss: 0.325\n","Iteration: 0003720,Generator Loss : 1.136, Discriminator Loss : 1.994, domain_classifier_loss: 0.949\n","Iteration: 0003730,Generator Loss : 0.693, Discriminator Loss : 2.325, domain_classifier_loss: 0.999\n","Iteration: 0003740,Generator Loss : 1.006, Discriminator Loss : 1.557, domain_classifier_loss: 0.052\n","Iteration: 0003750,Generator Loss : 0.945, Discriminator Loss : 2.044, domain_classifier_loss: 0.389\n","Iteration: 0003760,Generator Loss : 0.603, Discriminator Loss : 2.402, domain_classifier_loss: 0.461\n","Iteration: 0003770,Generator Loss : 3.022, Discriminator Loss : 2.191, domain_classifier_loss: 0.149\n","Iteration: 0003780,Generator Loss : 0.423, Discriminator Loss : 2.495, domain_classifier_loss: 0.018\n","Iteration: 0003790,Generator Loss : 0.479, Discriminator Loss : 2.007, domain_classifier_loss: 0.017\n","Iteration: 0003800,Generator Loss : 1.069, Discriminator Loss : 1.731, domain_classifier_loss: 0.002\n","Iteration: 0003810,Generator Loss : 0.684, Discriminator Loss : 2.838, domain_classifier_loss: 0.046\n","Iteration: 0003820,Generator Loss : 1.155, Discriminator Loss : 2.091, domain_classifier_loss: 0.164\n","Iteration: 0003830,Generator Loss : 0.690, Discriminator Loss : 3.354, domain_classifier_loss: 0.237\n","Iteration: 0003840,Generator Loss : 0.665, Discriminator Loss : 1.493, domain_classifier_loss: 0.286\n","Iteration: 0003850,Generator Loss : 0.727, Discriminator Loss : 1.793, domain_classifier_loss: 0.092\n","Iteration: 0003860,Generator Loss : 0.566, Discriminator Loss : 3.207, domain_classifier_loss: 0.073\n","Iteration: 0003870,Generator Loss : 0.810, Discriminator Loss : 2.654, domain_classifier_loss: 0.582\n","Iteration: 0003880,Generator Loss : 1.077, Discriminator Loss : 3.137, domain_classifier_loss: 0.889\n","Iteration: 0003890,Generator Loss : 0.598, Discriminator Loss : 2.215, domain_classifier_loss: 0.125\n","Iteration: 0003900,Generator Loss : 0.920, Discriminator Loss : 2.284, domain_classifier_loss: 0.012\n","Iteration: 0003910,Generator Loss : 0.965, Discriminator Loss : 3.491, domain_classifier_loss: 0.351\n","Iteration: 0003920,Generator Loss : 0.884, Discriminator Loss : 2.299, domain_classifier_loss: 0.122\n","Iteration: 0003930,Generator Loss : 1.002, Discriminator Loss : 1.200, domain_classifier_loss: 0.364\n","Iteration: 0003940,Generator Loss : 1.282, Discriminator Loss : 1.462, domain_classifier_loss: 0.046\n","Iteration: 0003950,Generator Loss : 0.696, Discriminator Loss : 3.907, domain_classifier_loss: 0.351\n","Iteration: 0003960,Generator Loss : 0.715, Discriminator Loss : 1.814, domain_classifier_loss: 0.057\n","Iteration: 0003970,Generator Loss : 0.820, Discriminator Loss : 2.255, domain_classifier_loss: 0.068\n","Iteration: 0003980,Generator Loss : 0.803, Discriminator Loss : 2.093, domain_classifier_loss: 0.068\n","Iteration: 0003990,Generator Loss : 1.127, Discriminator Loss : 2.846, domain_classifier_loss: 0.053\n","Iteration: 0004000,Generator Loss : 1.409, Discriminator Loss : 1.702, domain_classifier_loss: 0.094\n","Iteration: 0004010,Generator Loss : 1.999, Discriminator Loss : 2.287, domain_classifier_loss: 0.078\n","Iteration: 0004020,Generator Loss : 0.784, Discriminator Loss : 1.870, domain_classifier_loss: 0.091\n","Iteration: 0004030,Generator Loss : 1.564, Discriminator Loss : 1.874, domain_classifier_loss: 0.255\n","Iteration: 0004040,Generator Loss : 1.219, Discriminator Loss : 1.369, domain_classifier_loss: 0.026\n","Iteration: 0004050,Generator Loss : 0.794, Discriminator Loss : 1.628, domain_classifier_loss: 0.025\n","Iteration: 0004060,Generator Loss : 0.627, Discriminator Loss : 3.569, domain_classifier_loss: 1.152\n","Iteration: 0004070,Generator Loss : 0.839, Discriminator Loss : 2.649, domain_classifier_loss: 0.326\n","Iteration: 0004080,Generator Loss : 1.462, Discriminator Loss : 1.327, domain_classifier_loss: 0.003\n","Iteration: 0004090,Generator Loss : 0.867, Discriminator Loss : 2.853, domain_classifier_loss: 0.684\n","Iteration: 0004100,Generator Loss : 0.804, Discriminator Loss : 1.670, domain_classifier_loss: 0.067\n","Iteration: 0004110,Generator Loss : 0.825, Discriminator Loss : 1.892, domain_classifier_loss: 0.287\n","Iteration: 0004120,Generator Loss : 0.714, Discriminator Loss : 1.890, domain_classifier_loss: 0.018\n","Iteration: 0004130,Generator Loss : 1.798, Discriminator Loss : 2.190, domain_classifier_loss: 0.016\n","Iteration: 0004140,Generator Loss : 0.928, Discriminator Loss : 3.157, domain_classifier_loss: 0.065\n","Iteration: 0004150,Generator Loss : 0.868, Discriminator Loss : 1.594, domain_classifier_loss: 0.000\n","Iteration: 0004160,Generator Loss : 1.044, Discriminator Loss : 1.433, domain_classifier_loss: 0.446\n","Iteration: 0004170,Generator Loss : 0.627, Discriminator Loss : 2.008, domain_classifier_loss: 0.040\n","Iteration: 0004180,Generator Loss : 0.783, Discriminator Loss : 1.505, domain_classifier_loss: 0.002\n","Iteration: 0004190,Generator Loss : 0.866, Discriminator Loss : 2.294, domain_classifier_loss: 0.016\n","Iteration: 0004200,Generator Loss : 1.488, Discriminator Loss : 1.555, domain_classifier_loss: 0.030\n","Iteration: 0004210,Generator Loss : 0.683, Discriminator Loss : 2.345, domain_classifier_loss: 0.118\n","Iteration: 0004220,Generator Loss : 0.794, Discriminator Loss : 2.039, domain_classifier_loss: 0.659\n","Iteration: 0004230,Generator Loss : 1.196, Discriminator Loss : 3.605, domain_classifier_loss: 0.136\n","Iteration: 0004240,Generator Loss : 1.063, Discriminator Loss : 2.513, domain_classifier_loss: 0.025\n","Iteration: 0004250,Generator Loss : 0.868, Discriminator Loss : 3.550, domain_classifier_loss: 0.206\n","Iteration: 0004260,Generator Loss : 1.626, Discriminator Loss : 1.424, domain_classifier_loss: 0.017\n","Iteration: 0004270,Generator Loss : 0.843, Discriminator Loss : 1.790, domain_classifier_loss: 0.157\n","Iteration: 0004280,Generator Loss : 1.291, Discriminator Loss : 1.771, domain_classifier_loss: 0.280\n","Iteration: 0004290,Generator Loss : 0.849, Discriminator Loss : 1.582, domain_classifier_loss: 0.780\n","Iteration: 0004300,Generator Loss : 0.667, Discriminator Loss : 1.727, domain_classifier_loss: 0.290\n","Iteration: 0004310,Generator Loss : 0.706, Discriminator Loss : 2.195, domain_classifier_loss: 0.262\n","Iteration: 0004320,Generator Loss : 0.622, Discriminator Loss : 1.709, domain_classifier_loss: 0.027\n","Iteration: 0004330,Generator Loss : 0.959, Discriminator Loss : 3.283, domain_classifier_loss: 0.116\n","Iteration: 0004340,Generator Loss : 0.826, Discriminator Loss : 1.984, domain_classifier_loss: 0.089\n","Iteration: 0004350,Generator Loss : 1.539, Discriminator Loss : 1.648, domain_classifier_loss: 0.016\n","Iteration: 0004360,Generator Loss : 1.277, Discriminator Loss : 4.116, domain_classifier_loss: 0.351\n","Iteration: 0004370,Generator Loss : 1.483, Discriminator Loss : 1.549, domain_classifier_loss: 0.032\n","Iteration: 0004380,Generator Loss : 1.072, Discriminator Loss : 2.671, domain_classifier_loss: 0.719\n","Iteration: 0004390,Generator Loss : 0.834, Discriminator Loss : 2.030, domain_classifier_loss: 0.075\n","Iteration: 0004400,Generator Loss : 1.628, Discriminator Loss : 1.766, domain_classifier_loss: 0.184\n","Iteration: 0004410,Generator Loss : 1.095, Discriminator Loss : 2.410, domain_classifier_loss: 0.199\n","Iteration: 0004420,Generator Loss : 0.700, Discriminator Loss : 3.310, domain_classifier_loss: 0.110\n","Iteration: 0004430,Generator Loss : 0.558, Discriminator Loss : 3.370, domain_classifier_loss: 0.214\n","Iteration: 0004440,Generator Loss : 0.812, Discriminator Loss : 5.965, domain_classifier_loss: 0.257\n","Iteration: 0004450,Generator Loss : 0.906, Discriminator Loss : 2.639, domain_classifier_loss: 0.968\n","Iteration: 0004460,Generator Loss : 0.682, Discriminator Loss : 2.207, domain_classifier_loss: 1.225\n","Iteration: 0004470,Generator Loss : 0.854, Discriminator Loss : 2.363, domain_classifier_loss: 0.006\n","Iteration: 0004480,Generator Loss : 0.826, Discriminator Loss : 3.427, domain_classifier_loss: 0.364\n","Iteration: 0004490,Generator Loss : 0.909, Discriminator Loss : 1.717, domain_classifier_loss: 1.001\n","Iteration: 0004500,Generator Loss : 0.890, Discriminator Loss : 1.388, domain_classifier_loss: 0.003\n","Iteration: 0004510,Generator Loss : 0.775, Discriminator Loss : 2.404, domain_classifier_loss: 0.226\n","Iteration: 0004520,Generator Loss : 0.814, Discriminator Loss : 2.675, domain_classifier_loss: 0.185\n","Iteration: 0004530,Generator Loss : 0.745, Discriminator Loss : 1.652, domain_classifier_loss: 0.041\n","Iteration: 0004540,Generator Loss : 1.199, Discriminator Loss : 1.688, domain_classifier_loss: 0.009\n","Iteration: 0004550,Generator Loss : 1.032, Discriminator Loss : 2.604, domain_classifier_loss: 0.222\n","Iteration: 0004560,Generator Loss : 0.794, Discriminator Loss : 2.158, domain_classifier_loss: 0.228\n","Iteration: 0004570,Generator Loss : 0.719, Discriminator Loss : 1.748, domain_classifier_loss: 0.724\n","Iteration: 0004580,Generator Loss : 2.725, Discriminator Loss : 1.702, domain_classifier_loss: 0.082\n","Iteration: 0004590,Generator Loss : 0.798, Discriminator Loss : 2.770, domain_classifier_loss: 0.105\n","Iteration: 0004600,Generator Loss : 0.717, Discriminator Loss : 1.836, domain_classifier_loss: 0.681\n","Iteration: 0004610,Generator Loss : 1.103, Discriminator Loss : 1.771, domain_classifier_loss: 0.098\n","Iteration: 0004620,Generator Loss : 0.913, Discriminator Loss : 1.998, domain_classifier_loss: 0.005\n","Iteration: 0004630,Generator Loss : 0.514, Discriminator Loss : 2.604, domain_classifier_loss: 0.383\n","Iteration: 0004640,Generator Loss : 0.730, Discriminator Loss : 1.742, domain_classifier_loss: 0.001\n","Iteration: 0004650,Generator Loss : 0.771, Discriminator Loss : 1.917, domain_classifier_loss: 0.263\n","Iteration: 0004660,Generator Loss : 0.632, Discriminator Loss : 1.731, domain_classifier_loss: 0.036\n","Iteration: 0004670,Generator Loss : 0.807, Discriminator Loss : 1.548, domain_classifier_loss: 0.146\n","============test model============\n","[save]:out/4_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/4_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/4_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/4_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/4_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/4_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/4_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/4_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/4_2020-10-29-05-37/model\n","Time Elapsed for Epoch 4: 01:22:39\n","Iteration: 0004680,Generator Loss : 0.635, Discriminator Loss : 2.346, domain_classifier_loss: 0.007\n","Iteration: 0004690,Generator Loss : 0.931, Discriminator Loss : 1.732, domain_classifier_loss: 0.084\n","Iteration: 0004700,Generator Loss : 1.385, Discriminator Loss : 3.188, domain_classifier_loss: 0.083\n","Iteration: 0004710,Generator Loss : 0.583, Discriminator Loss : 2.545, domain_classifier_loss: 0.621\n","Iteration: 0004720,Generator Loss : 0.737, Discriminator Loss : 2.858, domain_classifier_loss: 0.038\n","Iteration: 0004730,Generator Loss : 1.165, Discriminator Loss : 1.703, domain_classifier_loss: 0.110\n","Iteration: 0004740,Generator Loss : 1.048, Discriminator Loss : 2.531, domain_classifier_loss: 0.618\n","Iteration: 0004750,Generator Loss : 1.376, Discriminator Loss : 3.079, domain_classifier_loss: 0.233\n","Iteration: 0004760,Generator Loss : 0.749, Discriminator Loss : 2.123, domain_classifier_loss: 0.219\n","Iteration: 0004770,Generator Loss : 1.408, Discriminator Loss : 1.873, domain_classifier_loss: 0.008\n","Iteration: 0004780,Generator Loss : 0.808, Discriminator Loss : 2.503, domain_classifier_loss: 0.573\n","Iteration: 0004790,Generator Loss : 0.969, Discriminator Loss : 1.742, domain_classifier_loss: 0.018\n","Iteration: 0004800,Generator Loss : 0.863, Discriminator Loss : 1.779, domain_classifier_loss: 0.173\n","Iteration: 0004810,Generator Loss : 0.999, Discriminator Loss : 1.748, domain_classifier_loss: 0.312\n","Iteration: 0004820,Generator Loss : 1.060, Discriminator Loss : 3.068, domain_classifier_loss: 0.181\n","Iteration: 0004830,Generator Loss : 0.948, Discriminator Loss : 2.178, domain_classifier_loss: 0.259\n","Iteration: 0004840,Generator Loss : 0.961, Discriminator Loss : 2.300, domain_classifier_loss: 0.311\n","Iteration: 0004850,Generator Loss : 0.594, Discriminator Loss : 2.249, domain_classifier_loss: 0.028\n","Iteration: 0004860,Generator Loss : 0.943, Discriminator Loss : 2.745, domain_classifier_loss: 0.425\n","Iteration: 0004870,Generator Loss : 0.835, Discriminator Loss : 2.146, domain_classifier_loss: 0.899\n","Iteration: 0004880,Generator Loss : 0.735, Discriminator Loss : 1.603, domain_classifier_loss: 0.235\n","Iteration: 0004890,Generator Loss : 1.003, Discriminator Loss : 2.900, domain_classifier_loss: 0.006\n","Iteration: 0004900,Generator Loss : 0.935, Discriminator Loss : 2.167, domain_classifier_loss: 0.013\n","Iteration: 0004910,Generator Loss : 0.639, Discriminator Loss : 3.218, domain_classifier_loss: 0.207\n","Iteration: 0004920,Generator Loss : 0.523, Discriminator Loss : 2.032, domain_classifier_loss: 0.025\n","Iteration: 0004930,Generator Loss : 0.723, Discriminator Loss : 4.879, domain_classifier_loss: 0.639\n","Iteration: 0004940,Generator Loss : 0.705, Discriminator Loss : 1.779, domain_classifier_loss: 0.075\n","Iteration: 0004950,Generator Loss : 1.241, Discriminator Loss : 1.323, domain_classifier_loss: 0.024\n","Iteration: 0004960,Generator Loss : 0.688, Discriminator Loss : 2.200, domain_classifier_loss: 0.169\n","Iteration: 0004970,Generator Loss : 0.519, Discriminator Loss : 2.507, domain_classifier_loss: 1.172\n","Iteration: 0004980,Generator Loss : 0.845, Discriminator Loss : 2.324, domain_classifier_loss: 0.015\n","Iteration: 0004990,Generator Loss : 1.194, Discriminator Loss : 2.304, domain_classifier_loss: 0.001\n","Iteration: 0005000,Generator Loss : 0.758, Discriminator Loss : 2.436, domain_classifier_loss: 0.044\n","Iteration: 0005010,Generator Loss : 0.787, Discriminator Loss : 2.473, domain_classifier_loss: 0.630\n","Iteration: 0005020,Generator Loss : 0.445, Discriminator Loss : 2.198, domain_classifier_loss: 0.038\n","Iteration: 0005030,Generator Loss : 1.352, Discriminator Loss : 1.484, domain_classifier_loss: 0.021\n","Iteration: 0005040,Generator Loss : 0.559, Discriminator Loss : 3.512, domain_classifier_loss: 0.006\n","Iteration: 0005050,Generator Loss : 0.491, Discriminator Loss : 2.064, domain_classifier_loss: 0.005\n","Iteration: 0005060,Generator Loss : 0.711, Discriminator Loss : 2.933, domain_classifier_loss: 0.050\n","Iteration: 0005070,Generator Loss : 0.797, Discriminator Loss : 1.800, domain_classifier_loss: 0.148\n","Iteration: 0005080,Generator Loss : 0.799, Discriminator Loss : 1.833, domain_classifier_loss: 0.008\n","Iteration: 0005090,Generator Loss : 0.708, Discriminator Loss : 1.694, domain_classifier_loss: 0.076\n","Iteration: 0005100,Generator Loss : 0.940, Discriminator Loss : 1.617, domain_classifier_loss: 0.002\n","Iteration: 0005110,Generator Loss : 0.743, Discriminator Loss : 1.927, domain_classifier_loss: 0.101\n","Iteration: 0005120,Generator Loss : 0.765, Discriminator Loss : 2.281, domain_classifier_loss: 0.206\n","Iteration: 0005130,Generator Loss : 1.219, Discriminator Loss : 1.939, domain_classifier_loss: 0.001\n","Iteration: 0005140,Generator Loss : 0.729, Discriminator Loss : 2.336, domain_classifier_loss: 0.079\n","Iteration: 0005150,Generator Loss : 1.051, Discriminator Loss : 2.571, domain_classifier_loss: 0.064\n","Iteration: 0005160,Generator Loss : 0.704, Discriminator Loss : 1.608, domain_classifier_loss: 0.014\n","Iteration: 0005170,Generator Loss : 0.762, Discriminator Loss : 1.858, domain_classifier_loss: 0.035\n","Iteration: 0005180,Generator Loss : 0.966, Discriminator Loss : 1.788, domain_classifier_loss: 0.092\n","Iteration: 0005190,Generator Loss : 0.855, Discriminator Loss : 2.468, domain_classifier_loss: 0.533\n","Iteration: 0005200,Generator Loss : 0.674, Discriminator Loss : 1.665, domain_classifier_loss: 0.032\n","Iteration: 0005210,Generator Loss : 0.783, Discriminator Loss : 1.791, domain_classifier_loss: 0.001\n","Iteration: 0005220,Generator Loss : 0.641, Discriminator Loss : 2.690, domain_classifier_loss: 0.048\n","Iteration: 0005230,Generator Loss : 0.965, Discriminator Loss : 1.810, domain_classifier_loss: 0.096\n","Iteration: 0005240,Generator Loss : 0.849, Discriminator Loss : 1.803, domain_classifier_loss: 0.028\n","Iteration: 0005250,Generator Loss : 0.790, Discriminator Loss : 1.992, domain_classifier_loss: 0.050\n","Iteration: 0005260,Generator Loss : 0.796, Discriminator Loss : 1.424, domain_classifier_loss: 0.008\n","Iteration: 0005270,Generator Loss : 0.717, Discriminator Loss : 2.649, domain_classifier_loss: 0.469\n","Iteration: 0005280,Generator Loss : 0.908, Discriminator Loss : 1.668, domain_classifier_loss: 0.011\n","Iteration: 0005290,Generator Loss : 1.161, Discriminator Loss : 2.416, domain_classifier_loss: 0.207\n","Iteration: 0005300,Generator Loss : 0.864, Discriminator Loss : 1.728, domain_classifier_loss: 0.257\n","Iteration: 0005310,Generator Loss : 0.943, Discriminator Loss : 1.595, domain_classifier_loss: 0.001\n","Iteration: 0005320,Generator Loss : 0.985, Discriminator Loss : 1.748, domain_classifier_loss: 0.050\n","Iteration: 0005330,Generator Loss : 0.939, Discriminator Loss : 1.723, domain_classifier_loss: 0.001\n","Iteration: 0005340,Generator Loss : 0.860, Discriminator Loss : 2.636, domain_classifier_loss: 0.386\n","Iteration: 0005350,Generator Loss : 0.703, Discriminator Loss : 3.004, domain_classifier_loss: 0.388\n","Iteration: 0005360,Generator Loss : 0.867, Discriminator Loss : 1.993, domain_classifier_loss: 0.046\n","Iteration: 0005370,Generator Loss : 0.808, Discriminator Loss : 1.721, domain_classifier_loss: 0.083\n","Iteration: 0005380,Generator Loss : 1.252, Discriminator Loss : 2.984, domain_classifier_loss: 0.114\n","Iteration: 0005390,Generator Loss : 0.662, Discriminator Loss : 2.773, domain_classifier_loss: 0.314\n","Iteration: 0005400,Generator Loss : 1.462, Discriminator Loss : 2.011, domain_classifier_loss: 0.092\n","Iteration: 0005410,Generator Loss : 0.699, Discriminator Loss : 1.925, domain_classifier_loss: 0.207\n","Iteration: 0005420,Generator Loss : 0.900, Discriminator Loss : 2.354, domain_classifier_loss: 0.043\n","Iteration: 0005440,Generator Loss : 0.482, Discriminator Loss : 1.726, domain_classifier_loss: 0.386\n","Iteration: 0005450,Generator Loss : 0.744, Discriminator Loss : 2.000, domain_classifier_loss: 0.513\n","Iteration: 0005460,Generator Loss : 0.830, Discriminator Loss : 1.993, domain_classifier_loss: 0.009\n","Iteration: 0005470,Generator Loss : 0.921, Discriminator Loss : 3.792, domain_classifier_loss: 0.038\n","Iteration: 0005480,Generator Loss : 0.976, Discriminator Loss : 1.698, domain_classifier_loss: 0.009\n","Iteration: 0005490,Generator Loss : 0.633, Discriminator Loss : 1.724, domain_classifier_loss: 0.072\n","Iteration: 0005500,Generator Loss : 0.748, Discriminator Loss : 2.174, domain_classifier_loss: 0.003\n","Iteration: 0005510,Generator Loss : 0.830, Discriminator Loss : 3.250, domain_classifier_loss: 0.045\n","Iteration: 0005520,Generator Loss : 0.894, Discriminator Loss : 1.823, domain_classifier_loss: 0.238\n","Iteration: 0005530,Generator Loss : 0.819, Discriminator Loss : 2.559, domain_classifier_loss: 0.622\n","Iteration: 0005540,Generator Loss : 0.990, Discriminator Loss : 1.633, domain_classifier_loss: 0.190\n","Iteration: 0005550,Generator Loss : 0.497, Discriminator Loss : 1.516, domain_classifier_loss: 0.010\n","Iteration: 0005560,Generator Loss : 0.857, Discriminator Loss : 1.829, domain_classifier_loss: 0.035\n","Iteration: 0005570,Generator Loss : 0.736, Discriminator Loss : 2.033, domain_classifier_loss: 1.774\n","Iteration: 0005580,Generator Loss : 1.038, Discriminator Loss : 2.124, domain_classifier_loss: 0.004\n","Iteration: 0005590,Generator Loss : 0.703, Discriminator Loss : 1.933, domain_classifier_loss: 0.094\n","Iteration: 0005600,Generator Loss : 0.688, Discriminator Loss : 2.699, domain_classifier_loss: 0.004\n","Iteration: 0005610,Generator Loss : 1.003, Discriminator Loss : 1.740, domain_classifier_loss: 0.006\n","Iteration: 0005620,Generator Loss : 0.720, Discriminator Loss : 2.640, domain_classifier_loss: 0.057\n","Iteration: 0005630,Generator Loss : 0.633, Discriminator Loss : 1.994, domain_classifier_loss: 0.002\n","Iteration: 0005640,Generator Loss : 1.085, Discriminator Loss : 2.798, domain_classifier_loss: 0.134\n","Iteration: 0005650,Generator Loss : 0.855, Discriminator Loss : 2.180, domain_classifier_loss: 0.113\n","Iteration: 0005660,Generator Loss : 0.734, Discriminator Loss : 2.629, domain_classifier_loss: 0.214\n","Iteration: 0005670,Generator Loss : 1.173, Discriminator Loss : 3.656, domain_classifier_loss: 0.378\n","Iteration: 0005680,Generator Loss : 0.952, Discriminator Loss : 2.830, domain_classifier_loss: 0.159\n","Iteration: 0005690,Generator Loss : 0.777, Discriminator Loss : 1.731, domain_classifier_loss: 0.078\n","Iteration: 0005700,Generator Loss : 0.777, Discriminator Loss : 1.866, domain_classifier_loss: 0.146\n","Iteration: 0005710,Generator Loss : 0.898, Discriminator Loss : 2.694, domain_classifier_loss: 0.105\n","Iteration: 0005720,Generator Loss : 0.494, Discriminator Loss : 2.260, domain_classifier_loss: 0.371\n","Iteration: 0005730,Generator Loss : 0.712, Discriminator Loss : 1.684, domain_classifier_loss: 0.005\n","Iteration: 0005740,Generator Loss : 0.986, Discriminator Loss : 1.822, domain_classifier_loss: 0.085\n","Iteration: 0005750,Generator Loss : 1.124, Discriminator Loss : 1.504, domain_classifier_loss: 1.872\n","Iteration: 0005760,Generator Loss : 0.718, Discriminator Loss : 1.802, domain_classifier_loss: 1.615\n","Iteration: 0005770,Generator Loss : 1.069, Discriminator Loss : 1.454, domain_classifier_loss: 0.075\n","Iteration: 0005780,Generator Loss : 0.755, Discriminator Loss : 1.951, domain_classifier_loss: 0.107\n","Iteration: 0005790,Generator Loss : 0.803, Discriminator Loss : 1.875, domain_classifier_loss: 0.026\n","Iteration: 0005800,Generator Loss : 0.715, Discriminator Loss : 1.848, domain_classifier_loss: 0.003\n","Iteration: 0005810,Generator Loss : 0.982, Discriminator Loss : 1.804, domain_classifier_loss: 0.108\n","Iteration: 0005820,Generator Loss : 0.842, Discriminator Loss : 2.941, domain_classifier_loss: 0.587\n","Iteration: 0005830,Generator Loss : 0.943, Discriminator Loss : 1.734, domain_classifier_loss: 0.006\n","Iteration: 0005840,Generator Loss : 0.674, Discriminator Loss : 1.519, domain_classifier_loss: 0.005\n","============test model============\n","[save]:out/5_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/5_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/5_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/5_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/5_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/5_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/5_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/5_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/5_2020-10-29-05-37/model\n","Time Elapsed for Epoch 5: 01:22:25\n","Iteration: 0005850,Generator Loss : 0.828, Discriminator Loss : 2.034, domain_classifier_loss: 0.016\n","Iteration: 0005860,Generator Loss : 0.584, Discriminator Loss : 1.864, domain_classifier_loss: 0.125\n","Iteration: 0005870,Generator Loss : 1.547, Discriminator Loss : 1.681, domain_classifier_loss: 0.011\n","Iteration: 0005880,Generator Loss : 0.802, Discriminator Loss : 2.755, domain_classifier_loss: 0.373\n","Iteration: 0005890,Generator Loss : 1.073, Discriminator Loss : 1.616, domain_classifier_loss: 0.323\n","Iteration: 0005900,Generator Loss : 0.953, Discriminator Loss : 1.647, domain_classifier_loss: 0.001\n","Iteration: 0005910,Generator Loss : 0.837, Discriminator Loss : 1.957, domain_classifier_loss: 0.271\n","Iteration: 0005920,Generator Loss : 0.860, Discriminator Loss : 1.545, domain_classifier_loss: 0.008\n","Iteration: 0005930,Generator Loss : 0.686, Discriminator Loss : 2.973, domain_classifier_loss: 0.043\n","Iteration: 0005940,Generator Loss : 0.661, Discriminator Loss : 2.576, domain_classifier_loss: 0.065\n","Iteration: 0005950,Generator Loss : 0.573, Discriminator Loss : 2.925, domain_classifier_loss: 0.007\n","Iteration: 0005960,Generator Loss : 0.828, Discriminator Loss : 1.817, domain_classifier_loss: 0.116\n","Iteration: 0005970,Generator Loss : 1.054, Discriminator Loss : 1.679, domain_classifier_loss: 0.106\n","Iteration: 0005980,Generator Loss : 1.120, Discriminator Loss : 2.115, domain_classifier_loss: 0.074\n","Iteration: 0005990,Generator Loss : 1.623, Discriminator Loss : 2.140, domain_classifier_loss: 0.000\n","Iteration: 0006000,Generator Loss : 0.920, Discriminator Loss : 1.556, domain_classifier_loss: 0.025\n","Iteration: 0006010,Generator Loss : 0.712, Discriminator Loss : 1.751, domain_classifier_loss: 0.158\n","Iteration: 0006020,Generator Loss : 0.695, Discriminator Loss : 3.367, domain_classifier_loss: 0.022\n","Iteration: 0006030,Generator Loss : 0.990, Discriminator Loss : 6.046, domain_classifier_loss: 0.074\n","Iteration: 0006040,Generator Loss : 0.772, Discriminator Loss : 1.744, domain_classifier_loss: 0.003\n","Iteration: 0006050,Generator Loss : 0.949, Discriminator Loss : 2.397, domain_classifier_loss: 1.555\n","Iteration: 0006060,Generator Loss : 0.700, Discriminator Loss : 1.757, domain_classifier_loss: 0.112\n","Iteration: 0006070,Generator Loss : 1.390, Discriminator Loss : 1.568, domain_classifier_loss: 0.090\n","Iteration: 0006080,Generator Loss : 0.884, Discriminator Loss : 1.886, domain_classifier_loss: 0.002\n","Iteration: 0006090,Generator Loss : 0.703, Discriminator Loss : 1.858, domain_classifier_loss: 0.110\n","Iteration: 0006100,Generator Loss : 0.753, Discriminator Loss : 2.997, domain_classifier_loss: 0.125\n","Iteration: 0006110,Generator Loss : 0.749, Discriminator Loss : 5.589, domain_classifier_loss: 0.106\n","Iteration: 0006120,Generator Loss : 0.792, Discriminator Loss : 1.807, domain_classifier_loss: 0.001\n","Iteration: 0006130,Generator Loss : 0.628, Discriminator Loss : 2.918, domain_classifier_loss: 0.004\n","Iteration: 0006140,Generator Loss : 0.700, Discriminator Loss : 1.941, domain_classifier_loss: 0.005\n","Iteration: 0006150,Generator Loss : 0.728, Discriminator Loss : 3.281, domain_classifier_loss: 0.208\n","Iteration: 0006160,Generator Loss : 0.771, Discriminator Loss : 2.026, domain_classifier_loss: 0.128\n","Iteration: 0006170,Generator Loss : 0.632, Discriminator Loss : 3.657, domain_classifier_loss: 0.064\n","Iteration: 0006180,Generator Loss : 0.730, Discriminator Loss : 2.028, domain_classifier_loss: 0.145\n","Iteration: 0006190,Generator Loss : 1.146, Discriminator Loss : 1.711, domain_classifier_loss: 0.788\n","Iteration: 0006200,Generator Loss : 0.868, Discriminator Loss : 1.706, domain_classifier_loss: 0.001\n","Iteration: 0006210,Generator Loss : 0.665, Discriminator Loss : 1.848, domain_classifier_loss: 0.018\n","Iteration: 0006220,Generator Loss : 0.844, Discriminator Loss : 1.631, domain_classifier_loss: 0.049\n","Iteration: 0006230,Generator Loss : 0.703, Discriminator Loss : 1.599, domain_classifier_loss: 0.001\n","Iteration: 0006240,Generator Loss : 0.837, Discriminator Loss : 3.771, domain_classifier_loss: 0.001\n","Iteration: 0006250,Generator Loss : 0.644, Discriminator Loss : 2.267, domain_classifier_loss: 0.038\n","Iteration: 0006260,Generator Loss : 0.891, Discriminator Loss : 1.818, domain_classifier_loss: 0.239\n","Iteration: 0006270,Generator Loss : 0.741, Discriminator Loss : 1.716, domain_classifier_loss: 0.021\n","Iteration: 0006280,Generator Loss : 0.729, Discriminator Loss : 2.017, domain_classifier_loss: 0.364\n","Iteration: 0006290,Generator Loss : 1.144, Discriminator Loss : 1.746, domain_classifier_loss: 0.000\n","Iteration: 0006300,Generator Loss : 0.752, Discriminator Loss : 1.661, domain_classifier_loss: 0.002\n","Iteration: 0006310,Generator Loss : 0.914, Discriminator Loss : 1.757, domain_classifier_loss: 0.014\n","Iteration: 0006320,Generator Loss : 0.978, Discriminator Loss : 1.520, domain_classifier_loss: 0.047\n","Iteration: 0006330,Generator Loss : 0.782, Discriminator Loss : 1.649, domain_classifier_loss: 0.000\n","Iteration: 0006340,Generator Loss : 1.023, Discriminator Loss : 1.628, domain_classifier_loss: 0.038\n","Iteration: 0006350,Generator Loss : 0.799, Discriminator Loss : 1.754, domain_classifier_loss: 0.000\n","Iteration: 0006360,Generator Loss : 0.811, Discriminator Loss : 1.316, domain_classifier_loss: 1.290\n","Iteration: 0006370,Generator Loss : 0.950, Discriminator Loss : 4.723, domain_classifier_loss: 0.753\n","Iteration: 0006380,Generator Loss : 0.760, Discriminator Loss : 1.882, domain_classifier_loss: 0.004\n","Iteration: 0006390,Generator Loss : 0.988, Discriminator Loss : 1.656, domain_classifier_loss: 0.001\n","Iteration: 0006400,Generator Loss : 0.693, Discriminator Loss : 1.594, domain_classifier_loss: 0.000\n","Iteration: 0006410,Generator Loss : 0.736, Discriminator Loss : 3.701, domain_classifier_loss: 0.085\n","Iteration: 0006420,Generator Loss : 0.849, Discriminator Loss : 2.018, domain_classifier_loss: 0.046\n","Iteration: 0006430,Generator Loss : 1.110, Discriminator Loss : 1.721, domain_classifier_loss: 0.000\n","Iteration: 0006440,Generator Loss : 0.655, Discriminator Loss : 1.556, domain_classifier_loss: 0.001\n","Iteration: 0006450,Generator Loss : 0.799, Discriminator Loss : 1.674, domain_classifier_loss: 0.011\n","Iteration: 0006460,Generator Loss : 1.019, Discriminator Loss : 3.456, domain_classifier_loss: 0.173\n","Iteration: 0006470,Generator Loss : 0.764, Discriminator Loss : 1.756, domain_classifier_loss: 0.001\n","Iteration: 0006480,Generator Loss : 0.706, Discriminator Loss : 1.624, domain_classifier_loss: 0.406\n","Iteration: 0006490,Generator Loss : 0.610, Discriminator Loss : 1.719, domain_classifier_loss: 0.031\n","Iteration: 0006500,Generator Loss : 0.826, Discriminator Loss : 1.606, domain_classifier_loss: 0.036\n","Iteration: 0006510,Generator Loss : 0.727, Discriminator Loss : 1.573, domain_classifier_loss: 0.008\n","Iteration: 0006520,Generator Loss : 0.905, Discriminator Loss : 1.615, domain_classifier_loss: 0.076\n","Iteration: 0006530,Generator Loss : 0.840, Discriminator Loss : 2.347, domain_classifier_loss: 0.000\n","Iteration: 0006540,Generator Loss : 0.972, Discriminator Loss : 2.339, domain_classifier_loss: 0.240\n","Iteration: 0006550,Generator Loss : 0.731, Discriminator Loss : 2.159, domain_classifier_loss: 0.071\n","Iteration: 0006560,Generator Loss : 0.820, Discriminator Loss : 1.860, domain_classifier_loss: 0.032\n","Iteration: 0006570,Generator Loss : 0.835, Discriminator Loss : 1.625, domain_classifier_loss: 0.278\n","Iteration: 0006580,Generator Loss : 0.658, Discriminator Loss : 2.212, domain_classifier_loss: 0.021\n","Iteration: 0006590,Generator Loss : 0.804, Discriminator Loss : 1.560, domain_classifier_loss: 1.885\n","Iteration: 0006600,Generator Loss : 0.865, Discriminator Loss : 1.611, domain_classifier_loss: 0.026\n","Iteration: 0006610,Generator Loss : 0.951, Discriminator Loss : 1.898, domain_classifier_loss: 0.222\n","Iteration: 0006620,Generator Loss : 0.827, Discriminator Loss : 1.888, domain_classifier_loss: 0.063\n","Iteration: 0006630,Generator Loss : 0.641, Discriminator Loss : 2.434, domain_classifier_loss: 0.095\n","Iteration: 0006640,Generator Loss : 0.875, Discriminator Loss : 1.642, domain_classifier_loss: 0.196\n","Iteration: 0006650,Generator Loss : 1.174, Discriminator Loss : 1.536, domain_classifier_loss: 0.103\n","Iteration: 0006660,Generator Loss : 0.718, Discriminator Loss : 1.667, domain_classifier_loss: 0.000\n","Iteration: 0006670,Generator Loss : 0.921, Discriminator Loss : 1.705, domain_classifier_loss: 0.001\n","Iteration: 0006680,Generator Loss : 0.674, Discriminator Loss : 1.765, domain_classifier_loss: 0.019\n","Iteration: 0006690,Generator Loss : 0.765, Discriminator Loss : 2.830, domain_classifier_loss: 0.017\n","Iteration: 0006700,Generator Loss : 0.808, Discriminator Loss : 1.683, domain_classifier_loss: 0.134\n","Iteration: 0006710,Generator Loss : 0.849, Discriminator Loss : 2.870, domain_classifier_loss: 0.058\n","Iteration: 0006720,Generator Loss : 0.802, Discriminator Loss : 1.575, domain_classifier_loss: 0.015\n","Iteration: 0006730,Generator Loss : 0.682, Discriminator Loss : 1.750, domain_classifier_loss: 0.008\n","Iteration: 0006740,Generator Loss : 0.975, Discriminator Loss : 2.052, domain_classifier_loss: 0.100\n","Iteration: 0006750,Generator Loss : 0.622, Discriminator Loss : 2.275, domain_classifier_loss: 0.091\n","Iteration: 0006760,Generator Loss : 0.803, Discriminator Loss : 1.653, domain_classifier_loss: 0.014\n","Iteration: 0006770,Generator Loss : 1.254, Discriminator Loss : 2.225, domain_classifier_loss: 0.010\n","Iteration: 0006780,Generator Loss : 0.780, Discriminator Loss : 1.585, domain_classifier_loss: 0.014\n","Iteration: 0006790,Generator Loss : 0.708, Discriminator Loss : 1.799, domain_classifier_loss: 0.003\n","Iteration: 0006800,Generator Loss : 0.954, Discriminator Loss : 1.781, domain_classifier_loss: 0.017\n","Iteration: 0006810,Generator Loss : 0.716, Discriminator Loss : 1.791, domain_classifier_loss: 0.035\n","Iteration: 0006820,Generator Loss : 0.774, Discriminator Loss : 2.486, domain_classifier_loss: 0.028\n","Iteration: 0006830,Generator Loss : 0.903, Discriminator Loss : 1.463, domain_classifier_loss: 0.043\n","Iteration: 0006840,Generator Loss : 0.919, Discriminator Loss : 2.116, domain_classifier_loss: 0.007\n","Iteration: 0006850,Generator Loss : 0.756, Discriminator Loss : 2.011, domain_classifier_loss: 0.000\n","Iteration: 0006860,Generator Loss : 0.953, Discriminator Loss : 3.842, domain_classifier_loss: 0.046\n","Iteration: 0006870,Generator Loss : 0.908, Discriminator Loss : 2.150, domain_classifier_loss: 0.169\n","Iteration: 0006880,Generator Loss : 0.789, Discriminator Loss : 2.394, domain_classifier_loss: 0.010\n","Iteration: 0006890,Generator Loss : 0.717, Discriminator Loss : 2.333, domain_classifier_loss: 0.025\n","Iteration: 0006900,Generator Loss : 1.066, Discriminator Loss : 2.363, domain_classifier_loss: 0.014\n","Iteration: 0006910,Generator Loss : 0.900, Discriminator Loss : 1.609, domain_classifier_loss: 0.026\n","Iteration: 0006920,Generator Loss : 0.646, Discriminator Loss : 1.323, domain_classifier_loss: 0.006\n","Iteration: 0006930,Generator Loss : 0.548, Discriminator Loss : 3.967, domain_classifier_loss: 0.016\n","Iteration: 0006940,Generator Loss : 0.695, Discriminator Loss : 2.174, domain_classifier_loss: 0.002\n","Iteration: 0006950,Generator Loss : 1.821, Discriminator Loss : 1.589, domain_classifier_loss: 0.042\n","Iteration: 0006960,Generator Loss : 1.039, Discriminator Loss : 1.308, domain_classifier_loss: 0.002\n","Iteration: 0006970,Generator Loss : 0.917, Discriminator Loss : 2.014, domain_classifier_loss: 0.044\n","Iteration: 0006980,Generator Loss : 1.029, Discriminator Loss : 1.719, domain_classifier_loss: 0.388\n","Iteration: 0006990,Generator Loss : 0.829, Discriminator Loss : 1.694, domain_classifier_loss: 0.100\n","Iteration: 0007000,Generator Loss : 1.018, Discriminator Loss : 1.492, domain_classifier_loss: 0.122\n","Iteration: 0007010,Generator Loss : 0.662, Discriminator Loss : 1.696, domain_classifier_loss: 0.403\n","============test model============\n","[save]:out/6_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/6_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/6_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/6_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/6_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/6_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/6_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/6_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/6_2020-10-29-05-37/model\n","Time Elapsed for Epoch 6: 01:22:22\n","Iteration: 0007020,Generator Loss : 0.750, Discriminator Loss : 1.617, domain_classifier_loss: 0.228\n","Iteration: 0007030,Generator Loss : 0.583, Discriminator Loss : 1.774, domain_classifier_loss: 0.037\n","Iteration: 0007040,Generator Loss : 0.709, Discriminator Loss : 1.596, domain_classifier_loss: 0.002\n","Iteration: 0007050,Generator Loss : 0.839, Discriminator Loss : 1.964, domain_classifier_loss: 0.012\n","Iteration: 0007060,Generator Loss : 0.824, Discriminator Loss : 3.402, domain_classifier_loss: 0.048\n","Iteration: 0007070,Generator Loss : 0.557, Discriminator Loss : 1.999, domain_classifier_loss: 0.001\n","Iteration: 0007080,Generator Loss : 0.910, Discriminator Loss : 2.304, domain_classifier_loss: 0.090\n","Iteration: 0007090,Generator Loss : 0.940, Discriminator Loss : 1.561, domain_classifier_loss: 0.120\n","Iteration: 0007100,Generator Loss : 0.713, Discriminator Loss : 1.846, domain_classifier_loss: 0.041\n","Iteration: 0007110,Generator Loss : 0.698, Discriminator Loss : 1.734, domain_classifier_loss: 0.160\n","Iteration: 0007120,Generator Loss : 0.681, Discriminator Loss : 1.613, domain_classifier_loss: 0.001\n","Iteration: 0007130,Generator Loss : 0.983, Discriminator Loss : 1.958, domain_classifier_loss: 0.023\n","Iteration: 0007140,Generator Loss : 0.728, Discriminator Loss : 1.660, domain_classifier_loss: 0.031\n","Iteration: 0007150,Generator Loss : 0.688, Discriminator Loss : 2.151, domain_classifier_loss: 0.689\n","Iteration: 0007160,Generator Loss : 0.661, Discriminator Loss : 1.922, domain_classifier_loss: 0.021\n","Iteration: 0007170,Generator Loss : 0.743, Discriminator Loss : 1.405, domain_classifier_loss: 0.207\n","Iteration: 0007180,Generator Loss : 0.739, Discriminator Loss : 1.870, domain_classifier_loss: 0.004\n","Iteration: 0007190,Generator Loss : 0.774, Discriminator Loss : 1.438, domain_classifier_loss: 0.001\n","Iteration: 0007200,Generator Loss : 0.676, Discriminator Loss : 1.549, domain_classifier_loss: 0.000\n","Iteration: 0007210,Generator Loss : 0.705, Discriminator Loss : 1.582, domain_classifier_loss: 0.040\n","Iteration: 0007220,Generator Loss : 0.957, Discriminator Loss : 2.187, domain_classifier_loss: 0.001\n","Iteration: 0007230,Generator Loss : 1.144, Discriminator Loss : 1.811, domain_classifier_loss: 0.030\n","Iteration: 0007240,Generator Loss : 0.809, Discriminator Loss : 2.056, domain_classifier_loss: 0.000\n","Iteration: 0007250,Generator Loss : 1.055, Discriminator Loss : 1.456, domain_classifier_loss: 0.008\n","Iteration: 0007260,Generator Loss : 0.822, Discriminator Loss : 1.602, domain_classifier_loss: 0.039\n","Iteration: 0007270,Generator Loss : 0.753, Discriminator Loss : 1.760, domain_classifier_loss: 0.002\n","Iteration: 0007280,Generator Loss : 0.611, Discriminator Loss : 1.572, domain_classifier_loss: 0.007\n","Iteration: 0007290,Generator Loss : 0.883, Discriminator Loss : 1.634, domain_classifier_loss: 0.008\n","Iteration: 0007300,Generator Loss : 0.482, Discriminator Loss : 4.208, domain_classifier_loss: 0.004\n","Iteration: 0007310,Generator Loss : 0.797, Discriminator Loss : 1.825, domain_classifier_loss: 0.264\n","Iteration: 0007320,Generator Loss : 0.697, Discriminator Loss : 2.676, domain_classifier_loss: 0.043\n","Iteration: 0007330,Generator Loss : 1.236, Discriminator Loss : 1.710, domain_classifier_loss: 0.285\n","Iteration: 0007340,Generator Loss : 0.909, Discriminator Loss : 1.732, domain_classifier_loss: 0.028\n","Iteration: 0007350,Generator Loss : 0.765, Discriminator Loss : 1.563, domain_classifier_loss: 0.000\n","Iteration: 0007360,Generator Loss : 0.677, Discriminator Loss : 1.911, domain_classifier_loss: 0.051\n","Iteration: 0007370,Generator Loss : 0.729, Discriminator Loss : 1.992, domain_classifier_loss: 0.027\n","Iteration: 0007380,Generator Loss : 0.764, Discriminator Loss : 1.898, domain_classifier_loss: 0.351\n","Iteration: 0007390,Generator Loss : 0.647, Discriminator Loss : 7.197, domain_classifier_loss: 0.129\n","Iteration: 0007400,Generator Loss : 0.965, Discriminator Loss : 1.451, domain_classifier_loss: 0.024\n","Iteration: 0007410,Generator Loss : 0.772, Discriminator Loss : 1.999, domain_classifier_loss: 0.098\n","Iteration: 0007420,Generator Loss : 0.826, Discriminator Loss : 1.555, domain_classifier_loss: 0.012\n","Iteration: 0007430,Generator Loss : 0.763, Discriminator Loss : 5.870, domain_classifier_loss: 0.004\n","Iteration: 0007440,Generator Loss : 0.668, Discriminator Loss : 2.057, domain_classifier_loss: 0.038\n","Iteration: 0007450,Generator Loss : 0.791, Discriminator Loss : 1.688, domain_classifier_loss: 0.126\n","Iteration: 0007460,Generator Loss : 0.749, Discriminator Loss : 1.843, domain_classifier_loss: 0.067\n","Iteration: 0007470,Generator Loss : 1.013, Discriminator Loss : 1.781, domain_classifier_loss: 0.009\n","Iteration: 0007480,Generator Loss : 0.990, Discriminator Loss : 3.283, domain_classifier_loss: 0.005\n","Iteration: 0007490,Generator Loss : 0.587, Discriminator Loss : 2.656, domain_classifier_loss: 0.006\n","Iteration: 0007500,Generator Loss : 0.733, Discriminator Loss : 1.639, domain_classifier_loss: 0.007\n","Iteration: 0007510,Generator Loss : 0.707, Discriminator Loss : 3.018, domain_classifier_loss: 0.005\n","Iteration: 0007520,Generator Loss : 0.962, Discriminator Loss : 2.251, domain_classifier_loss: 0.439\n","Iteration: 0007530,Generator Loss : 0.682, Discriminator Loss : 1.601, domain_classifier_loss: 0.003\n","Iteration: 0007540,Generator Loss : 0.629, Discriminator Loss : 1.637, domain_classifier_loss: 0.001\n","Iteration: 0007550,Generator Loss : 0.905, Discriminator Loss : 2.264, domain_classifier_loss: 0.012\n","Iteration: 0007560,Generator Loss : 0.893, Discriminator Loss : 8.596, domain_classifier_loss: 0.140\n","Iteration: 0007570,Generator Loss : 0.907, Discriminator Loss : 2.054, domain_classifier_loss: 0.027\n","Iteration: 0007580,Generator Loss : 0.773, Discriminator Loss : 1.702, domain_classifier_loss: 0.034\n","Iteration: 0007590,Generator Loss : 0.650, Discriminator Loss : 1.826, domain_classifier_loss: 0.048\n","Iteration: 0007600,Generator Loss : 0.844, Discriminator Loss : 1.524, domain_classifier_loss: 0.000\n","Iteration: 0007610,Generator Loss : 0.858, Discriminator Loss : 1.645, domain_classifier_loss: 0.040\n","Iteration: 0007620,Generator Loss : 0.754, Discriminator Loss : 1.510, domain_classifier_loss: 0.451\n","Iteration: 0007630,Generator Loss : 0.924, Discriminator Loss : 1.230, domain_classifier_loss: 0.002\n","Iteration: 0007640,Generator Loss : 0.709, Discriminator Loss : 1.593, domain_classifier_loss: 0.335\n","Iteration: 0007650,Generator Loss : 0.824, Discriminator Loss : 1.587, domain_classifier_loss: 0.078\n","Iteration: 0007660,Generator Loss : 0.528, Discriminator Loss : 3.413, domain_classifier_loss: 0.002\n","Iteration: 0007670,Generator Loss : 1.151, Discriminator Loss : 2.738, domain_classifier_loss: 0.007\n","Iteration: 0007680,Generator Loss : 0.752, Discriminator Loss : 1.806, domain_classifier_loss: 0.000\n","Iteration: 0007690,Generator Loss : 0.822, Discriminator Loss : 2.192, domain_classifier_loss: 0.023\n","Iteration: 0007700,Generator Loss : 1.437, Discriminator Loss : 1.726, domain_classifier_loss: 0.000\n","Iteration: 0007710,Generator Loss : 0.851, Discriminator Loss : 1.672, domain_classifier_loss: 0.749\n","Iteration: 0007720,Generator Loss : 0.871, Discriminator Loss : 1.945, domain_classifier_loss: 0.373\n","Iteration: 0007730,Generator Loss : 0.734, Discriminator Loss : 1.881, domain_classifier_loss: 0.035\n","Iteration: 0007740,Generator Loss : 0.823, Discriminator Loss : 2.475, domain_classifier_loss: 0.473\n","Iteration: 0007750,Generator Loss : 0.809, Discriminator Loss : 1.745, domain_classifier_loss: 0.004\n","Iteration: 0007760,Generator Loss : 0.592, Discriminator Loss : 1.970, domain_classifier_loss: 0.016\n","Iteration: 0007770,Generator Loss : 0.848, Discriminator Loss : 2.010, domain_classifier_loss: 0.001\n","Iteration: 0007780,Generator Loss : 0.811, Discriminator Loss : 6.032, domain_classifier_loss: 0.202\n","Iteration: 0007790,Generator Loss : 0.745, Discriminator Loss : 1.624, domain_classifier_loss: 0.007\n","Iteration: 0007800,Generator Loss : 1.557, Discriminator Loss : 1.922, domain_classifier_loss: 0.218\n","Iteration: 0007810,Generator Loss : 0.633, Discriminator Loss : 6.433, domain_classifier_loss: 0.004\n","Iteration: 0007820,Generator Loss : 0.841, Discriminator Loss : 1.164, domain_classifier_loss: 0.001\n","Iteration: 0007830,Generator Loss : 0.565, Discriminator Loss : 10.795, domain_classifier_loss: 0.223\n","Iteration: 0007840,Generator Loss : 0.875, Discriminator Loss : 1.052, domain_classifier_loss: 0.005\n","Iteration: 0007850,Generator Loss : 0.797, Discriminator Loss : 2.038, domain_classifier_loss: 0.138\n","Iteration: 0007860,Generator Loss : 0.783, Discriminator Loss : 1.784, domain_classifier_loss: 0.157\n","Iteration: 0007870,Generator Loss : 0.746, Discriminator Loss : 1.685, domain_classifier_loss: 0.063\n","Iteration: 0007880,Generator Loss : 0.900, Discriminator Loss : 1.837, domain_classifier_loss: 0.000\n","Iteration: 0007890,Generator Loss : 1.067, Discriminator Loss : 1.679, domain_classifier_loss: 0.010\n","Iteration: 0007900,Generator Loss : 0.892, Discriminator Loss : 1.927, domain_classifier_loss: 0.006\n","Iteration: 0007910,Generator Loss : 0.750, Discriminator Loss : 2.372, domain_classifier_loss: 0.021\n","Iteration: 0007920,Generator Loss : 0.728, Discriminator Loss : 3.663, domain_classifier_loss: 0.091\n","Iteration: 0007930,Generator Loss : 0.780, Discriminator Loss : 4.204, domain_classifier_loss: 0.007\n","Iteration: 0007940,Generator Loss : 0.826, Discriminator Loss : 1.327, domain_classifier_loss: 0.002\n","Iteration: 0007950,Generator Loss : 0.648, Discriminator Loss : 1.808, domain_classifier_loss: 0.001\n","Iteration: 0007960,Generator Loss : 0.743, Discriminator Loss : 2.086, domain_classifier_loss: 0.024\n","Iteration: 0007970,Generator Loss : 0.640, Discriminator Loss : 1.666, domain_classifier_loss: 0.039\n","Iteration: 0007980,Generator Loss : 0.681, Discriminator Loss : 1.522, domain_classifier_loss: 0.001\n","Iteration: 0007990,Generator Loss : 1.517, Discriminator Loss : 1.538, domain_classifier_loss: 0.000\n","Iteration: 0008000,Generator Loss : 0.847, Discriminator Loss : 1.722, domain_classifier_loss: 0.014\n","Iteration: 0008010,Generator Loss : 0.738, Discriminator Loss : 1.867, domain_classifier_loss: 0.007\n","Iteration: 0008020,Generator Loss : 0.543, Discriminator Loss : 1.733, domain_classifier_loss: 0.151\n","Iteration: 0008030,Generator Loss : 0.578, Discriminator Loss : 3.074, domain_classifier_loss: 0.002\n","Iteration: 0008040,Generator Loss : 0.801, Discriminator Loss : 1.644, domain_classifier_loss: 0.003\n","Iteration: 0008050,Generator Loss : 0.639, Discriminator Loss : 1.700, domain_classifier_loss: 0.002\n","Iteration: 0008060,Generator Loss : 0.772, Discriminator Loss : 8.791, domain_classifier_loss: 0.046\n","Iteration: 0008070,Generator Loss : 0.665, Discriminator Loss : 1.800, domain_classifier_loss: 0.004\n","Iteration: 0008080,Generator Loss : 0.919, Discriminator Loss : 1.443, domain_classifier_loss: 0.001\n","Iteration: 0008090,Generator Loss : 0.578, Discriminator Loss : 1.674, domain_classifier_loss: 0.000\n","Iteration: 0008100,Generator Loss : 0.719, Discriminator Loss : 1.742, domain_classifier_loss: 0.001\n","Iteration: 0008110,Generator Loss : 0.591, Discriminator Loss : 2.149, domain_classifier_loss: 0.018\n","Iteration: 0008120,Generator Loss : 0.850, Discriminator Loss : 1.713, domain_classifier_loss: 0.001\n","Iteration: 0008130,Generator Loss : 0.764, Discriminator Loss : 1.691, domain_classifier_loss: 0.001\n","Iteration: 0008140,Generator Loss : 0.798, Discriminator Loss : 1.621, domain_classifier_loss: 0.047\n","Iteration: 0008150,Generator Loss : 0.763, Discriminator Loss : 2.073, domain_classifier_loss: 0.034\n","Iteration: 0008160,Generator Loss : 0.716, Discriminator Loss : 1.699, domain_classifier_loss: 0.001\n","Iteration: 0008170,Generator Loss : 0.815, Discriminator Loss : 1.551, domain_classifier_loss: 0.013\n","Iteration: 0008180,Generator Loss : 0.970, Discriminator Loss : 2.149, domain_classifier_loss: 0.002\n","============test model============\n","[save]:out/7_2020-10-29-05-37/wavs/TM2-SF2+200027.wav\n","[save]:out/7_2020-10-29-05-37/wavs/TM2-SF2+200046.wav\n","[save]:out/7_2020-10-29-05-37/wavs/TM1-SF1+200030.wav\n","[save]:out/7_2020-10-29-05-37/wavs/TM1-SF1+200052.wav\n","[save]:out/7_2020-10-29-05-37/wavs/SF2-TM2+200023.wav\n","[save]:out/7_2020-10-29-05-37/wavs/SF2-TM2+200011.wav\n","[save]:out/7_2020-10-29-05-37/wavs/SF1-TM1+200029.wav\n","[save]:out/7_2020-10-29-05-37/wavs/SF1-TM1+200042.wav\n","============test finished!============\n","============save model============\n","[save]: out/7_2020-10-29-05-37/model\n","Time Elapsed for Epoch 7: 01:22:34\n","Iteration: 0008190,Generator Loss : 0.793, Discriminator Loss : 1.489, domain_classifier_loss: 0.007\n","Iteration: 0008200,Generator Loss : 0.860, Discriminator Loss : 2.084, domain_classifier_loss: 0.003\n","Iteration: 0008210,Generator Loss : 0.837, Discriminator Loss : 1.645, domain_classifier_loss: 0.042\n","Iteration: 0008220,Generator Loss : 0.802, Discriminator Loss : 1.795, domain_classifier_loss: 0.022\n","Iteration: 0008230,Generator Loss : 0.726, Discriminator Loss : 6.808, domain_classifier_loss: 0.682\n","Iteration: 0008240,Generator Loss : 1.308, Discriminator Loss : 2.066, domain_classifier_loss: 0.006\n","Iteration: 0008250,Generator Loss : 0.764, Discriminator Loss : 1.589, domain_classifier_loss: 0.007\n","Iteration: 0008260,Generator Loss : 0.414, Discriminator Loss : 2.749, domain_classifier_loss: 0.002\n","Iteration: 0008270,Generator Loss : 0.982, Discriminator Loss : 1.602, domain_classifier_loss: 0.058\n","Iteration: 0008280,Generator Loss : 0.819, Discriminator Loss : 5.097, domain_classifier_loss: 0.005\n","Iteration: 0008290,Generator Loss : 0.774, Discriminator Loss : 1.404, domain_classifier_loss: 0.004\n","Iteration: 0008300,Generator Loss : 0.541, Discriminator Loss : 2.887, domain_classifier_loss: 0.632\n","Iteration: 0008310,Generator Loss : 0.828, Discriminator Loss : 1.878, domain_classifier_loss: 0.001\n","Iteration: 0008320,Generator Loss : 0.739, Discriminator Loss : 2.256, domain_classifier_loss: 0.000\n","Iteration: 0008330,Generator Loss : 0.839, Discriminator Loss : 2.358, domain_classifier_loss: 0.022\n","Iteration: 0008340,Generator Loss : 0.843, Discriminator Loss : 2.333, domain_classifier_loss: 0.185\n","Iteration: 0008350,Generator Loss : 0.626, Discriminator Loss : 1.697, domain_classifier_loss: 0.006\n","Iteration: 0008360,Generator Loss : 0.631, Discriminator Loss : 2.546, domain_classifier_loss: 0.040\n","Iteration: 0008370,Generator Loss : 1.009, Discriminator Loss : 4.518, domain_classifier_loss: 0.001\n","Iteration: 0008380,Generator Loss : 0.869, Discriminator Loss : 1.493, domain_classifier_loss: 0.001\n","Iteration: 0008390,Generator Loss : 0.794, Discriminator Loss : 1.447, domain_classifier_loss: 0.000\n","Iteration: 0008400,Generator Loss : 0.782, Discriminator Loss : 2.677, domain_classifier_loss: 0.040\n","Iteration: 0008410,Generator Loss : 0.775, Discriminator Loss : 1.753, domain_classifier_loss: 0.001\n","Iteration: 0008420,Generator Loss : 0.874, Discriminator Loss : 2.409, domain_classifier_loss: 0.076\n","Iteration: 0008430,Generator Loss : 0.897, Discriminator Loss : 2.225, domain_classifier_loss: 0.145\n","Iteration: 0008440,Generator Loss : 0.809, Discriminator Loss : 3.307, domain_classifier_loss: 0.088\n","Iteration: 0008450,Generator Loss : 0.885, Discriminator Loss : 3.263, domain_classifier_loss: 0.024\n","Iteration: 0008460,Generator Loss : 0.819, Discriminator Loss : 1.632, domain_classifier_loss: 0.001\n","Iteration: 0008470,Generator Loss : 1.113, Discriminator Loss : 1.330, domain_classifier_loss: 0.001\n","Iteration: 0008480,Generator Loss : 0.726, Discriminator Loss : 1.670, domain_classifier_loss: 0.002\n","Iteration: 0008490,Generator Loss : 0.712, Discriminator Loss : 3.155, domain_classifier_loss: 0.084\n","Iteration: 0008500,Generator Loss : 0.941, Discriminator Loss : 7.193, domain_classifier_loss: 0.008\n","Iteration: 0008510,Generator Loss : 0.804, Discriminator Loss : 1.348, domain_classifier_loss: 0.001\n","Iteration: 0008520,Generator Loss : 0.728, Discriminator Loss : 1.488, domain_classifier_loss: 0.011\n","Iteration: 0008530,Generator Loss : 0.845, Discriminator Loss : 1.615, domain_classifier_loss: 0.001\n","Iteration: 0008540,Generator Loss : 0.780, Discriminator Loss : 3.139, domain_classifier_loss: 0.006\n","Iteration: 0008550,Generator Loss : 1.021, Discriminator Loss : 1.777, domain_classifier_loss: 0.001\n","Iteration: 0008560,Generator Loss : 0.758, Discriminator Loss : 1.631, domain_classifier_loss: 0.003\n","Iteration: 0008570,Generator Loss : 0.845, Discriminator Loss : 1.794, domain_classifier_loss: 0.063\n","Iteration: 0008580,Generator Loss : 0.706, Discriminator Loss : 2.647, domain_classifier_loss: 0.003\n","Iteration: 0008590,Generator Loss : 0.664, Discriminator Loss : 3.012, domain_classifier_loss: 0.008\n","Iteration: 0008600,Generator Loss : 0.649, Discriminator Loss : 1.630, domain_classifier_loss: 0.353\n","Iteration: 0008610,Generator Loss : 0.844, Discriminator Loss : 2.379, domain_classifier_loss: 0.015\n","Iteration: 0008620,Generator Loss : 0.915, Discriminator Loss : 2.005, domain_classifier_loss: 0.002\n","Iteration: 0008630,Generator Loss : 0.787, Discriminator Loss : 2.199, domain_classifier_loss: 0.002\n","Iteration: 0008640,Generator Loss : 0.989, Discriminator Loss : 1.830, domain_classifier_loss: 0.002\n","Iteration: 0008650,Generator Loss : 0.999, Discriminator Loss : 7.160, domain_classifier_loss: 0.018\n","Iteration: 0008660,Generator Loss : 0.644, Discriminator Loss : 1.371, domain_classifier_loss: 0.059\n","Iteration: 0008670,Generator Loss : 0.926, Discriminator Loss : 1.647, domain_classifier_loss: 0.003\n","Iteration: 0008680,Generator Loss : 0.748, Discriminator Loss : 1.639, domain_classifier_loss: 0.001\n","Iteration: 0008690,Generator Loss : 0.731, Discriminator Loss : 1.569, domain_classifier_loss: 0.220\n","Iteration: 0008700,Generator Loss : 0.599, Discriminator Loss : 1.960, domain_classifier_loss: 0.025\n","Iteration: 0008710,Generator Loss : 0.651, Discriminator Loss : 1.800, domain_classifier_loss: 0.083\n","Iteration: 0008720,Generator Loss : 0.540, Discriminator Loss : 1.719, domain_classifier_loss: 0.117\n","Iteration: 0008730,Generator Loss : 0.861, Discriminator Loss : 1.705, domain_classifier_loss: 0.001\n","Iteration: 0008740,Generator Loss : 0.734, Discriminator Loss : 2.435, domain_classifier_loss: 0.623\n","Iteration: 0008750,Generator Loss : 0.746, Discriminator Loss : 2.000, domain_classifier_loss: 0.177\n","Iteration: 0008760,Generator Loss : 0.889, Discriminator Loss : 1.703, domain_classifier_loss: 0.010\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pnl6e9yvvapy","executionInfo":{"status":"ok","timestamp":1604046654735,"user_tz":-330,"elapsed":192796,"user":{"displayName":"PAMPANA KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgC8-NBywOVdBZ5leotgm2gdUhoIb-HmQX-09S4=s64","userId":"05163607940283044342"}},"outputId":"4882fd93-f647-4771-d00f-052348b18710","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","\n","import argparse\n","import os\n","import numpy as np\n","\n","from model import StarGANVC\n","from preprocess import *\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from utility import *\n","\n","#get all speaker\n","all_speaker = get_speakers(trainset='./data/fourspeakers')\n","label_enc = LabelEncoder()\n","label_enc.fit(all_speaker)\n","\n","\n","def conversion(model_dir, test_dir, output_dir, source, target):\n","    if not os.path.exists(model_dir) or not os.path.exists(test_dir):\n","        raise Exception('model dir or test dir not exist!')\n","    model = StarGANVC(num_features=FEATURE_DIM, mode='test')\n","\n","    model.load(filepath=os.path.join(model_dir, MODEL_NAME))\n","    #f'./data/fourspeakers_test/{source}/*.wav'\n","    p = os.path.join(test_dir, f'{source}/*.wav')\n","    tempfiles = glob.glob(p)\n","\n","    normlizer = Normalizer()\n","\n","    for one_file in tempfiles:\n","        _, speaker, name = os.path.normpath(one_file).rsplit(os.sep, maxsplit=2)\n","        # print(speaker, name)\n","        wav_, fs = librosa.load(one_file, sr=SAMPLE_RATE, mono=True, dtype=np.float64)\n","        wav, pad_length = pad_wav_to_get_fixed_frames(wav_, frames=FRAMES)\n","\n","        f0, timeaxis = pyworld.harvest(wav, fs, f0_floor=71.0, f0_ceil=500.0)\n","\n","        #CheapTrick harmonic spectral envelope estimation algorithm.\n","        sp = pyworld.cheaptrick(wav, f0, timeaxis, fs, fft_size=FFTSIZE)\n","\n","        #D4C aperiodicity estimation algorithm.\n","        ap = pyworld.d4c(wav, f0, timeaxis, fs, fft_size=FFTSIZE)\n","        #feature reduction\n","        coded_sp = pyworld.code_spectral_envelope(sp, fs, FEATURE_DIM)\n","\n","        coded_sps_mean = np.mean(coded_sp, axis=0, dtype=np.float64, keepdims=True)\n","        coded_sps_std = np.std(coded_sp, axis=0, dtype=np.float64, keepdims=True)\n","        #normalize\n","        # coded_sp = (coded_sp - coded_sps_mean) / coded_sps_std\n","        # print(coded_sp.shape, f0.shape, ap.shape)\n","\n","        #one audio file to multiple slices(that's one_test_sample),every slice is an input\n","        one_test_sample = []\n","        csp_transpose = coded_sp.T  #36x512 36x128...\n","        for i in range(0, csp_transpose.shape[1] - FRAMES + 1, FRAMES):\n","            t = csp_transpose[:, i:i + FRAMES]\n","            #normalize t\n","            t = normlizer.forward_process(t, speaker)\n","            t = np.reshape(t, [t.shape[0], t.shape[1], 1])\n","            one_test_sample.append(t)\n","        # print(f'{len(one_test_sample)} slices appended!')\n","\n","        #generate target label (one-hot vector)\n","        one_test_sample_label = np.zeros([len(one_test_sample), len(all_speaker)])\n","        temp_index = label_enc.transform([target])[0]\n","        one_test_sample_label[:, temp_index] = 1\n","\n","        generated_results = model.test(one_test_sample, one_test_sample_label)\n","\n","        reshpaped_res = []\n","        for one in generated_results:\n","            t = np.reshape(one, [one.shape[0], one.shape[1]])\n","\n","            t = normlizer.backward_process(t, target)\n","            reshpaped_res.append(t)\n","        #collect the generated slices, and concate the array to be a whole representation of the whole audio\n","        c = []\n","        for one_slice in reshpaped_res:\n","            one_slice = np.ascontiguousarray(one_slice.T, dtype=np.float64)\n","            # one_slice = one_slice * coded_sps_std + coded_sps_mean\n","\n","            # print(f'one_slice : {one_slice.shape}')\n","            decoded_sp = pyworld.decode_spectral_envelope(one_slice, SAMPLE_RATE, fft_size=FFTSIZE)\n","            # print(f'decoded_sp shape: {decoded_sp.shape}')\n","            c.append(decoded_sp)\n","\n","        concated = np.concatenate((c), axis=0)\n","        # print(f'concated shape: {concated.shape}')\n","        #f0 convert\n","        f0 = normlizer.pitch_conversion(f0, speaker, target)\n","\n","        synwav = pyworld.synthesize(f0, concated, ap, fs)\n","        # print(f'origin wav:{len(wav_)} paded wav:{len(wav)} synthesize wav:{len(synwav)}')\n","\n","        #remove synthesized wav paded length\n","        synwav = synwav[:-pad_length]\n","\n","        #save synthesized wav to file\n","        wavname = f'{speaker}-{target}+{name}'\n","        wavpath = f'{output_dir}/wavs'\n","        if not os.path.exists(wavpath):\n","            os.makedirs(wavpath, exist_ok=True)\n","        librosa.output.write_wav(f'{wavpath}/{wavname}', synwav, sr=fs)\n","\n","\n","if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser(description='Convert voices using pre-trained CycleGAN model.')\n","\n","    model_dir = './out/7_2020-10-29-05-37/model/'\n","    test_dir = './data/fourspeakers_test/'\n","    source_speaker = 'SF1'\n","    target_speaker = 'TM1'\n","    output_dir = '.\\converted_voices'\n","\n","    parser.add_argument('--model_dir', type=str, help='Directory for the pre-trained model.', default=model_dir)\n","    parser.add_argument('--test_dir', type=str, help='Directory for the voices for conversion.', default=test_dir)\n","    parser.add_argument('--output_dir', type=str, help='Directory for the converted voices.', default=output_dir)\n","    parser.add_argument('--source_speaker', type=str, help='source_speaker', default=source_speaker)\n","    parser.add_argument('--target_speaker', type=str, help='target_speaker', default=target_speaker)\n","    parser.add_argument('-f')\n","    argv = parser.parse_args()\n","\n","    model_dir = argv.model_dir\n","    test_dir = argv.test_dir\n","    output_dir = argv.output_dir\n","    source_speaker = argv.source_speaker\n","    target_speaker = argv.target_speaker\n","\n","    conversion(model_dir = model_dir,\\\n","     test_dir = test_dir, output_dir = output_dir, source=source_speaker, target=target_speaker)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","domain_classifier_d1: (?, 8, 512, 8)\n","domain_classifier_d1_p: (?, 4, 256, 8)\n","domain_classifier_d12: (?, 4, 256, 16)\n","domain_classifier_d2_p: (?, 2, 128, 16)\n","domain_classifier_d3: (?, 2, 128, 32)\n","domain_classifier_d3_p: (?, 1, 64, 32)\n","domain_classifier_d4: (?, 1, 64, 16)\n","domain_classifier_d4_p: (?, 1, 32, 16)\n","domain_classifier_d5: (?, 1, 32, 4)\n","domain_classifier_d5_p: (?, 1, 16, 4)\n","classifier_output: (?, 1, 1, 4)\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","domain_classifier_d1: (?, 8, 512, 8)\n","domain_classifier_d1_p: (?, 4, 256, 8)\n","domain_classifier_d12: (?, 4, 256, 16)\n","domain_classifier_d2_p: (?, 2, 128, 16)\n","domain_classifier_d3: (?, 2, 128, 32)\n","domain_classifier_d3_p: (?, 1, 64, 32)\n","domain_classifier_d4: (?, 1, 64, 16)\n","domain_classifier_d4_p: (?, 1, 32, 16)\n","domain_classifier_d5: (?, 1, 32, 4)\n","domain_classifier_d5_p: (?, 1, 16, 4)\n","classifier_output: (?, 1, 1, 4)\n","d1: [None, 36, 512, 32]\n","d2: [None, 18, 256, 64]\n","d3: [None, 9, 128, 128]\n","d4: [None, 9, 128, 64]\n","[None, 1, 128, 4]\n","u1.shape :[None, 9, 128, 64]\n","c1 shape: (?, 9, 128, 4)\n","u1_concat.shape :[None, 9, 128, 68]\n","u2.shape :[None, 9, 128, 128]\n","u3.shape :[None, 18, 256, 64]\n","u4.shape :[None, 36, 512, 32]\n","u4_concat.shape :[None, 36, 512, 36]\n","u5.shape :[None, 36, 512, 1]\n","INFO:tensorflow:Restoring parameters from ./out/7_2020-10-29-05-37/model/starganvc_model\n","found stat file: ./etc/TM2-stats.npz\n","found stat file: ./etc/TM1-stats.npz\n","found stat file: ./etc/SF2-stats.npz\n","found stat file: ./etc/SF1-stats.npz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Bx4qSDcmn3H"},"source":[""],"execution_count":null,"outputs":[]}]}